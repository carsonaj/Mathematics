\documentclass[12pt]{amsart}
\usepackage[margin=1in]{geometry} 
\usepackage{amsmath,amsthm,amssymb,setspace, mathtools}
\usepackage{physics}

\usepackage{color}   %May be necessary if you want to color links
\usepackage{hyperref}
\hypersetup{
	colorlinks=true, %set true if you want colored links
	linktoc=all,     %set to all if you want both sections and subsections linked
	linkcolor=black,  %choose some color if you want links to stand out
	urlcolor=cyan
}


%
%
%
\newif\ifhideproofs
%\hideproofstrue %uncomment to hide proofs
%
%
%
%
\ifhideproofs
\usepackage{environ}
\NewEnviron{hide}{}
\let\proof\hide
\let\endproof\endhide
\fi

\theoremstyle{definition}
\newtheorem{definition}{Definition}[subsection]
\newtheorem{defn}[definition]{Definition}
\newtheorem{note}[definition]{Note}
\newtheorem{thm}[definition]{Theorem}
\newtheorem{lem}[definition]{Lemma}
\newtheorem{prop}[definition]{Proposition}
\newtheorem{cor}[definition]{Corollary}
\newtheorem{conj}[definition]{Conjecture}
\newtheorem{ex}[definition]{Exercise}




\newcommand{\al}{\alpha}
\newcommand{\gam}{\gamma}
\newcommand{\Gam}{\Gamma}
\newcommand{\bet}{\beta} 
\newcommand{\del}{\delta} 
\newcommand{\Del}{\Delta}
\newcommand{\lam}{\lambda}  
\newcommand{\Lam}{\Lambda} 
\newcommand{\ep}{\epsilon}
\newcommand{\sig}{\sigma} 
\newcommand{\om}{\omega}
\newcommand{\Om}{\Omega}
\newcommand{\C}{\mathbb{C}}
\newcommand{\N}{\mathbb{N}}
\newcommand{\E}{\mathbb{E}}
\renewcommand{\H}{\mathbb{H}}
\newcommand{\Z}{\mathbb{Z}}
\newcommand{\R}{\mathbb{R}}
\newcommand{\T}{\mathbb{T}}
\newcommand{\Q}{\mathbb{Q}}
\renewcommand{\P}{\mathbb{P}}
\newcommand{\MA}{\mathcal{A}}
\newcommand{\MC}{\mathcal{C}}
\newcommand{\MB}{\mathcal{B}}
\newcommand{\MD}{\mathcal{D}}
\newcommand{\MF}{\mathcal{F}}
\newcommand{\MG}{\mathcal{G}}
\newcommand{\ML}{\mathcal{L}}
\newcommand{\MN}{\mathcal{N}}
\newcommand{\MS}{\mathcal{S}}
\newcommand{\MP}{\mathcal{P}}
\newcommand{\ME}{\mathcal{E}}
\newcommand{\MT}{\mathcal{T}}
\newcommand{\MI}{\mathcal{I}}
\newcommand{\MM}{\mathcal{M}}
\newcommand{\MX}{\mathcal{X}}
\newcommand{\MU}{\mathcal{U}}


\renewcommand{\r}{\rangle}
\renewcommand{\l}{\langle}

\newcommand{\RG}{[0,\infty]}
\newcommand{\Rg}{[0,\infty)}
\newcommand{\Ll}{L^1_{\text{loc}}(\R^n)}
\newcommand{\iid}{\stackrel{iid}{\sim}}

\newcommand{\limfn}{\liminf \limits_{n \rightarrow \infty}}
\newcommand{\limpn}{\limsup \limits_{n \rightarrow \infty}}
\newcommand{\limn}{\lim \limits_{n \rightarrow \infty}}
\newcommand{\convt}[1]{\xrightarrow{\text{#1}}}
\newcommand{\conv}[1]{\xrightarrow{#1}} 
\newcommand{\seq}[2]{(#1_{#2})_{#2 \in \N}}


\DeclareMathOperator{\supp}{supp}
\DeclareMathOperator{\spn}{span}
\DeclareMathOperator{\sgn}{sgn}
\DeclareMathOperator{\iso}{Iso}
\DeclareMathOperator{\id}{id}
\DeclareMathOperator{\uni}{Uni}


\begin{document}
	
	\title{Introduction to Bayesian Statistics}
	\author{Carson James}
	\maketitle
	
	\tableofcontents
	
	\section{Introduction}
	\begin{defn}
		Let $A \in \MB(R^d)$ and $\Theta \neq \varnothing$. Suppose that $m(A) > 0$. We define 
		$$\MD(A) = \{f \in L^1(A) : f \geq 0 \text{ and } \|f\|_1 = 1\}$$ 
		and for $\theta \in \Theta$, we define
		$$\MD(A|\theta) = \{f: A \times \Theta \rightarrow \R : f(\cdot| \theta) \in \MD(A)\}$$
	\end{defn}
	
	\section{Sampling}
	
	\subsection{Inverse CDF Sampling}
	
	\subsection{Conditional Chain Sampling}
	\begin{defn}
	Let $A \subset \R^d$ be open, $a = (a_1, \dots, a_d) \in A$. Define $\tau_1:\R \rightarrow \R^d$ and $A_1 \subset \R$ by 
	\begin{itemize}
	\item $\tau_1(x) = (x, a_2, \ldots, a_d)$
	\item $A_1 = \tau_1^{-1}(A)$
\end{itemize}	 
	Choose $f_1 \in \MD(A_1)$ and sample $b_1 \sim f_1$. For $j \in \{2, \cdots, d\}$, define $\tau_j: \R \rightarrow \R^n$, $A_j$, choose $f_j$ and sample $b_j$ inductively by 
	\begin{itemize}
	\item setting $\tau_j(x) = (b_1, \dots, b_{j-1}, x_j, a_{j+1}, \dots, a_d)$  
	\item setting $A_j = \tau_j^{-1}(A)$
	\item choosing $f_j \in \MD(A_j|b_1, \ldots, b_{j-1})$
	and
	setting $b_j \sim f_j$ 
	\end{itemize}
	Note that $\tau_j$ is continuous which implies that $A_j = \tau_j^{-1}(A)$ is open.
	
	\end{defn}	
	
	\begin{ex}
	Let $A \subset \R$ be open and $a = (a_1, \dots, a_d) \in A$. Define $A_j$, $f_j$ and $b_j$ as above and define $b \in A$ and $f: A \rightarrow \R$ by $$b = (b_1, \dots, b_d)$$ and  $$f(x_1, \dots, x_d) = \prod_{j=1}^nf_j(x_j)$$ 
	Then 
	\begin{enumerate}
	\item $f \in \MD(A)$ 
	\item $b \sim f$
	\end{enumerate}
	\end{ex}
	
	\begin{proof}
	\begin{enumerate}
	\item Fubini's theorem implies that 
	\begin{align*}
	\int_A f dm^d
	&= \int f_1(x_1) \bigg[ \int f_2(x_2) \bigg[ \dots \bigg[ \int f_d(x_d) dm(x_d) \bigg] \dots \bigg] dm(x_2) \bigg] dm(x_1) \\
	&= 1
	\end{align*} 
	\item We observe that 
	\begin{align*}
	[b] 
	&= [b_d| b_{d-1}, \ldots, b_1][b_{d-1}| b_{d-2}, \ldots, b_1] \cdots [b_1] \\
	&= f_d(b_d) \cdots f_1(b_1) \\
	&= f(b)
	\end{align*}
	
	\end{enumerate}
	\end{proof}
	
	\begin{ex}
	Set $A = B^d(0, 1) \cap [0,1]^d$ (the first orthant of the unit $d$-ball) and $a = 0$. Then $A_1 = (0,1)$. Choose $f_1 = 1_{(0,1)}$ and sample $b_1 \sim f_1$. For each $j \in \{2, \ldots, d\}$, set $$s_j = \sqrt{1 - \sum_{k=1}^{j-1} b^2_k}$$ 
	Then for each $j \in \{2, \ldots, d\}$, $$A_j = ( 0, s_j)$$ 
	\end{ex}
	
	\begin{proof}
	Clear.
	\end{proof}
	
	\begin{ex}
	Continuing from the previous problem, for each $j \in \{2, \ldots, d\}$, choose $f_j = s_j^{-1}1_{(0, s_j )}$. Then $f	 = \bigg( \prod_{j=2}^ds^{-1}_j \bigg) 1_{\prod_{j=2}^d (0, s_j)}$. 
	\end{ex}
	
	\begin{proof}
	Clear.
	\end{proof}
	
	\begin{defn}
	Now make $f_j \sim GP(\mu_j, c_j)$. 	
	\end{defn}
	
	\subsection{Importance Sampling}
	
	\subsection{Rejection Sampling}
	
	\begin{ex}
		Let $f, g \in \MD(\R^d)$ and $A \in \MB(\R^d)$. Suppose that $m^d(A) > 0$. If $X \sim f$, then $X|X \in A \sim \|fI_A\|_1^{-1}fI_A$. 
	\end{ex}

	\begin{proof}
		Let $C \in \MB(\R^d)$. Then
		\begin{align*}
			P(X \in C|X \in A)
			&= P(X \in C \cap A) P(X \in A)^{-1} \\
			&= \|fI_A\|_1^{-1} \int_C fI_A dm^d \\
		\end{align*}
		So $f_{X|X \in A} = \|fI_A\|_1^{-1}fI_A$.
	\end{proof}
	
	\begin{ex}
		Let $A, B \in \MB(\R^d)$. Suppose that $A \subset B$ and $0 < m^d(A)$ and $ m^{d}(B) < \infty$. If $X \sim \uni(B)$, then $X|X \in A \sim \uni(A)$. 
	\end{ex}

	\begin{proof}
		Clear using the previous exercise with $f = I_B$.
	\end{proof}
	
	\begin{ex}\textbf{(Fundamental Theorem of Simulation):} \\
		Let $f \in \MD(\R^d)$ and $c > 0$. Define $$G_c = \{(x,v) \in \R^{d+1}: 0< v < cf(x)\}$$ 
		\begin{enumerate}
			\item If $X \sim f$ and $U \sim \uni(0,1)$  are independent, then $(X, cUf(X)) \sim \uni(G_c)$.
			\item If $(X, V) \sim \uni(G_c)$, then $X \sim f$.
		\end{enumerate}
	\end{ex}

	\begin{proof} First we note that $m^{d+1}(G_c) = c$. 
		\begin{enumerate}
			\item Suppose that $X \sim f$ and $U \sim \uni(0,1)$ are independent and put $Y = cUf(X)$. Then $Y| X= x \sim cUf(x) \sim \uni(0, cf(x))$ and we have that for each $x \in \supp X$ and $y \in (0, cf(x))$,
			\begin{align*}
				f_{X, Y}(x,y) 
				&= f_{Y|X}(y| x) f(x) \\
				&= \frac{1}{c f(x)}f(x) \\
				&= \frac{1}{c}
			\end{align*}
			So $(X, Y) \sim \uni(G_c)$\\
			\item Suppose that $(X, V) \sim \uni(G_c)$. Then $f_{X,V}(x,v) = \frac{1}{c} I_{G_c}(x,v)$. So 
			\begin{align*}
				f_X(x) 
				&= \int_{\R} \frac{1}{c}I_{G_c}(x,v) dm(v) \\ 
				&= \int_{0}^{cf(x)} \frac{1}{c}dv \\
				&= f(x) 
			\end{align*}
			So $X \sim f$.
		\end{enumerate}
	\end{proof}

	\begin{ex}
		Let $f, g \in \MD(\R^d)$, $c_f,c_g>0$ and $M > 0$. Put $\tilde{f} = c_f f$ and $\tilde{g} = c_g g$. Suppose that $\tilde{f} \leq M \tilde{g}$. If $Y \sim g$ and $U \sim \uni(0,1)$ are independent, then $Y|U \leq \frac{\tilde{f}(Y)}{M\tilde{g}(Y)} \sim f$ and $P ( U \leq \frac{\tilde{f}(Y)}{M\tilde{g}(Y)} ) = \frac{c_f}{c_gM}$ 
	\end{ex}

	\begin{proof}
		Put $$G_g = \{(y,v) \in \R^{d+1}: 0< v < M\tilde{g}(y)\} $$ and $$ G_f = \{(y,v) \in \R^{d+1}: 0< v < \tilde{f}(y)\} $$ 
		Then $G_f \subset G_g$, $m^d(G_g) = c_gM$ and $m^d(G_f) =c_f$. By the first part of the fundamental theorem of simulation, we know that $$(Y, MUc_gg(Y)) \sim \uni(G_g)$$ 
		Since $\{(Y, MUc_gg(Y)) \in G_f \} = \{U \leq \frac{c_ff(Y)}{Mc_gg(Y)}\}$, a previous exercise tells us that $$(Y, MUc_gg(Y))|U \leq \frac{c_ff(Y)}{Mc_gg(Y)} \sim \uni(G_f)$$
		Then the second part of the fundamental theorem of simulation tells us that $$Y|U \leq \frac{c_ff(Y)}{Mc_gg(Y)} \sim f$$
		Finally we have that
		\begin{align*}
			P \bigg( U \leq \frac{c_ff(Y)}{Mc_gg(Y)} \bigg) 
			&= P [(Y, MUc_gg(Y)) \in G_f ]\\
			&= \frac{c_f}{c_gM}
		\end{align*}
	\end{proof}

	\begin{defn}\textbf{(Rejection Sampling Algorithm):} \\
		Let $f, g \in \MD(\R^d)$, $c_f,c_g>0$ and $M > 0$. Put $\tilde{f} = c_f f$ and $\tilde{g} = c_g g$. Suppose that $\tilde{f} \leq M \tilde{g}$. We define the \textbf{rejection sampling algorithm} as follows:
		\begin{enumerate}
			\item sample $Y \sim g$ and $U \sim \uni(0,1)$ independently
			\item if $U \leq \frac{\tilde{f}(Y)}{M\tilde{g}(Y)} $, accept $Y$, else return to $(1)$.
		\end{enumerate}
		If we sample $(X_n)_{n \in \N}$ independently using the rejection sampler, then the previous exercises imply that $(X_n)_{n \in \N} \iid f$ and the acceptance rate is $\frac{c_f}{c_gM}$.
	\end{defn}

	\begin{note}
		Phrasing the rejection sampler in terms of $\tilde{f}$ and $\tilde{g}$ instead of $f$ and $g$ is usefule because we may not always be able to solve for the normalizing constants.
	\end{note}
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	\section{Posterior Consistency}
	
	\subsection{Introduction}
	
	\begin{defn}
	Let $(\MX, \MF)$ and $\Theta$ be
	\end{defn}	
	

	
\end{document}