\documentclass[12pt]{amsart}
\usepackage[margin=1in]{geometry} 
\usepackage{amsmath,amsthm,amssymb,setspace, mathtools, enumitem}
\usepackage{physics}

\usepackage{color}   %May be necessary if you want to color links
\usepackage{hyperref}
\hypersetup{
	colorlinks=true, %set true if you want colored links
	linktoc=all,     %set to all if you want both sections and subsections linked
	linkcolor=black,  %choose some color if you want links to stand out
	urlcolor=cyan
}


%
%
%
\newif\ifhideproofs
%\hideproofstrue %uncomment to hide proofs
%
%
%
%
\ifhideproofs
\usepackage{environ}
\NewEnviron{hide}{}
\let\proof\hide
\let\endproof\endhide
\fi

\theoremstyle{definition}
\newtheorem{definition}{Definition}[subsection]
\newtheorem{defn}[definition]{Definition}
\newtheorem{note}[definition]{Note}
\newtheorem{thm}[definition]{Theorem}
\newtheorem{lem}[definition]{Lemma}
\newtheorem{prop}[definition]{Proposition}
\newtheorem{cor}[definition]{Corollary}
\newtheorem{conj}[definition]{Conjecture}
\newtheorem{ex}[definition]{Exercise}


\newcommand{\al}{\alpha}
\newcommand{\Gam}{\Gamma}
\newcommand{\be}{\beta} 
\newcommand{\del}{\delta} 
\newcommand{\Del}{\Delta}
\newcommand{\lam}{\lambda}  
\newcommand{\Lam}{\Lambda} 
\newcommand{\ep}{\epsilon}
\newcommand{\sig}{\sigma} 
\newcommand{\om}{\omega}
\newcommand{\Om}{\Omega}
\newcommand{\C}{\mathbb{C}}
\newcommand{\N}{\mathbb{N}}
\newcommand{\E}{\mathbb{E}}
\newcommand{\Z}{\mathbb{Z}}
\newcommand{\R}{\mathbb{R}}
\newcommand{\T}{\mathbb{T}}
\newcommand{\Q}{\mathbb{Q}}
\renewcommand{\P}{\mathbb{P}}
\newcommand{\MA}{\mathcal{A}}
\newcommand{\MC}{\mathcal{C}}
\newcommand{\MB}{\mathcal{B}}
\newcommand{\MF}{\mathcal{F}}
\newcommand{\MG}{\mathcal{G}}
\newcommand{\ML}{\mathcal{L}}
\newcommand{\MN}{\mathcal{N}}
\newcommand{\MS}{\mathcal{S}}
\newcommand{\MP}{\mathcal{P}}
\newcommand{\ME}{\mathcal{E}}
\newcommand{\MT}{\mathcal{T}}
\newcommand{\MM}{\mathcal{M}}
\newcommand{\MI}{\mathcal{I}}

\newcommand{\ui}{[0,1]}
\newcommand{\p}{\partial}

\newcommand{\io}{\text{ i.o.}}
%\newcommand{\ev}{\text{ ev.}}
\renewcommand{\r}{\rangle}
\renewcommand{\l}{\langle}

\newcommand{\RG}{[0,\infty]}
\newcommand{\Rg}{[0,\infty)}
\newcommand{\Ru}{(\infty, \infty]}
\newcommand{\Rd}{[\infty, \infty)}
\newcommand{\Ll}{L^1_{\text{loc}}(\R^n)}

\newcommand{\limfn}{\liminf \limits_{n \rightarrow \infty}}
\newcommand{\limpn}{\limsup \limits_{n \rightarrow \infty}}
\newcommand{\limn}{\lim \limits_{n \rightarrow \infty}}
\newcommand{\convt}[1]{\xrightarrow{\text{#1}}}
\newcommand{\conv}[1]{\xrightarrow{#1}} 
\newcommand{\seq}[2]{(#1_{#2})_{#2 \in \N}}

\newcommand{\lsc}{l.s.c. }

\newcommand{\as}[1]{\overset{#1}{\sim}}
\newcommand{\astx}[1]{\overset{\text{#1}}{\sim}}

\DeclareMathOperator{\supp}{supp}
\DeclareMathOperator{\sgn}{sgn}
\DeclareMathOperator{\spn}{span}
\DeclareMathOperator{\iso}{Iso}
\DeclareMathOperator{\id}{id}
\DeclareMathOperator{\argmax}{arg\,max}
\DeclareMathOperator{\argmin}{arg\,min}
\DeclareMathOperator{\Aut}{Aut}
\DeclareMathOperator{\Homeo}{Homeo}
\DeclareMathOperator{\Sym}{Sym}


\begin{document}
	
	\title{Introduction to Analysis}
	\author{Carson James}
	\maketitle
	
	\tableofcontents
	
	\section*{Preface}
	\begin{flushleft}
		\href{https://creativecommons.org/licenses/by-nc-sa/4.0/legalcode.txt}{cc-by-nc-sa}
	\end{flushleft}

	
	
	\newpage
	

	\newpage
	
	\section{Real and Complex Numbers}
	\begin{note}
		As a starting point, we will take as fact the existence of the \textbf{natural numbers} $$\N = \{1, 2, \cdots\}$$ the \textbf{integers} $$\Z = \{\cdots, -2, -2, 0, 1, 2, \cdots\}$$ and the \textbf{rational numbers} $$\Q = \bigg \{\frac{a}{b}: a \in \Z, b \in \N \bigg \}$$
	\end{note}
	\subsection{Real Numbers}
	
	\begin{defn}
		Let $X$ be a set and $\leq$ a relation on $X$. Then $\leq$ is said to be a \textbf{total order} if for each $a,b,c \in X$,
		\begin{enumerate}
			\item $a \leq a$
			\item $a \leq b$ and $b \leq c$ implies that $a \leq  c$ 
			\item $a \leq b$ and $b \leq a$ implies that $a = b$ 
			\item $a \leq b$ or $b \leq a$
		\end{enumerate}
	\end{defn}

	\begin{ex}
		We define the relation $\leq$ on $\Q$ defined by $$\frac{a}{b} \leq \frac{c}{d} \hspace{.2cm} \text{iff} \hspace{.2cm} ad \leq bc$$ Then $\leq$ is a total order of $\Q$.
	\end{ex}

	\begin{proof} Let $\frac{a}{b}, \frac{c}{d}, \frac{e}{f} \in \Q$. Then
		\begin{enumerate}
			\item  $\frac{a}{b} \leq \frac{a}{b}$ since $ab \leq ab$. 
			\item if $\frac{a}{b} \leq \frac{c}{d}$ and $\frac{c}{d} \leq  \frac{e}{f}$, then $ad \leq bc$ and $ cf \leq de$. Multiplying the first inequality by $f$ and the second inequality by $b$, we obtain $adf \leq bcf \leq bde$. Dividing both sides by $d$ yields $af \leq be$. Hence $\frac{a}{b} \leq \frac{e}{f}$. 
			\item if $\frac{a}{b} \leq \frac{c}{d}$ and $\frac{c}{d} \leq \frac{a}{b}$, then $ad \leq bc$ and $bc \leq ab$. This implies that $ad = bc$. Hence $\frac{a}{b} = \frac{c}{d}$.
			\item 
		\end{enumerate}
	\end{proof}
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	\newpage
	\section{Metric Spaces}
	\subsection{Introduction}
	\begin{defn}
	Let $M$ be a set and $d: M \times M \rightarrow \R$. Then $d$ is said to be a \textbf{metric on $M$} if for each $x,y,z \in M$, 
	\begin{enumerate}
	\item $d(x,y) = 0$ iff $x = y$
	\item $d(x, y) \leq d(x, z) + d(z, y)$
\end{enumerate}	 
	\end{defn}	
	
	\begin{ex}
	Let $M$ be a set and $d: M \times M \rightarrow \R$ a metric on $M$. Then for each $x,y \in M$, $d(x,y) \geq 0$. 
	\end{ex}
	
	\begin{proof}
	Let $x, y, z \in M$. Then $d(x,z) \leq d(x, y) + d(y,z)$. This implies that $d(x,z) - d(x, y) \leq d(y, z)$. Since $z$ is arbitrary, taking $z=x$, we obtain 
	\begin{align*}
	d(x,x) - d(x, y) \leq d(y, x)
	& \implies - d(x, y) \leq d(x, y) \\
	& \implies 0 \leq 2 d(x,y) \\
	& \implies d(x,y) \geq 0
	\end{align*}
	\end{proof}		
	
	\begin{defn}
	Let $M$ be a set and $d: M \times M \rightarrow \Rg$ a metric. Then $(M, d)$ is called a \textbf{metric space}.
	\end{defn}	
	
	\begin{defn}
	Let $(M,d)$ be a metric space and $A,B \subset M$. We define the \textbf{distance between $A$ and $B$}, denoted $d(A,B)$, by $$d(A,B) = \inf_{\substack{a \in A \\ b \in B}} d(a,b)$$
	\end{defn}
	
	\begin{ex}
	Let $(M,d)$ be a metric space. Then for each $A,B \subset M$ and $c \in M$, $$d(A,B) \leq d(A,c) + d(c, B)$$
	\end{ex}
	
	\begin{proof}
	Let $A,B \subset M$, $c \in M$ and $\ep>0$. Choose $a \in A$ and $b \in B$ such that $d(a,c) < d(A,c)+ \ep/2$ and  $d(c,b) < d(c,B)+ \ep/2$. Then 
	\begin{align*}
	d(A,B) 
	&\leq d(a,b) \\
	&\leq d(a,c) + d(c,b) \\
	&< d(A,c) + \frac{\ep}{2} + d(c,B) + \frac{\ep}{2} \\
	&= d(A,c) + d(c,B) + \ep
	\end{align*}
	Since $\ep >0$ is arbitrary, $d(A,B) \leq d(A,c) + d(c,B)$.
	\end{proof}
	
	\begin{defn}
	Let $M$ be a set, $d_1, d_2: M \times M \rightarrow \Rg$ metrics on $M$ and $p$ a property. Then $d_1$ and $d_2$ are said to be \textbf{$p$-equivalent} if $\id_M: (M, d_1) \rightarrow (M, d_2)$ and $\id_M: (M, d_2) \rightarrow (M, d_1)$ have property $p$. We say that $d_1$ and $d_2$ are \textbf{topologically equivalent} when $p$ is the property of being continuous. We say that $d_1$ and $d_2$ are \textbf{equivalent} when $p$ is the property of being Lipschitz.
	\end{defn}	
	
	\begin{ex}
	
	\end{ex}
	
	
	\begin{defn}
	Let $(M,d)$ be a metric space. Then $(M,d)$ is said to be a \textbf{Polish space} if $(M,d)$ is complete and separable. 
	\end{defn}
	
	
	
	\begin{ex}
	Let $(X, d)$ be a compact metric space, $E \subset X$ closed, $U \subset X$ open. Suppose that $E \subset U$. Then there exists $\del >0$ such that for each $x \in E$, $B(x, \del) \subset U$.
	\end{ex}	
	
	\begin{proof}
	Since $X$ is compact, $E$ and $U^c$ are compact. Then there exist $x_0 \in E$ and $y_0 \in U^c$ such that $d(E, U^c) = d(x_0,y_0)$. Since $E \cap U^c = \varnothing$, $x_0 \neq y_0$ and $d(E, U^c) >0$. Put $\ep = d(E, U^c)$ and $\del = \frac{\ep}{2}$.  Let $x \in E$, $w \in B(x, \del)$ and $y \in U^c$. Then 
	\begin{align*}
	d(y, w) 
	&\geq d(y, x) - d(x, w) \\
	&> \ep - \del \\
	&= \ep - \frac{\ep}{2} \\
	&= \frac{\ep}{2} \\
	&> 0
\end{align*}	  
	So $y \neq w$. Since and $y \in U^c$ and $w \in B(x, \del)$ are arbitrary, $B(x, \del) \subset U$.
	\end{proof}
	
	\begin{defn}
	Let $X$ be a set, $(M, d)$ a metrix space and $B(S, M) = \{f: S \rightarrow M: f \text{ is bounded} \}$. We define the \textbf{supremum metric}, denoted $d_u:B(S,M) \times B(S,M) \rightarrow \Rg$, by $$d_u(f, g) = \sup_{x \in X}d(f(x), g(x)) $$ 
	\end{defn}
	
	\begin{defn}
	Let $(X, d)$ be a metric space. Define
	\begin{enumerate}
	\item $\Aut(X) = \{\sig:X \rightarrow X: \sig \text{ is a homeomorphism}\}$
	\item $\Aut(X, d) = \{\sig:X \rightarrow X: \sig \text{ is an isometric isomorphism}\}$
	\end{enumerate}
	\end{defn}
	
	\begin{ex}
	Let $(X, d)$ be a compact metric space, $E \subset X$ closed, $U \subset X$ open. Suppose that $E \subset U$. Let $(f_n)_{n \in \N} \in \Aut(X)$, $f \in \Aut(X)$.  Suppose that $f_n \convt{u} f$. Then there exists $N \in \N$ such that for each $n \geq N$, $f(E) \subset f_n(U)$.
	\end{ex}
	
	\begin{proof}
	Since $f$ is a homeomorphism, $E$ is closed and $U$ is open, $f(E)$ is compact and $f(U)$ is open and $f(E) \subset f(U)$. Then $d(f(E), f(U^c)) >0$. Put $\ep = d(f(E), f(U^c))$. Choose $\del = \ep/2$. Then there exists $N \in \N$ such that for each $n \in \N$, $n \geq N$ implies that $\sup\limits_{z \in X} d(f(z), f_n(z)) < \del$. Let $n \geq N$, $x \in E$ and $w \in B(f(x), \del)$. For the sake of contradiction, suppose that $w \in f_n(U^c)$. Then there exist $p \in U^c$ such that $w = f_n(p)$. Put $z = f(p) \in f(U^c)$. Then 
	\begin{align*}
	\ep 
	&\leq d(f(x), z) \\ 
	&\leq d(f(x), w) + d(w, z) \\
	& = d(f(x), w) + d(f_n(p), f(p))  \\
	& < \del + \del \\
	& = \ep
	\end{align*}
	which is a contradiction. So $w \in f_n(U)$. Hence $B(f(x), \del) \subset f_n(U)$
	\end{proof}
	
	
	
	
	
	
	
	
	
	
	
	
	\newpage
	\section{Topology}
	
	\begin{defn}
	Let $X$ be a topological space and $S,N \subset X$. Then $N$ is said to be a \textbf{neighborhood} of $S$ if there exists $U \subset X$ such that $U$ is open and $S \subset U \subset N$. For $S \in X$, we denote the set of neighborhoods of $S$ by $\MN_S$ 
	\end{defn}
	
	\begin{ex}
	Let $X$ be a topological space and $A \subset X$. Then $A$ is open iff for each $a \in A$, there exists $U_a \in \MN_a$ such that $U_a$ is an open of $a$ and $U_a \subset A$.
	\end{ex}
	
	\begin{proof}
	Suppose that $A$ is open. Let $a \in A$. Then $A \in \MN_a$, $A$ is an open and $A \subset A$. Conversely, suppose that or each $a \in A$, there exists $U_a \in \MN_a$ such that $U_a$ is open and $U_a \subset A$. Then $A = \bigcup\limits_{a \in A}U_a$ is open. 
	\end{proof}
	
	\begin{defn}
		Let $(X,\MA)$ and $(Y,\MB)$ be topological spaces and $f:X \rightarrow Y$. Then 
		\begin{enumerate}
			\item $f$ is said to be \textbf{continuous} if for each $B \in \MB$, $f^{-1}(B) \in \MA$.
			\item $f$ is said to be open if for each $A \in \MA$, $f(A) \in \MB$.
			\item $f$ is said to be \textbf{closed} if for each $A \subset X$, if $A^c \in \MA$, then $f(A)^c \in \MB$.
		\end{enumerate}
	\end{defn}
	
	\begin{ex}
		Let $X, Y$ be topological spaces and $\phi: X \rightarrow Y$ a homeomorphism. Then for each $A \subset X$, 
		\begin{enumerate}
			\item $\overline{\phi(A)} = \phi(\overline{A})$  \item $\phi(A)^{\circ} = \phi(A^{\circ})$  
		\end{enumerate} 
	\end{ex}
	
	\begin{proof}\
		\begin{enumerate}
			\item Let $A \subset X$. Since $A \subset \overline{A}$, we have that $\phi(A) \subset \phi(\overline{A})$. Since $\overline{A}$ is closed, $\phi(\overline{A})$ is closed and thus $\overline{\phi(A)} \subset \phi(\overline{A})$. Conversely, let $x \in \phi(\overline{A})$. Then $\phi^{-1}(x) \in \overline{A}$. Then there exists a net $\l y_{\al}\r \subset A$ such that $y_{\al} \rightarrow \phi^{-1}(x)$. Then $\l \phi(y_{\al}) \r \subset \phi(A)$ and $\phi(y_{\al}) \rightarrow x$. Thus $x \in \overline{\phi(A)}$ and $\phi(\overline{A}) \subset \overline{\phi(A)}$.
			\item Similar
		\end{enumerate} 
	\end{proof}
	
	
	
	\subsection{Semi-continuity}
	
	\begin{defn}
	Let $X$ be a topological space, $f: X \rightarrow \Ru$ and $x_0 \in X$. Then $f$ is said to be \textbf{lower semicontinuous (l.s.c.) at $x_0$} if $$\liminf_{x \rightarrow x_0}f(x) \geq f(x_0)$$ and $f$ is said to be \textbf{lower semicontinuous (l.s.c.)} if for each $x_0 \in X$, $f$ is lower semicontinuous at $x_0$. 
	\end{defn}
	
	\begin{ex}
	Let $X$ be a topological space and $f: X \rightarrow \Ru$. Then $f$ is \lsc iff for each $\al \in \R$, $f^{-1}((\al, \infty])$ is open. 
	\end{ex}
	
	\begin{proof}
	Suppose that $f$ is \lsc Let $\al \in \R$ and $x_0 \in f^{-1}(\al, \infty]$. Put $\ep = f(x_0) - \al$. By definition, $$\sup_{V \in N_{x_0}} \inf_{x \in V \setminus \{x_0\}} f(x) \geq f(x_0)$$ Choose $V_{\ep} \in N_{x_0}$ such that 
	\begin{align*}
	\inf_{x \in V_{\ep}} f(x)  
	&> f(x_0) - \ep \\
	&= \al
\end{align*}
Then $V_{\ep}^o \in \MN_{x_0}$ is open and 
	\begin{align*}
		V_{\ep}^o 
		& \subset V_{\ep} \\
		&\subset f^{-1}((\al, \infty])
	\end{align*} 
	So $f^{-1}((\al, \infty])$ is open. \\
	Conversely, suppose that for each $\al \in \R$, $f^{-1}((\al, \infty])$ is open. Let $x_0 \in X$. Put $\al = f(x_0)$. For $n \in \N$, define $V_n = f^{-1}((f(x_0)-1/n, \infty]) $. Then for each $n \in \N$, $V_n \in \MN_{x_0}$ and 
	\begin{align*}
	\liminf_{x \rightarrow x_0} f(x) 
	&= \sup_{V \in \MN_{x_0}} \inf_{x \in V \setminus \{x_0\}} f(x) \\
	& \geq \sup_{n \in \N} \inf_{x \in V_n \setminus \{x_0\}} f(x) \\
	& \geq \sup_{n \in \N} f(x_0)-1/n \\
	&= f(x_0) \\
	\end{align*}
	So $f$ is \lsc
	\end{proof}
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	\newpage
	\section{Banach Spaces}
	\subsection{Introduction}
	\begin{note}
		In the following, we will consider vector spaces over $\C$. There are analogous results for real vector spaces as well, just replace every $\C$ with $\R$.
	\end{note}
	
	\begin{defn}
		Let $X$ be a normed vector space. Then $X$ is said to be a \textbf{Banach space} if $X$ is complete.  
	\end{defn}
	
	\begin{defn}
		Let $X$ be a normed vector space and $(x_i)_{i=1}^n \subset X$. The series $\sum_{i =1}^{\infty}x_i$ is said to \textbf{converge} if the sequence $s_n := \sum_{i=1}^n x_i$ converges. The series $\sum_{i =1}^{\infty}x_i$ is said to \textbf{converge absolutely} if $\sum_{i\in \N}\|x_i \|< \infty$.
	\end{defn}
	
	\begin{ex}
		Let $X$ be a normed vector space. Then $X$ is complete iff for each $\seq{x}{i} \subset X$, $\sum_{i =1}^{\infty}x_i$ converges absolutely implies that $\sum_{i=1}^{\infty}x_i$ converges. \\
		\textbf{Hint:} Given a Cauchy sequence $(x_n)_{n \in \N}$, obtain a subsequence $(x_{n_j})_{j \in \N} \subset (x_n)_{n \in \N}$ such that for each $j \in \N$, $\|x_{n_{j+1}} - x_{n_{j}}\| < 2^{-j}$. Define a new sequence $(y_j)_{j \in \N} \subset X$ by 
		\[
		y_j = 
		\begin{cases}
		x_{n_1} & j =1 \\  
		x_{n_j} - x_{n_{j-1}} & j \geq 2	
		\end{cases}
		\] 
	\end{ex}
	
	\begin{proof}
		Suppose that $X$ is complete. Let $\seq{x}{i} \subset X$. Suppose that $\sum_{i=1}^{\infty}x_i$ converges absolutely. Let $\ep >0$. Choose $N \in \N$ such that for each $m,n \in \N$, if $m, n \geq N$ and $m< n$, then $\sum_{m+1}^n \|x_i \|< \ep$. Let $m, n \in \N$. Suppose that $m<n$. Then 
		\begin{align*}
			\|s_n-s_m \|
			&= \bigg \|\sum_{i=1}^n x_i -\sum_{i=1}^m x_i\bigg \|\\
			&= \bigg\|\sum_{i=m+1}^{n} x_i \bigg \| \\
			& \leq \sum_{i=m+1}^n \|x_i \|\\
			& < \ep
		\end{align*}
		
		Thus $(s_n)_{n \in N}$ is Cauchy. Since $X$ is complete, $\sum_{i=1}^{\infty}x_i$ converges. \\
		Conversely, Suppose that for each $\seq{x}{i} \subset X$, $\sum_{i =1}^{\infty}x_i$ converges absolutely implies that $\sum_{i=1}^{\infty}x_i$ converges. Let $\seq{x}{i} \subset X$ be Cauchy. Proceed inductively to create a strictly increasing sequence $(n_i)_{i \in \N} \subset \N$ such that for each $m, n \in \N$, if $m,n \geq n_i$, then $ \|x_m-x_n \|< 2^{-i}$. Define $(y_i)_{i \in \N} \subset X$ by 
		\[ y_i = \begin{cases}
			x_{n_1} & i=1 \\
			x_{n_i} - x_{n_{i-1}} & i \geq 2\\
		\end{cases}\]
		
		Then $\sum_{i=1}^k y_i = x_{n_k}$ and 
		\begin{align*}
			\sum_{i \in \N} \|y_i \|
			&= \|x_{n_1} \|+ \sum_{i \in \N} \|x_{n_i}-x_{n_{i-1}} \|\\
			& \leq \|x_{n_1} \|+ 2\sum_{i \in \N}2^{-i}\\
			& = \|x_{n_1} \|+2
		\end{align*}
		Hence $(x_{n_k})_{k \in \N} = (\sum_{i=1}^k y_i)_{i\in \N}$ converges. Since $(x_i)_{i \in \N}$ is cauchy and has a convergent subsequence, it converges. So $X$ is complete.
	\end{proof}
	\newpage
	
	\subsection{Linear Maps}
	
	\begin{defn}
		Let $X,Y$ be a normed vector spaces. A linear map $T:X \rightarrow Y$ is said to be \textbf{bounded} if there exists $C \geq 0$ such that for each $x \in X$, $$\|Tx \|\leq C \|x \|$$ We define $$L(X,Y) = \{T:X \rightarrow Y: T \text{ is linear and bounded}\}$$
		When $X=Y$, we write $L(X)$.
	\end{defn}
	
	\begin{ex}
		Let $X,Y$ be a normed vector spaces and $T:X \rightarrow Y$ a linear map. Then $T$ is bounded iff there exists $r,s>0$ such that $T(B(0,r)) \subset B(0,s)$
	\end{ex}
	
	\begin{proof}
		Suppose that $T$ is bounded. Then there exists $C \geq 0$ such that for each $x \in X$, $\|Tx \|\leq C \|x \|$. Thus $T(B(0,1)) \subset B(0,C+1)$. Conversely. Suppose that there exists $r,s >0$ such that $T(B(0,r)) \subset B(0,s)$. Define $C = \frac{2s}{r}$. Let $x \in X$. Put $\al = \frac{r}{2\|x \|}$ Then $\al x \in B(0,r)$. So $T(\al x ) = \al T(x) \in B(0,s)$. Hence 
		\begin{align*}
			\|T(\al x) \|
			&= \|\al T(x) \|\\
			&= \vert \al \vert \|T(x) \|\\
			& = \frac{r}{2 \|x \|}  \|T(x) \|\\
			& < s.
		\end{align*}
		Thus $$\|Tx \|< \frac{2 s}{r} \|x \|= C \|x \|$$ So $T$ is bounded. 
	\end{proof}
	
	\begin{ex}
		Let $X,Y$ be normed vector spaces and $T:X \rightarrow Y$ a linear map. Then the following are equivalent:
		\begin{enumerate}
			\item $T$ is continuous
			\item $T$ is continuous at $x=0$
			\item $T$ is bounded
		\end{enumerate}
	\end{ex}
	
	\begin{proof}\
		\begin{itemize}
		\item $(1) \implies (2)$:\\
		Trivial
		\item $(2) \implies (3)$:\\
		Suppose that $T$ is continuous at $x=0$. Then there exists $\del>0$ such that for each $x \in X$, if $\|x \|< \del$, then $\|Tx \|< 1$. Choose $C = \frac{2}{\del}$. If $x=0$, then $\|Tx \|\leq C \|x \|$. Suppose that $\|x \|\neq 0$. Define $y = \frac{\del}{2 \|x \|}x$. Then $\|y \|< \del$. So 
		\begin{align*}
		1 
		&> \|Ty \|\\
		&= \frac{\del}{2 \|x \|} \|Tx \|
		\end{align*}
		Thus 
		\begin{align*}
			\|Tx \|
			&< \frac{2}{\del} \|x \| \\
			&=C \|x \|
		\end{align*}
		
		Hence $T$ is bounded.
		\item $(3) \implies (1)$\\
		Suppose that $T$ is bounded. Then there exists $C \geq 0$ such that for each $x \in X$, $\|Tx \|\leq C\|x \|$. Let $\ep >0$. Choose $\del = \frac{\ep}{C+1}$. Let $x,y \in X$ Suppose that $\|x-y \|< \del$. Then 
		\begin{align*}
			\|Tx-Ty \|
			& = \|T(x-y) \| \\
			& \leq C \|x-y \|\\
			&< (C+1) \del\\ 
			&= \ep
		\end{align*}
		
		So $T$ is continuous.
		\end{itemize}
	\end{proof}
	
	\begin{defn}
		Let $X,Y$ be normed vector spaces. Define $\|\cdot\|: L(X,Y)\rightarrow \Rg$ by $$\|T\| = \inf \{C \geq 0: \text{for each }x \in X\text{, } \|Tx \|\leq C\|x\|\}$$ We call $\|\cdot \|$ the \textbf{operator norm on $L(X,Y)$}
	\end{defn}
	
	\begin{ex}
		Let $X,Y$ be normed vector spaces. If $X\neq \{0\}$, then the operater norm on $L(X,Y)$ is given by: 
		\begin{enumerate}
			\item $\|T\| = \sup\limits_{\|x\|=1}\|Tx\|$
			\item $\|T\| = \sup\limits_{x \neq 0}\|x\|^{-1} \|Tx\|$
			\item $\|T\| = \inf \{C \geq 0: \text{for each }x \in X\text{, } \|Tx \|\leq C\|x\|\}$
		\end{enumerate}
	\end{ex}
	
	\begin{proof} Since $X \neq \{0\}$, the supremums in (1) and (2) are well defined. Let $T \in L(X,Y)$. By linearity of $T$, the sets over which the supremums are taken in (1) and (2) are the same. So (1) and (2) are equal.\vspace{1cm}\\
		
		Now, put $M = \sup\limits_{\|x \|=1} \|Tx \|$, $m = \inf \{C \geq 0: \text{ for each }x \in X\text{, } \|Tx \|\leq C \|x \|\}$ and let $x \in X$. If $\|x \|=0$, then $\|Tx \|\leq M \|x \|$. Suppose that $\|x \|\neq 0$. Then 
		\begin{align*}
			\|Tx \|
			&= \bigg(\big\|T(x/\|x\|)\big\|\bigg)\|x \|\\
			& \leq M ||x||
		\end{align*}
		
		Hence $M \in \{C \geq 0: \text{ for each }x \in X\text{, } \|Tx \|\leq C \|x \|\}$. Therefore $m \leq M$
		
		Let $C \in \{C \geq 0: \text{ for each }x \in X\text{, } \|Tx \|\leq C \|x\|\}$. Suppose that $\|x \|=1$. Then $\Vert Tx\Vert \leq C \|x \|= C$. So $M \leq C$. Therefore $M \leq m$. So $M=m$ and the supremum in (1) is the same as the infimum in (3). 
	\end{proof}
	
	\begin{note}
		From here on, unless stated otherwise, we assume $X \neq 0$.
	\end{note}
	
	\begin{ex}
		Let $X,Y$ be normed vector spaces and $T \in L(X,Y)$. Then for each $x \in X$, $\|Tx \| \leq \|T\|\|x \|$
	\end{ex}
	
	\begin{proof}
		This is just part of the previous exercise. Let $x \in X$. If $x = 0$, then $\|Tx \|\leq \|T \|\|x \|$. Suppose that $x \neq 0$. Then $\|Tx \|= T(x/\|x\|)\|x\|\leq \|T \|\|x \|$
	\end{proof}
	
	\begin{ex}
		Let $X, Y$ be normed vector spaces. Then the operator norm is a norm on $L(X,Y)$.
	\end{ex}
	
	\begin{proof}
		Let $S,T \in L(X,Y)$ and $\al \in \C$. For each $x \in X$, we have that 
		\begin{align*}
			\|(S+T)x \|
			&= \|Sx+Tx \|\\
			& \leq \|Sx \|+ \|Tx \|\\
			&\leq \|S \|\|x \|+ \|T \|\|x \|\\
			&= \big(\|S \|+ \|T \|\big) \|x \|
		\end{align*}
		
		So $\|S+T \|\leq \|S \|+ \|T \|$.\vspace{1cm}\\
		
		Using the definition of $\|T \|$, we see that 
		\begin{align*}
			\|\al T \|
			&= \sup_{\|x \|=1} \|(\al T)x \|\\
			&= \sup_{\|x \|=1} \vert \al \vert \|Tx \|\\
			&=\vert \al \vert \sup_{\|x \|=1} \|Tx \|\\
			&=\vert \al \vert \|T \|
		\end{align*} 
		So $\|\al S \|= \vert \al \vert \|S \|$. \vspace{1cm}\\ Suppose that $\|T \|= 0$. Let $x \in X$. Then $\|T x\|\leq \|T \|\|x \|= 0$. So $Tx=0$. Since $x \in X$ is arbitrary, we have that $T=0$. 
	\end{proof}
	
	\begin{ex}
		Let $X,Y,Z$ be normed vector spaces, $T \in L(X,Y)$ and $S \in L(Y,Z)$. Define $ST:X \rightarrow Z$ by $STx = S(Tx)$. Then $ST \in L(X,Z)$ and $\|ST \|\leq \|S \|\|T \|$. 
	\end{ex}
	
	\begin{proof}
		Clearly $ST$ is linear. Let $x \in X$. Then 
		\begin{align*}
			\|ST x \|
			& = \|S(Tx) \|\\
			& \leq \|S \|\|Tx \|\\
			& \leq \|S \|\|T \|\|x \|
		\end{align*}
		
		So $\|ST \|\leq \|S \|\|T \|$.
	\end{proof}
	
	\begin{defn}
		Let $X,Y$ be a normed vector spaces and $T \in L(X,Y)$. Then $T$ is said to be \textbf{invertible} or an \textbf{isomorphism} if $T$ is a bijection and $T^{-1} \in L(Y,X)$.
	\end{defn}
	
	\begin{defn}
		Let $X$ be a normed vector space. Define $GL(X) := \{T \in L(X,X): T \text{ is invertible}\}$.
	\end{defn}
	
	\begin{ex}
		Let $X$ be a normed vector space. Then addition and scalar multiplication are continuous on $X \times X$ and $\|\cdot \|:X \rightarrow \Rg$ is continuous.
	\end{ex}
	
	\begin{proof}
		Let $\ep > 0$. Choose $\del = \frac{\ep}{2}$. Let $(x_1,y_1), (x_2,y_2) \in X \times X$. Suppose that $\|(x_1,y_1)-(x_2,y_2) \| = \max\{\|x_1-x_2 \|, \|y_1 - y_2 \|\} < \del$. Then 
		\begin{align*}
			\|(x_1 + y_1) - (x_2+y_2) \|
			&= \|(x_1-x_2) + (y_1-y_2) \|\\
			& \leq \| x_1-x_2 \|+ \|y_1-y_2 \|\\
			& < 2\del \\
			&= \ep
		\end{align*} 
		Hence addition is uniformly continuous. \vspace{1cm}\\ Let $(\lam_1,x_1) \in \C \times X$ and $\ep >0$. Choose $\del = \min\{\frac{\ep}{2(\vert \lam_1 \vert + \|x_1 \|+ 1)}, \frac{\sqrt{\ep}}{\sqrt{2}}\}$. Let $(\lam_2, x_2) \in \C \times X$. Suppose that $\|(\lam_1, x_1)-(\lam_2,x_2) \| = \max\{\vert \lam_1-\lam_2 \vert , \|x_1 - x_2 \|\} < \del$. Then 
		\begin{align*}
			\|\lam_1x_1 - \lam_2x_2 \|
			&= \|\lam_1x_1 - \lam_1x_2 + \lam_1x_2- \lam_2x_2 \|\\
			&= \|\lam_1(x_1-x_2) + (\lam_1-\lam_2)x_2 \|\\
			& \leq \vert \lam_1 \vert \| x_1-x_2 \|+ \vert \lam_1-\lam_2 \vert \|x_2\|\\
			& \leq \vert \lam_1 \vert  \| x_1-x_2 \|+ \vert \lam_1-\lam_2 \vert (\|x_1 -x_2\|+ \|x_1\|)\\
			& < \vert \lam_1 \vert \del  +  \del( \del + \|x_1 \|)\\
			&= (\vert \lam_1 \vert + \|x_1 \|) \del + \del^2 \\
			&< \frac{\ep}{2}+ \frac{\ep}{2}\\
			&= \ep
		\end{align*}
		Since $(\lam_1, x_1) \in \C \times X$ is arbitrary, scalar multiplication is continuous. \vspace{1cm} \\ Let $\ep > 0$. Choose $\del = \ep$. Let $x,y \in X$. Suppose that $\|x-y \|< \del$. Then 
		\begin{align*}
			\big \vert \|x \|- \|y \|\big  \vert
			& \leq \|x - y \|\\
			&< \del\\
			&=\ep
		\end{align*}  
		So $\|\cdot \|: X \rightarrow \Rg$ is uniformly continuous.
	\end{proof}
	
	\begin{ex}
		Let $X,Y$ be normed vector spaces. If $Y$ is complete, then so is $L(X,Y)$.
	\end{ex}
	
	\begin{proof}
		Suppose that $Y$ is complete. Let $(T_n)_{n \in \N} \subset L(X,Y)$. Suppose that $(T_n)_{n \in \N}$ is Cauchy. Since for each $m,n \in \N$, $\big\vert \|T_m \|- \|T_n \|\big\vert \leq \|T_m -T_n \|$, we have that $(\|T_n \|)_{n \in \N} \subset \Rg$ is Cauchy. Hence $\lim\limits_{n \rightarrow \infty}\|T_n \|$ exists. \vspace{1cm} \\ Let $x \in X$ and $m,n \in \N$. Then 
		\begin{align*}
			\|T_m x - T_n x \|
			&= \|(T_m-T_n) x \|\\
			&\leq \|T_m-T_n \|\|x \|
		\end{align*}
		So $(T_nx)_{n \in \N} \subset Y$ is Cauchy and hence converges. Define $T:X \rightarrow Y$ by $Tx = \lim\limits_{n \rightarrow \infty} T_nx$. \vspace{1cm}\\
		Since addition and scalar multiplication are continuous, $T$ is linear. Let $x \in X$ and $\ep>0$. Choose $N \in \N$ such that for each $n \in N$, if $n \geq N$, then $\|Tx - T_n x\|< \ep$. Then for each $n \in \N$, if $n \geq N$ we have that 
		\begin{align*}
			\|Tx\|
			&\leq \|Tx-T_nx \|+ \|T_nx \|\\
			&< \ep + \|T_nx \|\\
			&\leq \ep + \|T_n \|\|x \|
		\end{align*}  
		Thus $\|Tx \|\leq \ep +(\lim\limits_{n \rightarrow \infty} \|T_n \|) \|x \|$. Since $\ep >0$ is arbitrary, $\|Tx \|\leq (\lim\limits_{n \rightarrow \infty} \|T_n \|) \|x \|$. Thus $T \in L(X,Y)$ and $\|T \|\leq \limn \|T_n \|$. \vspace{1cm} \\
		Note that since addition, scalar multiplication and $\|\cdot \|$ are continuous, we have that for each $n \in \N$ and $x \in X$, $\|(T_n-T_m)x \|$ converges to $\|(T_n-T)x \|$ because 
		\begin{align*}
			\lim_{m \rightarrow \infty} \|(T_n-T_m)x \|
			&= \lim_{m \rightarrow \infty} \|T_nx-T_mx \|\\
			&= \|T_nx-\lim_{m \rightarrow \infty}T_mx \|\\
			&=\|T_nx-Tx \|\\
			&= \|(T_n-T)x \|
		\end{align*} 
		Let $\ep >0 $. Choose $N \in \N$ such that for each $m, n \in \N$ if $n,m \geq N$, then $\|T_n - T_m \|< \ep$. Then for each $n \in \N$ if $n \geq N$, then for each $x \in X$, $$\|(T_n-T_m)x\|\leq \|(T_n-T_m)\|\|x \|< \ep \|x\|$$ Combining this with the previous fact, we see that for each $n \in N$, if $n \geq N$, then for each $x \in X$, $$\|(T_n -T) x\|\leq \ep \|x \|$$ In particular, for each $n \in \N$, if $n \geq N$, then $$ \|T_n -T \|= \sup\limits_{\|x \|= 1}\|(T_n - T)x \|\leq \ep$$ This implies that $T_n$ converges to $T$ in $L(X,Y)$. 
		Since $$\big\vert \|T_n \|- \|T \|\big \vert \leq \|T_n - T \|$$ it is clear that $\limn \|T_n \|= \|T \|$
	\end{proof}
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	\newpage
	\subsection{Multilinear Maps}	
	\begin{defn}
	Let $X_1, \cdots, X_n, Y$ be normed vector spaces and $T: \prod\limits_{i=1}^n X_i \rightarrow Y$ multilinear. Then $T$ is said to be \textbf{bounded} if there exists $C \geq 0$ such that for each $x_1, \cdots, x_n \in X$, $$\|T(x_1, \cdots, x_n)\| \leq C \|x_1\| \cdots \|x_n\|$$
	We define $$L^n (X_1, \dots, X_n; Y) = \bigg\{T: \prod\limits_{i=1}^n X_i \rightarrow Y: T \text{ is multilinear and bounded}\bigg \}$$ 
	If $X_1 = \cdots = X_n = X$, we write $L^n(X,Y)$ in place of $L^n (X, \dots, X; Y) $. If $X_1 = \cdots = X_n = Y =  X$, we write $L^n(X)$.
	\end{defn}
	
	\begin{ex}
	Let $X_1, X_2, Y$ be normed vector spaces and $T_1 \in L(X_1, L(X_2, Y))$. Define $T:X_1 \times X_2 \rightarrow Y$ by $T(x_1, x_2) = T_1(x_1)(x_2)$. Then $T \in L^2(X_1, X_2; Y)$.  
	\end{ex}
	
	\begin{proof}
	It is straightforward to show that $T$ is multilinear. For $x_1 \in X_1$ and $x_2 \in X_2$, 
	\begin{align*}
	\|T(x_1, x_2)\| 
	&= \|T_1(x_1)(x_2)\| \\
	& \leq \|T_1(x_1)\| \|x_2\| \\
	& \leq \|T_1\| \|x_1\| \|x_2\|
	\end{align*}
	So $T \in L^2(X_1, X_2;Y)$.
	\end{proof}
	
	\begin{ex}
	Let $X_1, X_2, Y$ be normed vector spaces and $T \in L^2(X_1, X_2; Y)$. Define the map $T_1 : X_1 \rightarrow  Y^{X_2}$ by  $T_1(x_1)(\cdot) = T(x_1, \cdot)$. Then $T_1 \in L(X_1, L(X_2, Y))$.
	\end{ex}
	
	\begin{proof}
	Let $x_1 \in X_1$. By definition, $T_1(x_1)$ is linear. Since $T$ is bounded, there exists $C \geq 0$ such that for each $a_1 \in X_1$, $a_2 \in X_2$, $T(a_1, a_2) \leq C\|a_1\| \|a_2\|$. Then for each $x_2 \in X_2$,
	\begin{align*}
	\| T_1(x_1)(x_2) \|
	&= \|T(x_1, x_2) \| \\
	&\leq (C\|x_1\|) \|x_2\| 
	\end{align*}
	So $T_1(x_1) \in L(X_2,Y)$ with $\|T_1(x_1)\| \leq C\|x_1\|$. Since $x_1 \in X_1$ was arbitrary, $T_1: X_1 \rightarrow L(X,Y)$. By definition, $T_1$ is linear. The preceeding argument tells us that for each $x_1 \in X_1$, $$\|T_1(x_1)\| \leq C\|x_1\|$$ 
	So $T_1 \in L(X_1, L(X_2, Y))$ with $\|T_1\| \leq C$.  
	\end{proof}		
	
	\begin{ex}
	Let $X_1, \cdots, X_n, Y$ be normed vector spaces and $T: \prod\limits_{i=1}^n X_i \rightarrow Y$ multilinear. Then the following are equivalent:
	\begin{enumerate}
			\item $T$ is continuous
			\item $T$ is continuous at $x=(0, \ldots, 0)$
			\item $T$ is bounded
		\end{enumerate}
	\end{ex}
	
	\begin{proof}\
		\begin{itemize}
		\item $(1) \implies (2)$:\\
		Trivial
		\item $(2) \implies (3)$:\\ Suppose that $T$ is continuous at $x = (0, \ldots, 0)$. Let $(x_1, \ldots, x_n) \in \prod_{j=1}^nX_j$. Then $T(x_1, \ldots, x_{n-1}, \cdot) \in L(X_n, Y)$. Hence there exists $C_n \geq 0$ such that for each $a_n \in X_n$, $T(x_1, \ldots, x_{n-1}, a_n) \leq C_n\|x_n\|$. Continuing inductively, there exist $C_1, \ldots, C_{n-1}$ such that  
		
		\end{itemize}
		
	\end{proof}
	
	
	\begin{defn}
	Let $X_1, \cdots, X_n, Y$ be normed vector spaces
	\end{defn}
	
	
	\begin{ex}
	Let $X_1, \cdots, X_n, Y$ be normed vector spaces. Define a map $\phi: L^2(X_1, X_2;Y) \rightarrow L(X_1, L(X_2, Y))$ by $\phi(T)(x_1)(x_2) = T(x_1, x_2)$. Then $T$ is an isometric isomorphism.
	\end{ex}
	
	\begin{proof}
	. 
	\end{proof}
	
	
	\newpage
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	\subsection{Quotient Spaces}	
	
	\begin{defn}
		Let $X$ be a normed vector space and $M \subset X$ a closed subspace. Define $\|\cdot\|:X/M \rightarrow \Rg$ by $$\|x+M\| := \inf_{y \in M}\|x+y\|$$
		
		We call $\|\cdot\|$ the \textbf{subspace norm on $X/M$}
	\end{defn}
	
	\begin{ex}
		Let $X$ be a normed vector space and $M \subsetneq X$ a proper, closed subspace of $M$. 
		Then 
		\begin{enumerate}
			\item The previously defined subspace norm on $X/M$ is well defined and is a norm. 
			\item For each $\ep > 0$, there exists $x \in X$ such that $\|x\|=1$ and $\|x+M\| \geq 1-\ep$.
			\item The projection map $\pi:X \rightarrow X/M$ defined by $\pi(x) = x+M$ is continuous and $\|\pi\|=1$. 
			\item If $X$ is complete, then $X/M$ is complete. 
		\end{enumerate} 
	\end{ex}
	
	\begin{proof}\
		\begin{enumerate}
			\item  Let $x, y \in X$ and $\al \in \C$. Suppose that $x+M =y+M$. Then there exists $m \in M$ such that $x=y+m$. Since $M$ is a subspace, the map $T:M \rightarrow M$ given by $Tx = x+m$ is a bijection. So $$\inf_{z \in M} \|y+m+z \|= \inf_{z \in M} \|y+z \|$$ which implies that 
			\begin{align*}
				\|x +M \|
				&= \inf_{z \in M} \|x+z \|\\
				&= \inf_{z \in M} \|y+m+z \|\\
				&= \inf_{z \in M} \|y+z \|\\
				&= \|y+M \|
			\end{align*} 
			So $\|\cdot \|: X/M \rightarrow \Rg$ is well defined.\vspace{.5cm}\\
			We observe that for each $z,w \in M$, $$\|x+y+z \|\leq \|x+w \|+ \|y+w+z \|$$
			Taking infimums over $M$ with respect to $z$ in this inequality implies that for each $w \in M$,
			\begin{align*}
				\inf_{z \in M}\|x+y+z \|
				&\leq \inf_{z \in M} \bigg( \|x+w \|+ \|y+w+z \|\bigg) \\
				&= \|x+w \|+\inf_{z \in M}\|y+w+z \|
			\end{align*}
			Again we use the fact that for each $w \in M$, $$\inf_{z \in M}\|y+w+z \|= \inf_{z \in M}\|y+z \|$$
			This implies that for each $w \in M$, $$\inf_{z \in M}\|x+y+z \|\leq \|x+w \|+ \inf_{z \in M}\|y+z \|$$
			
			Therefore, taking infimums over $M$ with respect to $w$ in this inequality yields
			\begin{align*}
				\|x+y+M \|
				&= \inf_{z \in M} \|x+y +z \|\\
				& \leq \inf_{w \in M} \bigg(\|x+w \|+ \inf_{z \in M}\|y+z \|\bigg)\\
				&= \inf_{w \in M} \|x+w \|+ \inf_{z \in M}\|y+z \|\\
				&= \|x+M \|+ \|y+M \|
			\end{align*}
			\vspace{.5cm}\\
			If $\al =0$, then $\al x = 0$. Choosing $z = 0 \in M$ gives $\|\al x+M \|=0 = \vert \al \vert \|x+M \|$. Suppose that $\al \neq 0$. Then the map $T:M \rightarrow M$ given by $Tx = \al ^{-1}x$ is a bijection and thus $\inf\limits_{z \in M} \|x+\al^{-1}z \|= \inf\limits_{z \in M} \|x+z \|$. Hence we have that
			\begin{align*}
				\|\al x+M \|
				&= \inf_{z \in M} \|\al x +z \|\\
				&= \inf_{z \in M} \vert \al \vert \|x +\al^{-1}z \|\\
				&= \vert \al \vert \inf_{z \in M}\|x +\al^{-1}z \|\\
				&= \vert \al \vert \inf_{z \in M}\|x +z \|\\
				&= \vert \al \vert \|x+M \|
			\end{align*} 
			
			Suppose that $\|x \|=0$. Choose a sequence $(z_n)_{n \in N} \subset M$ such that 
			\begin{align*}
				\lim\limits_{n \rightarrow \infty} \|x - z_n \|
				& = \inf_{z \in M} \|x+ z \|\\
				& = 0
			\end{align*} 
			
			Then $\limn z_n =x$. Since $M$ is closed, $x \in M$. Hence $x+M=0+M$. \vspace{1cm}\\
			\item Since $M$ is a proper subspace, there exists $v \in X$ such that $v \not \in M$. Then $\|v +M \|\neq 0$. Let $\ep >0$. Then $(1-\ep)^{-1}\|v+M \|> \|v+M \|$. So there exists $z \in M$ such that $$0< \|v+M\|\leq \|v+z \|< (1-\ep)^{-1} \|v+M \|$$ Choose $x = \|v+z \|^{-1}(v+z)$. Then $\|x \|=1$ and 
			\begin{align*}
				\|x+M \|
				&= \|v+z \|^{-1} \|v+z +M \|\\
				&= \|v+z \|^{-1} \|v +M \|\\
				&> 1-\ep
			\end{align*}\vspace{.5cm}\\
			\item Let $x \in X$. Taking $z=0$, we we see that $\|\pi(x) \|=\|x+M \|\leq \|x+z \|= \|x \|$. So $\pi$ is bounded and in particular, $$\sup_{\|x \|=1} \|\pi(x) \|\leq 1$$ 
			From (2) we see that $$\sup_{\|x \|=1} \|\pi(x) \|\geq 1$$
			Hence $\|\pi\|= 1$. \vspace{.5cm}\\
			\item Suppose that $X$ is complete. Let $(x_i+M)_{i\in \N} \subset X/M$. Suppose that $\sum\limits_{i\in \N} \|x_i+M \|< \infty$. Let $\ep>0$. Then for each $i \in \N$, there exists $z_i \in M$ such that $\|x_i +z_i \|< \|x_i +M \|+ \ep2^{-i}$. Define the sequence $(a_i)_{i\in \N} \subset X$ by $a_i = x_i +z_i$. Then we have 
			\begin{align*}
				\sum_{i\in \N} \|a_i \|
				&= \sum_{i \in N} \|x_i + z_i \|\\
				&\leq \sum_{i \in N} \bigg (\|x_i +M \|+ \ep2^{-i} \bigg)\\
				&= \sum_{i\in \N} \|x_i+M\|+ \ep
			\end{align*}
			Since $\ep>0$ is arbitrary, it follows that $$\sum_{i\in \N} \|a_i \|\leq \sum_{i\in \N} \|x_i+M\|< \infty$$
			Since $X$ is complete, $\sum\limits_{i=1}^{\infty}a_i$ converges in $X$. Define $(s_n)_{n \in \N} \subset X$ and $s \in X$ by $s_n = \sum\limits_{i =1}^n a_i$ and $s = \sum\limits_{i=1}^\infty a_i $. Since $\limn s_n = s$, and $\pi: X \rightarrow X/M$ is continuous, it follows that $\limn \pi(s_n) = \pi(s)$. Since 
			\begin{align*}
				\pi(s_n) 
				&= \sum_{i=1}^n a_i +M\\
				&= \sum_{i=1}^n x_i +M
			\end{align*} 
			We have that $\sum\limits_{i=1}^{\infty}x_i +M$ converges which implies that $X/M$ is complete.
		\end{enumerate}
	\end{proof}
	
	\begin{ex}
		Let $X,Y$ be normed vector spaces and $T \in L(X,Y)$. Then
		\begin{enumerate}
			\item $\ker T$ is closed
			\item there exists a unique map $S :X/ \ker T \rightarrow T(X)$ such that $T = S \circ \pi$. Furthermore $S$ is a bounded linear bijection and $\|S \|= \|T \|$.
		\end{enumerate}
	\end{ex}
	
	\begin{proof}
		\begin{enumerate}
			\item Since $T$ is continuous and $\ker T = T^{-1}(\{0\})$, we have that $\ker T$ is closed.
			\item Suppose that there exists $S_1,S_2 \in L(X/ \ker T, T(X)) $ such that $T = S_1 \circ \pi$ and  $T = S_2 \circ \pi $. Let $x \in X$. Then $$S_1(x + \ker T) = S_1(\pi(x)) = T(x) = S_2(\pi(x)) = S_2(x + \ker T)$$ So $S_1 = S_2$. Therefore such a map is unique.\\
			Define $S: X / \ker T \rightarrow T(X)$ by $S(x+ \ker T) = T(x)$. Then $S$ is clearly a linear bijection that satisfies $T = S \circ \pi$. Let $x \in X$ and $z \in \ker T$. Then 
			\begin{align*}
				\|S(x+ \ker T) \|
				& = \|T(x) \|\\
				& = \|T(x+z) \|\\
				& \leq \|T \|\|x+ z \|
			\end{align*} 
			Thus $$\|S(x+ \ker T) \|\leq \|T \|\inf_{z \in \ker T}  \|x + z \|= \|T \|\|x + \ker T \|$$
			So $S$ is bounded and $\|S \|\leq \|T \|$. This implies that $$\|T \|= \|S \circ \pi \|\leq \|S \|\|\pi \|= \|S \|$$
			Thus $\|S \|= \|T \|$.
		\end{enumerate}
	\end{proof}
	
	\begin{ex}
		Let $X, Y$ be normed vector spaces. Define $\phi: L(X,Y) \times X \rightarrow Y$ by \\$\phi(T,x) = Tx$. Then $\phi$ is continuous.
	\end{ex}
	
	\begin{proof}
		Let $(T_1, x_1) \in L(X,Y) \times X$ and $\ep > 0$. Choose $\del = \min \{\frac{\ep}{2(\|x_1 \|+ \|T_1 \|+1)}, \frac{\sqrt{\ep}}{\sqrt{2}} \}$. Let $(t_2, x_2) \in L(X,Y) \times X$. Suppose that $$\|(T_1, x_1) - (T_2, x_2) \|= \max \{\|T_1 - T_2\|, \|x_1 -x_2 \|\} < \del$$ Then 
		\begin{align*}
			\|\phi(T_1, x_1) - \phi(T_2-x_2) \|
			&= \|T_1 x_ - T_2 x_2 \|\\
			&= \|T_1 x_1 - T_2 x_1 + T_2 x_1 - T_2 x_2 \|\\
			& \leq \|(T_1 - T_2) x_1 \|+ \|T_2(x_1 -x_2) \|\\
			& \leq \|T_1 -T_2 \|\|x_1 \|+ \|T_2 \|\|x_1 -x_2 \|\\
			& \leq \|T_1 -T_2 \|\|x_1 \|+ \big(\|T_1 - T_2 \|+ \|T_1 \|\big)\|x_1 -x_2 \|\\
			& < \del \|x_1 \|+ (\del + \|T_1 \|) \del \\
			&= \del (\|T_1 \|+ \|x_1 \|) + \del^2\\
			& < \frac{\ep}{2} + \frac{\ep}{2}\\
			&= \ep
		\end{align*}
		So $\phi$ is continuous.
	\end{proof}
	
	\begin{ex}
		Let $X$ be a normed vector space and $M \subset X$ a subspace. Then $\overline{M}$ is a subspace.
	\end{ex}
	
	\begin{proof}
		Let $x,y \in \overline{M}$ and $\al \in \C$. Then there exist sequences $(x_n)_{n \in \N} \subset M$ and $(y_n)_{n \in \N} \subset M$ such that $x_n \conv{} x$ and $y_n \conv{} y$. Since $M$ is a subspace, $(x_n +y_n)_{n \in \N} \subset M$ and $(\al x_n)_{n \in \N} \subset M$. Since addition and scalar multiplication are continuous, we have that $x_n + y_n \conv{} x+y$ and $\al x_n \conv{} \al x$. Thus $x+y \in \overline{M}$ and $\al x \in \overline{M}$ and hence $\overline{M}$ is a subspace.
	\end{proof}
	
	\newpage
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	\subsection{Direct Sums}
	
	\begin{defn}
	Let $X_1, \cdots, X_n$ be Banach spaces and $p \in [1, \infty]$. We define $\| \cdot \|_p : \bigoplus\limits_{j=1}^n X_j \rightarrow \Rg$ by $$\|(x_j)_{j=1}^n\|_p = \|(\|x_j\|)_{j=1}^n \|_{\R^n, p}$$
	\end{defn}
	
	\begin{ex}	
	Let $X_1, \cdots, X_n$ be Banach spaces. Then 
	\begin{enumerate}
	\item for each $p \in [1, \infty]$, $\|\cdot\|_p:\bigoplus\limits_{j=1}^n X_j \rightarrow \Rg$ is a norm on $\bigoplus\limits_{j=1}^n X_j$
	\item  $\{\|\cdot \|_p:  p \in [1, \infty]\}$ are equivalent. 
	\end{enumerate}
	\end{ex}
	
	\begin{proof}\
	\begin{enumerate}
	\item Let $p \in [1, \infty]$.
	\item 
	\end{enumerate}
\end{proof}		


	
	
	










	\newpage
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	

	

	
	\subsection{The Hahn-Banach Theorem}
	
	\begin{defn}\
		\begin{itemize}
		\item Let $X$ be a vector space over $\C$ and $T :X \rightarrow \C$. Then $T$ is said to be a \textbf{linear functional on} $X$ if $T$ is linear. We define the \textbf{dual space of} $X$, denoted $X^*$, by $ X^* = \{ T:X \rightarrow \C: T \text{ is linear} \} $
		\item Let $X$ be a normed vector space over $\C$, and $T :X \rightarrow \C$. Then $T$ is said to be a \textbf{bounded linear functional on} $X$ if $T \in L(X, \C)$. We define the \textbf{dual space of} $X$, denoted $X^*$, by $X^* = L(X, \C)$.
		\end{itemize}
	\end{defn}
	
	\begin{note}
	We define $X^*$ similarly when $X$ is an vector space or normed vector space over $\R$.
	\end{note}
	
	\begin{defn}
		Let $X$ be a vector space and $p:X \rightarrow \R$. Then $p$ is said to be a \textbf{sublinear functional} if for each $x,y \in X$, $\lam \geq 0$, 
		\begin{enumerate}
			\item $p(x+y) \leq p(x) + p(y)$
			\item $p(\lam x ) = \lam p(x)$
		\end{enumerate}  
	\end{defn}
	
	\begin{ex}
		Let $X$ be a vector space and $p: X \rightarrow \R$ be a sublinear functional. Then $p(0) = 0$.
	\end{ex}
	
	\begin{proof} Set $\lam = 0$. Then 
	\begin{align*}
	0
	&= \lam p(0) \\
	&= p(\lam 0) \\
	&= p(0)
	\end{align*}
	\end{proof}
	
	\begin{proof}
	Clear
	\end{proof}
	
	\begin{defn}
		Let $X$ be a vector space and $p:X \rightarrow \R$. Then $ p$ is said to be a \textbf{seminorm} if for each $x,y \in X$, $\lam \in \R$, 
		\begin{enumerate}
			\item $p(x+y) \leq p(x) + p(y)$
			\item $p(\lam x) = |\lam| p(x)$
		\end{enumerate}  
	\end{defn}
	
	\begin{ex}
		Let $X$ be a vector space and $p: X \rightarrow \R$ be a seminorm, then $p$ is a sublinear functional.
	\end{ex}
	
	\begin{proof}
	Clear
	\end{proof}
	
	\begin{ex}
	Let $X$ be a vector space and $p: X \rightarrow \R$ be a seminorm. Then $p \geq 0$. 
	\end{ex}
	
	\begin{proof}
	Let $x \in X$. Then 
	\begin{align*}
	0 
	&= p(0) \\ 
	&= p(x - x) \\
	&\leq  p(x) + p(-x) \\
	&= p(x) + p(x) \\
	&= 2p(x)
	\end{align*}
	So $p(x) \geq 0$.
	\end{proof}
	
	\begin{ex}
	Let $X$ be a vector space and $p:X \rightarrow \R$ a sublinear functional. Then for each $x, y \in X$
	\begin{enumerate}
	\item $-p(-x) \leq p(x)$
	\item $- p(y-x) \leq p(x) - p(y) \leq p(x-y)$
	\end{enumerate}
	\end{ex}
	
	\begin{proof}
	Let $x, y \in X$.
	\begin{enumerate}
	\item We have
	\begin{align*}
	0
	&= p(0) \\ 
	&= p(x - x) \\
	& \leq p(x) + p(-x)
	\end{align*}
	So $-p(-x) \leq p(x)$.
	\item We have
	\begin{align*}
	p(x)
	&= p(x -y + y) \\
	& \leq p(x-y) + p(y)
	\end{align*}
	So $p(x) - p(y) \leq p(x-y)$. Switching $x$ and $y$ gives us $p(y) - p(x) \leq p(y-x)$ and multiplying both sides by $-1$ yields $-p(y-x) \leq p(x) - p(y)$ \\ 
	Putting these two together, we see that $$-p(y-x) \leq p(x) - p(y) \leq p(x-y)$$
	\end{enumerate}
	\end{proof}
	
	\begin{defn}
	Let $X$ be a normed vector space and $p:X \rightarrow \R$ a sublinear functional. Then $p$ is said to be \textbf{bounded} if there exists $M >0$ such that for each $x \in X$, $p(x) \leq M\|x\|$. 
	\end{defn}
	
	\begin{ex}
	Let $X$ be a normed vector space and $p:X \rightarrow \R$ a sublinear functional. Then $p$ is bounded iff $p$ is Lipschitz. 
	\end{ex}
	
	\begin{proof}
	Suppose that $p$ is bounded. Then there exists $M >0$ such that for each $x \in X$, $p(x) \leq M\|x\|$. Let $x, y \in X$. Then the previous exercise implies that 
	\begin{align*}
	-M\|x-y\| 
	&= -M\|y-x\| \\
	& \leq -p(y-x) \\
	& \leq p(x)-p(y) \\
	& \leq p(x-y) \\
	& \leq M \| x-y\| 
	\end{align*}
	So that $$|p(x) - p(y)| \leq  M\|x-y\|$$
	and $p$ is Lipschitz.
	Conversely, suppose that $p$ is Lipschitz. Then there exists $M >0 $ such that for each $x ,y \in X$, $|p(x) - p(y)| \leq  M\|x-y\|$. Let $x \in X$. Then 
	\begin{align*}
	p(x) 
	& \leq |p(x)| \\
	& = |p(x) - p(0)| \\
	& \leq M\|x - 0\| \\
	  & \leq M\|x\| 
	\end{align*}
	So $p$ is bounded.
	\end{proof}
	
	\begin{thm}\textbf{Hahn-Banach Theorem}\\
		Let $X$ be a vector space, $p:X \rightarrow \R$ a sublinear functional, $M \subset X$ a subspace and $f:M \rightarrow \R$ a linear functional. If for each $x \in M$, $ f(x)  \leq p(x)$, then there exists a linear functional $F:X \rightarrow \R$ such that for each $x \in X$, $F(x) \leq p(x)$ and $F|_{M}=f$.
	\end{thm}
	
	\begin{ex}
	Let $X$ be a vector space and $p:X \rightarrow \R$ a sublinear functional. Then there exists a linear functional $F: X \rightarrow \R$ such that for each $x \in X$, $F(x) \leq p(x)$.
	\end{ex}
	
	\begin{proof}
	Take $M = \{0\}$ and $f \equiv 0$ and apply the Hahn-Banach theorem.
	\end{proof}	
	
	\begin{ex}\textbf{Equivalency of linearity (General Case)}
	Let $X$ be a vector space and $p:X \rightarrow \R$ a sublinear functional. Then the following are equivalent:
	\begin{enumerate}
	\item there exists a unique $F \in X^*$ such that $F \leq p$
	\item for each $x \in X$, $-p(-x) = p(x)$
	\item $p$ is linear
\end{enumerate}	
\textbf{Hint:} If there exists $x \in X$ such that $-p(-x) \neq p(x)$, define $f_1,f_2 :\spn(x) \rightarrow \R$ by $f_1(tx) = t p(x)$ and $f_2(tx) = -tp(-x)$
	\end{ex}	
	
	\begin{proof} \
	\begin{itemize}
	\item $(1) \implies (2)$: \\ 
	Suppose that there exists a unique $F \in X^*$ such that $F \leq p$. For the sake of contradiction, suppose that there exists $x \in X$ such that $-p(-x) \neq p(x)$. Define $f_1,f_2: \spn(x) \rightarrow \R$ by $$f_1(tx) = t p(x)$$ and $$f_2(tx) = -tp(-x)$$ Let $y \in \spn(x)$. Then there exists $t \in \R$ such that $y = tx$. Then for each $k \in \R$,
	\begin{align*}
	f_1(ky)
	&= f_1(ktx) \\
	&= ktp(x) \\
	&= k f_1(tx) \\
	&= k f_1(y)
	\end{align*}
	Similarly, $f_2(ky) = kf_2(y)$ and so $f_1, f_2 \in \spn(x)^*$. 
	If $t \geq 0$, then 
	\begin{align*}
	f_1(y) 
	&= f_1(tx) \\
	&= tp(x) \\
	&= p(tx) \\
	&= p(y) 
	\end{align*}
	If $t <0$, then 	
	\begin{align*}
	f_1(y) 
	&= f_1(tx) \\
	&= tp(x) \\
	&= -|t|p(x) \\
	&= -p(|t|x) \\
	&= -p(-tx) \\
	& \leq p(tx) \\
	&= p(y)  
	\end{align*}
	So $f_1 \leq p$ on $\spn(x)$. Similarly, $f_2 \leq p$ on $\spn(x)$. The Hahn-Banach theorem implies that there exist $F_1, F_2 \in X^*$ such that $F_1, F_2 \leq p$ and $F_1 = f_1, F_2 = f_2$ on $\spn(x)$. By the assumption of uniqueness, $F_1 = F_2$. This is a contradiction since 
	\begin{align*}
	F_1(x) 
	&= p(x) \\
	& \neq -p(-x) \\
	& = F_2(x) 
	\end{align*}		
So for each $x \in X$, $-p(-x) = p(x)$. 
	\item $(2) \Rightarrow (3)$: \\
	Suppose that for each $x \in X$, $-p(-x) = p(x)$. The previous exercise implies that there exists $F \in X^*$ such that $F \leq p$. Let $x \in X$. Then 
	\begin{align*}
	-F(x) 
	&= F(-x) \\
	& \leq p(-x) \\
	&= -p(x)
\end{align*}	
	So $p(x) \leq F(x)$ and $p \leq F$. Therefore $p = F$ and $p$ is linear.  
	\item $(3) \implies (1)$: \\ 
	Suppose that $p$ is linear. Let $F \in X^*$. Suppose that $F \leq p$. Let $x \in X$. Then as in the case for $(2) \implies (3)$, we have that
	\begin{align*}
	-F(x) 
	&= F(-x) \\
	& \leq p(-x) \\
	&= -p(x)
	\end{align*}	 
	which implies that $p = F$. So $p$ is the unique linear function $F \in X^*$ such that $F \leq p$.
	\end{itemize}
	\end{proof}
	
	\begin{ex}
	Let $X$ be a normed vector space, $p:X \rightarrow \R$ a bounded sublinear functional and $\phi:X \rightarrow \R$ a linear functional. If $\phi \leq p$, then $\phi \in X^*$. 
	\end{ex}
	
	\begin{proof}
	Since $p$ is Lipschitz, there exists $M >0$ such that for each $x \in X$, $|p(x)| \leq M \|x\|$. Let $x \in X$. Then 
	\begin{align*}
	\phi(x) 
	&\leq p(x) \\
	&\leq |p(x)| \\
	&\leq M \|x\| 
	\end{align*}
	and therefore  
	\begin{align*}
	- M \|x\| 
	&= -M \|-x\| \\
	& \leq -p(-x) \\
	& \leq - \phi(-x) \\
	&= \phi(x) 
	\end{align*}
	So that $|\phi(x)| \leq  M\|x\|$ and $\phi \in X^*$.
	\end{proof}
	
	\begin{ex}
	Let $X$ be a normed vector space and $p:X \rightarrow \R$ a bounded sublinear functional. Then there exists $\phi \in X^*$ such that for each $x \in X$, $\phi(x) \leq p(x)$.
	\end{ex}
	
	\begin{proof}
	A previous exercise implies there exists $\phi: X \rightarrow \R$ such that $\phi$ is linear and $\phi \leq p$. The previous exercise implies that $\phi \in X^*$.
	\end{proof}
	
	\begin{ex}\textbf{Equivalency of linearity (Bounded Case)}\\
	Let $X$ be a normed vector space and $p:X \rightarrow \R$ a bounded sublinear functional. Then the following are equivalent:
	\begin{enumerate}
	\item there exists a unique $\phi \in X^*$ such that $\phi \leq p$
	\item for each $x \in X$, $-p(-x) = p(x)$
	\item $p$ is linear
\end{enumerate}	
	\end{ex}
	
	\begin{proof}
	Basically the same as last time.
	\end{proof}
	
	\begin{thm}\textbf{Complex Hahn-Banach Theorem}\\
		Let $X$ be a vector space, $p:X \rightarrow \R$ a seminorm, $M \subset X$ a subspace and $f:M \rightarrow \C$ a linear functional. If for each $x \in M$, $\vert f(x) \vert \leq p(x)$, then there exists a linear functional $F:X \rightarrow \C$ such that for each $x \in X$, $\vert F(x) \vert \leq p(x)$ and $F|_{M}=f$.
	\end{thm}	
	
	\begin{ex}
		Let $X$ be a normed vector space, $M \subset X$ a subspace and $f \in M^*$. Then there exists $F \in X^*$ such that $\|F \|= \|f \|$ and $F|_M = f$.  
	\end{ex}
	
	\begin{proof}
		If $f =0$, Choose $F=0$. Suppose $f \neq 0$. Then $\|f \|\neq 0$ and there exists $x_0 \in M$ such that $x_0  \neq 0$. Thus $\|f \|= \sup \{ \vert f(x) \vert: x \in M \text{ and } \|x \|= 1\}$. Define $p:X \rightarrow \Rg$ by $ p(x) = \|f \|\|x \|$. Then $p$ is a sublinear functional on $X$ and for each $x \in M$, $\vert f(x) \vert \leq p(x)$. So there exists a linear functional $F:X \rightarrow \C$ such that for each $x \in X$, $\vert F(x) \vert \leq p(x) = \|f \|\|x \|$ and $F|_M = f$. Thus $F \in X^*$ with $\|F \|\leq \|f \|$. Also $$\|F \|= \sup_{\substack{ x \in X \\ \|x \|= 1}} \vert F(x) \vert \geq  \sup_{\substack{ x \in M \\ \|x \|= 1}} \vert F(x) \vert = \sup_{\substack{ x \in M \\ \|x \|= 1}} \vert f(x) \vert = \|f \|$$
		
		So $\|F \|= \|f \|$.
	\end{proof}
	
	\begin{ex}
		Let $X$ be a normed vector space, $M \subsetneq X$ a proper closed subspace and $x \in X \setminus M$. Then there exists $F \in X^*$ such that $F|_M = 0$, $\|F \|=1$ and $ F(x) = \|x+M \|\neq 0$. \\
		\textbf{Hint:} Consider $f:M+\C x \rightarrow \C$ defined by $f(m+\lam x) = \lam \|x +M \|$.
	\end{ex}
	
	\begin{proof}
		Define $f:M+\C x \rightarrow \C$ as above. Clearly $f$ is linear and $f|M = 0$. Let $m \in M$ and $\lam \in \C$. If $\lam = 0$, then $\vert f(m +\lam x) \vert = 0 \leq \|m+ \lam x \|$. Suppose that $\lam \neq 0$. Then 
		\begin{align*}
			\vert f(m+\lam x) \vert 
			& = \vert \lam \vert \|x+M \|\\
			& =  \|\lam x+M \|\\
			& = \inf_{z \in M} \|z+ \lam x \|\\
			& \leq  \|m+ \lam x  \|\\
		\end{align*} 
		So $f \in (M+\C x )^*$ and $\|f \|\leq 1$. Let $\ep >0$. A previous exercise tells us that there exist $m \in M, \lam \in \C$ such that $\|m+ \lam x \|= 1$ and $\|m+ \lam x +M \|> 1- \ep$. Then 
		\begin{align*}
			\vert f(m + \lam x) \vert
			&= \vert \lam \vert \|x+M\|\\
			&=\|\lam x +M \|\\
			&= \|m + \lam x +M \|\\
			&> 1-\ep
		\end{align*}
		
		So $$ \|f \|= \sup_{\substack{z \in M + \C x \\ \|z \|=1}} \vert f(z) \vert \geq 1$$ Hence $\|f \|=1$. 
		The same exercise also tells us that $f(x) = \|x+M\|\neq 0$. Using the previous exercise, there exists $F \in X^*$ such that $\|F \|= \|f \|= 1$ and $F|_{M+\C x} = f$.
	\end{proof}
	
	\begin{ex}
		Let $X$ be a normed vector space and $x \in X$. If $x \neq 0$, then there exists $F \in X^*$ such that $\|F \|= 1$ and $F(x) = \|x \|$.
	\end{ex}
	
	\begin{proof}
		Define $f:\C x \rightarrow \C$ by $f(\lam x) = \lam \|x \|$. Then $f$ is linear and $f(x) = \|x \|$. Clearly $$\sup_{\substack{z \in \C x \\ \|z \|=1}}\vert f(z) \vert = 1$$ 
		So $f \in (\C x)^*$ and $\|f \|= 1$. By a previous exercise, there exists $F \in X^*$ such that $\|F \|= \|f \|=1$ and $F|_{\C x} = f$. 
	\end{proof}
	
	\begin{ex}
		Let $X$ be a normed vector space. Then $X^*$ separates the points of $X$. 
	\end{ex}
	
	\begin{proof}
		Let $x, y \in X$. Suppose that $x \neq y$. Then $x-y \neq 0$. The previous exercies implies that there exists $F \in X^*$ such that $\|F \|= 1$ and $$F(x) - F(y) = F(x-y) = \|x-y \|\neq 0$$ Thus $F(x) \neq F(y)$ and $X^*$ separates the points of $X$.
	\end{proof}
	
	\begin{defn}
		Let $X, Y$ be metric spaces and $T : X \rightarrow Y$. Then $T$ is said to be an \textbf{isometry} if for each $x_1, x_2 \in X$, $d( Tx_1, Tx_2) = d(x_1,x_2) $.
	\end{defn}
	
	\begin{ex}
		Let $X,Y$ be metric spaces and $T:X \rightarrow Y$ and isometry. Then $T$ is injective.
	\end{ex}
	
	\begin{proof}
		Let $x_1, x_2 \in X$. Suppose that $Tx_1=Tx_2$. Then $0= d( Tx_1, Tx_2) = d(x_1,x_2)$. So $x_1 = x_2$. Hence $T$ is injective.
	\end{proof}
	
	\begin{note}
		Let $X,Y$ be metric spaces and $T:X \rightarrow Y$ an isometry. Then $T$ is clearly continuous. If $T$ is surjective, then $T^{-1}$ is an isometry and therefore continuous. Hence $T$ is a homeomorphism.
	\end{note}
	
	\begin{ex}
		Let $X$ be a normed vector space and $x \in X$. Define $\hat{x}:X^* \rightarrow \C$ by $\hat{x}(f) = f(x)$. Then $\hat{x} \in X^{**}$ and $\|\hat{x} \|= \|x \|$.
	\end{ex}
	
	\begin{proof}
		Let $f,g \in X^*$ and $\lam \in \C$. Then $$\hat{x}(f+\lam g) = (f+ \lam g)(x) = f(x) + \lam g(x) = \hat{x}(f) + \lam \hat{x}(g)$$
		So $\hat{x}$ is linear. For each $f \in X^*$, $$\vert \hat{x}(f) \vert = \vert f(x) \vert \leq \|x \|\|f \|$$ Hence $\hat{x} \in X^{**}$ with $\|\hat{x} \|\leq \|x \|$. If $x=0$, then $\hat{x} = 0$ and $\|\hat{x} \|= \|x \|$. Suppose that $x \neq 0$. Then a previous exercise implies that there exists $F \in X^*$ such that $\|F \|=1$ and $F(x) = \|x \|$. Then we have that $$\sup_{\substack{f \in X^* \\ \|f \|= 1 } } \vert \hat{x}(f) \vert  = \sup_{\substack{f \in X^* \\ \|f \|= 1 }}  \vert f(x) \vert \geq \vert F(x) \vert = \|x \|$$
		Hence $\|\hat{x} \|= \|x \|$.
	\end{proof}
	
	
	\begin{ex}
		Let $X$ be a normed vector space. Define $\phi : X \rightarrow X^{**}$ by $\phi(x) = \hat{x}$. Then $\phi$ is a linear isometry. 
	\end{ex}
	
	\begin{proof}
		Let $x,y \in X$ and $\lam \in \C$. Then for each $f \in X^*$, we have that 
		\begin{align*}
			\phi(x+ \lam y)(f) 
			&= \widehat{x+ \lam y}(f) \\
			&= f(x+\lam y) \\
			&= f(x) + \lam f(y) \\
			&= \hat{x}(f) + \lam \hat{y}(f)\\
			&= \phi(x)(f) + \lam \phi(y)(f)
		\end{align*} 
		So $\phi(x+ \lam y) = \phi(x) + \lam \phi(y)$ and $\phi$ is linear. The previous exercise tells us that 
		\begin{align*}
			\|\phi(x) - \phi(y) \|
			&= \|\phi(x-y)\|\\
			&= \|\widehat{x-y} \|= \|x-y \|
		\end{align*}
		So $\phi$ is an isometry.
	\end{proof}
	
	\begin{defn}
		Let $X$ be a normed vector space and define $\phi:X \rightarrow X^{**}$ as above. We define $\widehat{X} = \phi(X) \subset X^{**}$. Since $\widehat{X}$ and $X$ are isomorphic, we may identify $X$ as a subset of $X^{**}$. 
	\end{defn}
	
	\begin{defn}
		Let $X$ be a normed vector space and define $\phi:X \rightarrow X^{**}$ as above. Then $X$ is said to be reflexive if $\phi$ is surjective. In this case $\phi$ is then an isomorphism
	\end{defn}
	
	\begin{ex}
		Let $X$ be a normed vector space and $f:X \rightarrow \C$ a linear functional on $X$. Then $f$ is bounded iff $\ker f$ is closed. 
	\end{ex}
	
	\begin{proof}
		Suppose that $f$ is continuous. Since $\{0\}$ is closed, we have that $\ker f = f^{-1}(\{0\})$ is closed. Conversely, suppose that $\ker f$ is closed. If $\ker f = X$, then $f =0$ and $f$ is continuous. Suppose that $\ker f \neq X$. Then $\ker f$ is a proper, closed subspace of $X$. A previous exercise tells us that there exists $x \in X$ such that $\|x \|= 1$ and $\|x + \ker f \|> \frac{1}{2}$. Let $y \in X$. Suppose that $\|y \|< \frac{1}{2}$. Then for each $z \in \ker f$, 
		\begin{align*}
			\|z -  (x+y)\|
			& = \|(z-x) -y \|\\
			& \geq \|z-x \|- \|y \|\\
			& > \frac{1}{2} - \frac{1}{2} \\
			&=0
		\end{align*}
		
		So $x+y \not \in \ker f$. Therefore $f(B(x,\frac{1}{2})) \cap \{0\} = \varnothing$. If $f(B(x,\frac{1}{2})) $ is unbounded, then $f(B(x,\frac{1}{2})) = \C$ by linearity. This is a contradiction since $0 \not \in f(B(x,\frac{1}{2}))$. So There exists $s > 0$ such that $f(B(x,\frac{1}{2})) \subset B(0,s)$ and thus $f$ is bounded. 
	\end{proof}
	
	\begin{ex}
		Let $X$ be a normed vector space. 
		\begin{enumerate}
			\item Let $M \subsetneq X$ be a proper closed subspace of $X$ and $x \in X \setminus M$. Then $M + \C x$ is closed.
			\item Let $M \subset X$ be a finite dimensional subspace of $X$. Then $M$ is closed.
		\end{enumerate}
	\end{ex}
	
	\begin{proof}
		\begin{enumerate}
			\item Let $y \in X$ and $(y_n)_{n \in \N} \subset M+ \C x$. Suppose that $y_n \conv{} y$. If $y \in M$, then $y \in M+ \C x$. Suppose that $y \not \in M$. For each $n \in \N$, there exists $m_n \in M$ and $\lam_n \in \C$ such that $y_n = m_n + \lam_nx$. A previous exercise tells us that there exists $F \in X^*$ such that $\|F \|= 1$, $F|_M = 0$ and $F(x) = \|x+M \|\neq 0$. Since $F$ is continuous, $F(y_n) \conv{} F(y)$. Since for each $n \in \N$, $$F(y_n) = F(m_n + \lam_n x) = F(m_n)+ \lam_n (F_x) = \lam_n F(x)$$ we have that $\lam_n F(x) \conv{} F(y)$. Since $F(x) \neq 0$, this implies that $\lam_n \conv{} F(x)^{-1} F(y)$. It follows that $\lam_n x \conv{}F(x)^{-1}F(y)x$. Since  for each $n \in \N$, $m_n = y_n - \lam_nx$, we know that $m_n \conv{} y-F(x)^{-1}F(y)x$. Since $(m_n)_{n \in \N} \subset M$ and $M$ is closed, we have that $y-F(x)^{-1}F(y)x \in M$ and therefore $y \in M+\C x$. Hence $M+\C x$ is closed. \vspace{.5cm}\\
			\item If $M = X$, then $M$ is closed. Suppose that $M \neq X$. Let $(x_i)_{i=1}^n$ be a basis for $M$. Define $N_0 = \{0\}$ and for each $i =1,2, \cdots, n$, define $N_i = N_{i-1}+\C x_i$. Since $N_0$ is a proper closed subpace of $X$ and $x_1 \in X \setminus N_0$, (1) implies that $N_1$ is closed. Proceed inductively to obtain that $M = N_n$ is closed.
		\end{enumerate}
	\end{proof}
	
	\begin{ex}
		Let $X$ be an infinite-dimensional normed vector space. 
		\begin{enumerate}
			\item There exists a sequence $(x_n)_{n\in \N} \subset X$ such that for each $m, n \in \N$, $\|x_n \|= 1$ and if $m \neq n$, then $\|x_m - x_n \|> \frac{1}{2}$.
			\item $X$ is not locally compact. 
		\end{enumerate}
	\end{ex}
	
	\begin{proof}
		\begin{enumerate}
			\item Define $N_0 = \{0\}$. Then $N_0$ is a closed proper subspace of $X$. Choose $x_1 \in X$ such that $\|x_1 \|= 1$. Using the results of previous exercises, we proceed inductively. For each $n \geq 2$ we define $N_{n-1} = \text{span}(x_1, x_2, \cdots, x_{n-1})$. Then $N_{n-1}$ is a closed proper subspace of $X$. Thus we may choose $x_n \in X$ such that $\|x_n \|= 1$ and $\|x_n + N_{n-1} \|>  \frac{1}{2}$. Let $m,n \in \N$. Suppose that $m<n$. Then $x_m \in N_{n-1}$. Thus $\|x_n - x_m \|\geq \|x_n + N_{n-1} \|> \frac{1}{2}$\vspace{.5cm}\\
			\item Suppose that $X$ is locally compact. Then $\overline{B(0,1)}$ is compact and therefore sequentially compact. Using $(x_n)_{n \in \N} \subset \overline{B(0,1)}$ defined in (1), we see that there exists a subsequence $(x_{n_k})_{k \in \N}$, $x \in \overline{B(0,1)}$ such that $x_{n_k} \conv{} x$. Then $(x_{n_k})_{k \in \N}$ is Cauchy. So there exists $N \in N$ such that for each $j, k \in \N$, if $j, k \geq N$, then $\|x_{n_j} - x_{n_k} \|< \frac{1}{2}$. Then $\|x_{n_N} - x_{n_{N+1}} \| < \frac{1}{2}$. This is a contradiction since by construction, $\|x_{n_N} - x_{n_{N+1}} \| > \frac{1}{2}$. Thus $X$ is not locally compact.
		\end{enumerate}
	\end{proof}
	
	\begin{ex}
		Let $X,Y$ be normed vector spaces and $T \in L(X,Y)$. 
		\begin{enumerate}
			\item Define the \textbf{adjoint of $T$}, denoted  $T^*:Y^* \rightarrow X^*$ by $T^*(f) = f \circ T$. Then $T^* \in L(Y^*, X^*)$.
			\item Applying the result from (1) twice, we have that $T^{**} \in L(X^{**},Y^{**})$. We have that for each $x \in X$, $T^{**}(\hat{x}) = \widehat{T(x)}$.
			\item $T^*$ is injective iff $T(X)$ is dense in $Y$.
			\item If $T^*(Y^*)$ is dense in $X^*$, then $T$ is injective. The converse is true if $X$ is reflexive.
		\end{enumerate}
	\end{ex}
	
	\begin{proof}
		\begin{enumerate}
			\item Let $f \in Y^*$. Then $\|T^* (f) \|= \|f \circ T \|\leq  \|T \| \|f \|$. So $T^* \in L(Y^*, X^*)$ with $\|T^* \|\leq \|T \|$.\vspace{.5cm}\\
			\item Let $x \in X$. Let $f \in Y^*$. Then 
			\begin{align*}
				T^{**}(\hat{x})(f) 
				&= \hat{x} \circ T^{*}(f) \\
				&= \hat{x}(T^* (f)) \\
				&= \hat{x}(f \circ T) \\
				&= f \circ T (x) \\
				&= f(T(x)) \\
				&= \widehat{T(x)}(f)
			\end{align*} 
			Hence $T^{**}(\hat{x}) = \widehat{T(x)}$.\vspace{.5cm}\\
			\item Suppose that $T(X)$ is not dense in $Y$. Then $\overline{T(X)} \neq Y$. So $T(X)$ is a proper closed subspace of $Y$ and there exists $y \in Y$ such that $y \not \in \overline{T(X)}$. By a previous exercise, there exists $f \in Y^*$ such that $f(y) = \|y+\overline{T(X)} \|\neq 0$, $\|f \|=1$ and $f|_{\overline{T(X)}} = 0$. Let $x \in X$. Then $T^*(f)(x) = f \circ T(x) = 0$. Hence $T^*(f) = 0 = T^*(0)$. Since $f \neq 0$, $T^*$ is not injective.\\ Now suppose that $T(X)$ is dense in $Y$. Let $f,g \in Y^*$. Define $h \in Y^*$ by $h = f-g$ Suppose that $T*(f) = T^*(g)$ Then $T^*(h) = 0$. So for each $x \in X$, $h(T(x)) = 0$. Let $y \in Y$ and $\ep >0$. By continuity, there exists $\del > 0 $ such that for each $y' \in Y$, if $\|y - y' \|< \del$, then $\|h(y) - h(y') \|< \ep$. Since $T(X)$ is dense in $Y$, there exists $x \in X$ such that $\|y - T(x) \|< \del$. Thus 
			\begin{align*}
				\|h (y) \|
				&\leq \|h(y) - h(T(x)) \|+ \|h(T(x)) \|\\
				& = \|h(y) - h(T(x)) \| \\
				& < \ep
			\end{align*} 
			Since $\ep > 0$ is arbitrary, $\|h(y) \|= 0$. This implies that $h(y) = 0$ and therefore $f(y) = g(y) $. Since $y \in Y$ is arbitrary, $f=g$ and $T^*$ is injective. \vspace{.5cm}\\
			\item For the sake of contradiction, suppose that $T^*(Y^*)$ is dense in $X^*$ and $T$ is not injective. Then there exist $x_1, x_2 \in X$ such that $x_1 \neq x_2$ and $T(x_1) = T(x_2)$. Define $x = x_1-x_2$. Then $x \neq 0$ and $T(x) = 0$. A previous exercise implies that there exists $F \in X^*$ such that $F(x) = \|x\|\neq 0$ and $\|F \|= 1$. Let $\ep >0$. Choose $g \in Y^*$ such that $\|F - T^*(g) \|< \ep$. Then 
			\begin{align*}
				\|x \|
				&= \vert F(x) \vert \\
				&\leq \vert F(x) - T^*(g)(x) \vert + \vert T^*(g)(x) \vert \\
				& < \ep \|x \|+ \vert g(T(x)) \vert\\
				&= \ep \|x \|
			\end{align*}
			
			Since $\ep > 0$ is arbitrary, we have that $\|x \|=0$ which is a contradiction. Hence if $T^*(Y^*) $ is dense in $X^*$, then $T$ is injective. \vspace{.5cm}\\ 
			Now, suppose that $X$ is reflexive and $T$ is injective. Let $\phi_1, \phi_2 \in X^{**}$. Suppose that $T^{**}(\phi_1) = T^{**}(\phi_2)$. Then $T^{**}(\phi_1 - \phi_2) = 0$. Since $X$ is reflexive, there exist $x_1, x_2 \in X$ such that $\phi_1 = \hat{x_1}$ and $\phi_2 = \hat{x_2}$. Define $x = x_1 - x_2$. Then $T^{**}(\hat{x}) = 0$. So for each $f \in Y^*$, 
			\begin{align*}
				T^{**}(\hat{x})(f) 
				&= \hat{x} \circ T^*(f)\\
				&= \hat{x}( T^*(f))\\
				&= \hat{x} (f \circ T)\\
				&= f \circ T(x)\\
				&= f(T(x))\\
				&= 0 
			\end{align*}
			Suppose that $T(x) \neq 0$. Then a previous exercise implies that there exists $g \in Y^*$ such that $g(T(x)) = \|T(x) \|\neq 0$ and $\|g \| = 1$. This is a contradiction since $g(T(x)) = 0$. So $T(x) = 0$. Since $T$ is injective, this implies that $x = 0$. Hence $\hat{x}=0$ and thus $\phi_1 = \phi_2$. Thus $T^{**}$ is injective. By (3), we have that $T^*(Y^*)$ is dense in $X^*$.
		\end{enumerate}
	\end{proof}
	
	\begin{ex}
		Let $X$ be a normed vector space. Then $X$ is reflexive iff $X^*$ is reflexive. 
	\end{ex}
	
	\begin{proof}
		Suppose that $X$ is reflexive. Let $\al \in X^{***}$. Define $f :X \rightarrow \C$ by $f(x) = \al(\hat{x})$. Clearly $f$ is linear and a previous exercise tells us that for each $x \in X$, 
		\begin{align*}
			\vert f(x) \vert 
			& \leq \|\al \|\|\hat{x} \|\\
			&= \|\al \|\|x \|
		\end{align*}
		So $f \in X^*$.
		Let $\phi \in X^{**}$. Since $X$ is reflexive, there exists $x \in X$ such that $\phi = \hat{x}$. Then 
		\begin{align*}
			\al(\phi)
			&= \al(\hat{x})\\
			&= f(x)\\
			&= \hat{x}(f)\\
			&= \hat{f}(\hat{x})\\
			&= \hat{f}(\phi)
		\end{align*}
		Hence $\al = \hat{f}$. Thus the map $X^* \rightarrow X^{***}$ given by $f \mapsto \hat{f} $ is surjective and so $X^{*}$ is reflexive.\vspace{.5cm}\\
		Conversely, suppose that $X^*$ is reflexive. Since $\phi:X \rightarrow X^{**}$ given by $\phi(x) = \hat{x}$ is an isometry, $\widehat{X} \subset X^{**}$ is closed. For the sake of contradiction, suppose that $\widehat{X} \neq X^{**}$. Then there exists $\al \in X^{**}$ such that $\al \not \in \widehat{X}$. Thus there exists $F \in X^{***}$ such that $\|F \|= 1$, $F(\al) = \|\al + \widehat{X} \|\neq 0$ and $F|_{\widehat{X}}=0$. Since $X^*$ is reflexive, there exists $f \in X^*$ such that $F = \hat{f}$. A previous exercise tells us that $\|f \|= \|\hat{f} \|= \|F \|= 1$. Since for each $x \in X$, $f(x) = \hat{x}(f) = \hat{f}(\hat{x}) = F(\hat{x}) = 0$, we have that $f = 0$. Thus $\|f \|= 0$, a contradiction. So $\widehat{X} = X^{**}$ and $X$ is reflexive.
		
	\end{proof}
	
	\newpage
	
	\subsection{The Baire Category and Closed Graph Theorems}
	
	\begin{thm}
		Let $X, Y$ be Banach spaces and $T\in L(X,Y)$. If $T$ is surjective, then $T$ is open.
	\end{thm}
	
	\begin{cor}
		Let $X, Y$ be Banach spaces and $T \in L(X,Y)$. If $T$ is a bijection, then $T^{-1} \in L(X,Y)$.
	\end{cor}
	
	\begin{defn}
		Let $X,Y$ be sets and $f:X \rightarrow Y$. We define the \textbf{graph of f}, $\Gam(f)$, by $\Gam(f) = \{(x,y) \in X \times Y: f(x) = y\}$.
	\end{defn}
	
	\begin{thm}
		Let $X, Y$ be Banach spaces and $T:X \rightarrow Y$ a linear map. If $\Gam(T)$ is closed, then $T \in L(X,Y)$.  
	\end{thm}
	
	\begin{note}
		We recall that $\Gam(T)$ is closed iff for each $(x_n)_{n \in \N} \subset X$, $x \in X$ and $y \in Y$, $x_n \conv{} x$ and $T(x_n) \conv{} y$ implies that $T(x) = y$. 
	\end{note}
	
	\begin{thm}
		
		Let $X, Y$ be Banach spaces and $S \subset L(X,Y)$. If for each $x \in X$, $$\sup_{T \in S} \|Tx \|< \infty$$ then $$\sup_{T \in S} \|T \|< \infty$$
	\end{thm}
	
	\begin{ex}
		Let $\mu$ be counting measure on $(N, \MP(\N))$. Define $h: \N \rightarrow \N$ and $ \nu$ on $(N, \MP(\N))$ by $h(n) = n$ and $d \nu = h d \mu$. Define $X=L^1(\nu)$ and $Y = L^1(\mu)$. Equip both $X$ and $Y$ with the $L^1$ norm with respect to $\mu$. 
		\begin{enumerate}
			\item We have that $X$ is a proper subspace of $Y$ and therefore $X$ is not complete.
			\item Define $T: X \rightarrow Y$ by $Tf(n) = nf(n)$. Then $T$ is linear, $\Gam(T)$ is closed, and $T$ is unbounded.
			\item Define $S:Y \rightarrow X$ by $Sg(n) = \frac{1}{n}g(n)$. Then $S \in L(Y,X)$, $S$ is surjective and $S$ is not open. 
		\end{enumerate}
	\end{ex}
	
	\begin{proof}\
		\begin{enumerate}
			\item Note that for each $f: \N \rightarrow \C$, 
			\begin{align*}
				{\|f \|}_{\mu, 1}
				&= \sum_{n=1}^{\infty} \vert f(n) \vert  \\
				& \leq \sum_{n=1}^{\infty} n \vert f(n) \vert  \\
				& = \|f \|_{\nu,1} 
			\end{align*} 
			Hence $X$ is a subspace of $Y$. Define $f : \N \rightarrow \C$ by $f(n) = \frac{1}{n^2}$. Then $$\|f \|_{\mu, 1} = \sum_{n=1}^{\infty} \frac{1}{n^2} < \infty$$ So  $f \in Y$. However $$\|f \|_{\nu, 1} = \sum_{n=1}^\infty \frac{1}{n} = \infty$$ So $f \not \in X$. Thus $X$ is a proper subspace of $Y$. Let $g \in Y$ and $\ep >0$. Since the simple functions are dense in $L^1(\mu)$, there exists $\phi \in L^1(\mu)$ such that $\phi$ is simple and $\|g - \phi \|_{\mu ,1} < \ep$. Then there exist $(c_i)_{i=1}^k \subset \C$ and $ (E_i)_{i=1}^k \subset \MP(\N)$ such that for each $i,j \in  \{1,2,\cdots, k\}$, $E_i$ is finite, $i \neq j$ implies that $E_i \cap E_j = \varnothing$ and  $$\phi = \sum_{i=1}^kc_i \chi_{E_i}$$ Define $c = \max\{\vert c_i \vert: i=1,2,\cdots k\}$ and $m = \max \bigg[ \bigcup_{i=1}^k E_i \bigg]$. Then 
			\begin{align*}
				\|\phi \|_{\nu,1} 
				&=  \sum_{n=1}^m n \vert \phi(n) \vert \\
				& \leq \sum_{n=1}^m  mc \\
				& = c m^2 \\
				& < \infty
			\end{align*}
			Hence $\phi \in X$ and $X$ is dense in $Y$. Since $X$ is a dense, proper subspace, it is not closed. Since $Y$ is complete and $X \subset Y$ is not closed, we have that $X$ is not complete.
			\item Clearly $T$ is linear. Let $(f_j)_{j \in \N} \subset X$, $f \in X$ and $g \in Y$. Suppose that $f_j \conv{L^1(\mu)} f$ and $Tf_j \conv{L^1(\mu)} g$. 
			
			Note that for each $j \in \N$ and $n \in \N$, $$\vert f_j(n) - f(n) \vert \leq \sum_{n =1}^{\infty}\vert f_j(n) - f(n) \vert = \|f_j-f \|_{\mu, 1}$$ and $$\vert nf_j(n) - g(n) \vert \leq \sum_{n =1}^{\infty}\vert nf_j(n) - g(n) \vert = \|Tf_j - g\|_{\mu, 1}$$  
			Thus for each $n \in \N$, $f_j(n) \conv{j} f(n)$ and $nf_j(n) \conv{j} g(n)$. This implies that for each $n \in \N$, $nf(n) = g(n)$. Thus $Tf = g$ which implies that $\Gam(T)$ is closed. Suppose, for the sake of contradiction, that $T$ is bounded. Then there exists $C \geq 0$ such that for each $f \in X$, $\|Tf \|_{\mu,1} \leq C \|f \|_{\mu, 1}$. Choose $n \in \N$ such that $n > C$. Define $f: \N \rightarrow \C$ by $f = \chi_{\{n\}}$. As established above, $S^+ \subset L^1(\mu)$. Then $\|f \|_{\mu,1} = 1$ and
			\begin{align*}
				\|Tf \|_{\mu,1}
				& = n \\
				&> C\\
				& = C \|f \|_{\mu,1}
			\end{align*}
			which is a contradiction. So $T$ is unbounded.
			\item Clearly $S$ is linear. Let $g \in Y$. Then \begin{align*}
				\|Sg \|_{\mu,1} 
				&= \sum_{n =1}^{\infty} \frac{1}{n} \vert g(n) \vert \\
				& \leq  \sum_{n =1}^{\infty} \vert g(n) \vert \\
				& = \|g \|_{\mu,1}
			\end{align*}
			So $S$ is bounded and $\|S \|\leq 1$. Thus $S \in L(Y,X)$. Let $f \in X$. Define $g: \N \rightarrow \C$ by $g(n) = nf(n)$. By defnition, $g \in Y$ and we have that
			\begin{align*}
				Sg(n) 
				&= \frac{1}{n}g(n) \\
				& = f(n)
			\end{align*}
			Hence $Sg =f$ and thus $S$ is surjective. Let $g \in Y$. Suppsose that $Sg = 0$. Then $$\sum_{n=1}^{\infty} \frac{1}{n}\vert g(n)\vert =\|Sg \| = 0$$ Thus for each $n \in \N$, $g(n) = 0$. Hence $\ker S = \{0\}$ and $S$ is injective. Note that for each $A \subset Y$, $S(A)= T^{-1}(A)$. If $S$ is open, then $T$ is continuous which as shown above is a contradiction. So $g$ is not open. 
		\end{enumerate}
	\end{proof}
	
	\begin{ex}
		Let $X = C^1([0,1])$ and $Y=C([0,1])$. Equip both $X$ and $Y$ with the uniform norm. 
		\begin{enumerate}
			\item Then $X$ is not complete
			\item Define $T: X \rightarrow Y$ by $Tf = f'$. Then $\Gam(T)$ is closed and $T$ is not bounded. 
		\end{enumerate}
	\end{ex}
	
	\begin{proof}
		\begin{enumerate}
			\item Recall that for each $a,b \geq 0$ and $p \in \N$, $$(a^{\frac{1}{p}}+b^{\frac{1}{p}})^p = \sum_{n=0}^p  {p \choose n} a^{\frac{n}{p}}b^{\frac{p-n}{p}} \geq a + b$$ Thus $(a+b)^{\frac{1}{p}} \leq a^{\frac{1}{p}}+b^{\frac{1}{p}}$.\\
			For each $n \in \N$, define $f_n: [0,1] \rightarrow \C$ by $f_n(x) = \sqrt{(x-\frac{1}{2})^2+ \frac{1}{n^2}}$. Then $(f_n)_{n \in \N} \subset X$. Define $f:[0,1] \rightarrow \C$ by $f(x) = \vert x-\frac{1}{2}\vert$. Then $f \in Y \cap X^c$. Note that for each $n \in \N$, $f \leq f_n$. Our observation above implies that for each $x \in X$,
			\begin{align*}
				f_n(x) 
				&= \bigg[ (x-\frac{1}{2})^2 + \frac{1}{n^2} \bigg]^{\frac{1}{2}}\\
				& \leq \vert x-\frac{1}{2} \vert + \frac{1}{n}
			\end{align*}
			Thus $0 \leq f_n - f \leq \frac{1}{n} $. This implies that $f_n \convt{u} f$. Since $f \not \in X$, $X$ is not complete. \vspace{.5cm}\\
			\item Let $(f_n)_{n \in \N} \subset X$, $f \in X$ and $g \in Y$. Suppose that $f_n \convt{u} f$ and $Tf_n \convt{u} g$. Let $x \in [0,1]$. Then $f_n(x) \conv{} f(x)$ and $f_n(0) \conv{} f(0)$ and $f_n' \conv{u} g$. Applying the DCT to this sequence of integrable functions that converges uniformly to an integrable function on a finite measure space (a previous exercise) we have that
			\begin{align*}
				f_n(x) - f_n(0) 
				&= \int_{[0,x]} f_n' dm \\
				& \conv{} \int_{[0,x]} g dm \\ 
			\end{align*} 
			Since $f_n(x) - f_n(0) \conv{} f(x) - f(0)$, we know that $$f(x) - f(0) = \int_{[0,x]} g dm$$. Thus $Tf = g$ and $\Gam(T)$ is closed. \\
			Suppose for the sake of contradiction that $T$ is bounded. Then there exists $C \geq 0$ such that for each $f \in X$, $\|T f \|\leq C \|f \|$. Choose $n \in \N$ such that $n > C$. Define $f \in X$ by $f(x) = x^n$. Then $\|f \|= 1$ and 
			\begin{align*}
				\|Tf \|
				&= \|f' \|\\
				&= n \\
				&> C \\
				&= C \|f \|
			\end{align*}
			which is a contradiction. So $T$ is not bounded.
		\end{enumerate}
	\end{proof}
	
	\begin{ex}
		Let $X, Y$ be Banach spaces and $T \in L(X,Y)$. Then $X/\ker T \cong T(X)$ iff $T(X)$ is closed.
	\end{ex}
	
	\begin{proof}
		Since $X$ is a banach space and $T$ is continuous, we have that $\ker T$ is closed and $X/ \ker T$ is a Banach space. Suppose that $X/ \ker T \cong T(X)$. Then $T(X)$ is complete. Since $Y$ is complete, this implies that $T(X)$ is closed. \\
		Conversely Suppose that $T(X)$ is closed. Then $T(X)$ is complete. Define $S: X/ \ker T \rightarrow T(X)$ by $S(x + \ker T) = T(x)$. A previous exercise tells us that the map $S: X/ \ker T \rightarrow T(X)$ defined by $S(x + \ker T) = T(x)$ is a bounded linear bijection. Since $T(X)$ is complete and $S$ is surjective, $S^{-1}$ is bounded and thus $S$ is an isomorphism.   
	\end{proof}
	
	\begin{ex}
		Let $X$ be a separable Banach space. Define $B_X = \{x \in X: \|x \|< 1\}$. Let $(x_n)_{n \in \N} \subset B_X $ a dense subset of the unit ball and $\mu$ the counting measure on $(\N, \MP(\N))$. Define $T: L^1(\mu) \rightarrow X$ by $$Tf = \sum_{n=1}^{\infty}f(n)x_n$$ Then 
		\begin{enumerate}
			\item $T$ is well defined and $T \in L(L^1(\mu), X)$
			\item $T$ is surjective
			\item There exists a closed subspace $K \subset L^1(\mu)$ such that $L^1(\mu)/K \cong X$ 
		\end{enumerate} 
	\end{ex}
	
	\begin{proof}
		\begin{enumerate}
			\item Let $f \in L^1(\mu)$. Since $X$ is complete and 
			\begin{align*}
				\sum_{n=1}^{\infty}\|f(n)x_n \|
				& = \sum_{n=1}^{\infty} \vert f(n) \vert \|x_n \|\\
				& \leq \sum_{n=1}^{\infty} \vert f(n) \vert \\
				&< \infty 
			\end{align*}
			we have that $\sum_{n=1}^{\infty} f(n)x_n $ converges and thus $Tf \in X$. Hence $T$ is well defined. \vspace{.5cm}\\
			Clearly $T$ is linear. Let $f \in L^1(\mu)$. Then
			\begin{align*}
				\|Tf \|
				&= \| \sum_{n=1}^{\infty} f(n)x_n \|\\
				& \leq \sum_{n=1}^{\infty} \|f(n)x_n \|\\
				& \leq \sum_{n=1}^{\infty} \vert f(n) \vert \\
				&= \|f \|_1
			\end{align*}
			So $T$ is bounded with $\|T \|\leq 1$.\vspace{.5cm}\\
			\item Let $x \in X$. Suppose that $\|x \|< 1$. Then $x \in B_X$. So there exists $n_1 \in \N$ such that $\|x - x_{n_1} \|< \frac{1}{2}$. Then $2(x-x_{n_1}) \in B_X$. Since for each $j \in \N$, $B_X\setminus (x_n)_{n=1}^j$ is dense in $B_X$, there exists $n_2 \in \N$ such that $x_{n_2} \not \in (x_n)_{n=1}^{n_1}$ and $\|2(x- x_{n_1}) - x_{n_2} \|< \frac{1}{2}$ which implies that $\|x- (x_{n_1} - \frac{1}{2}x_{n_2}) \|< \frac{1}{4}$. \vspace{.5cm}\\ 
			Proceed inductively to obtain a subsequence $(x_{n_k})_{k \in \N}$ such that for each $k \geq 2$, $x_{n_k} \not \in (x_n)_{n=1}^{n_{k-1}}$ and $\|x - \sum_{j=1}^k 2^{1-j}x_{n_j} \|< \frac{1}{2^k}$. Then $x = \sum_{k=1}^{\infty}2^{1-k}x_{n_k}$. \vspace{.5cm} \\ 
			Define $f:\N \rightarrow \C$ by $f = \sum_{k=1}^{\infty}2^{1-k}\chi_{\{n_k\}}$. Then $\|f \|_1 = \sum_{k=1}^{\infty}2^{1-k}< \infty$, so $f \in L^1(\mu)$ and $Tf = \sum_{k=1}^{\infty}2^{1-k}x_{n_k} = x$. Now, suppose that $\|x \|\geq 1$, then $\frac{1}{2\|x \|}x \in B_X$. The above argument shows that there exists $f \in L^1(\mu)$ such that $Tf = \frac{1}{2\|x \|}x$. Then $2 \|x \|f \in L^1(\mu)$ and $T(2 \|x \|f) = 2 \|x \|Tf =x$. \\
			So for each $x \in X$, there exists $f \in L^1(\mu)$ such that $Tf = x$ and thus $T$ is surjective. 
			\item Since $X$ is a Banach space and $T$ is surjective, the previous exercise implies that $L^1(\mu)/\ker T \cong X$. 
		\end{enumerate}
	\end{proof}
	
	\begin{ex}
		Let $X, Y$ be Banach spaces and $T:X \rightarrow Y$ a linear map. If for each $f \in Y^*$, $f \circ T \in X^*$, then $T \in L(X,Y)$. 
	\end{ex}
	
	\begin{proof}
		Suppose that for each $f \in Y^*$, $f \circ T \in X^*$. Let $x \in X$, 
	\end{proof}
	
	\newpage




























	\subsection{Banach Algebras}
	
	\begin{defn}
		Let $X$ be a Banach space and an associative algebra. Then $X$ is said to be a \textbf{Banach algebra} if for each $S,T \in X$, $\|ST \|\leq \|S \|\|T \|$. 
	\end{defn}
	
	\begin{defn}
	Let $X$ be a Banach algebra and $I \in X$. Then $I$ is said to be an \textbf{identity} if for each $T \in X$, $IT = TI = T$. 
	\end{defn}
	
	\begin{defn}
	Let $X$ be a Banach algebra. and $I \in X$. Then $I$ is said to be an \textbf{identity} if $I \neq 0$ and for each $T \in X$, $IT = TI = T$.
	\end{defn}
	
	\begin{defn}
	Let $X$ be a Banach algebra. Then $X$ is said to be \textbf{unital} if there exists $I \in X$ such that $I$ is an identity.
	\end{defn}	
		
		\begin{ex}
		Let $X$ be a unital Banach algebra. Then there exists a unique $I \in X$ such that $I$ is an identity.
		\end{ex} 
		
		\begin{proof}
		Clear.
		\end{proof}
		
		\begin{note}
		We denote the unique identity element by $I$.
		\end{note}
		
		\begin{defn}
		Let $X$ be a unital Banach algebra and $T,S \in X$. Then $S$ is said to be an 
		\textbf{inverse} of $T$ if $TS=ST = I$.
		\end{defn}

		\begin{defn}
		Let $X$ be a unital Banach algebra and $T \in X$. 			Then $T$ is said to be 
		\textbf{invertible} if there exists $S \in X$ such 		that $S$ is an inverse of $T$.
		\end{defn}
		
		\begin{ex}
		Let $X$ be a unital Banach algebra and $T \in X$. If $T$ is invertible, then there exists a unique $S \in X$ such that $S$ is an inverse of $T$.
		\end{ex}
		
		\begin{proof}
		Clear.
		\end{proof}
		
		\begin{note}
		We denote the unique inverse of $T$ by $T^{-1}$.
		\end{note}
		
			
	\begin{ex}\textbf{Fundamental Example:} \\
	Let $X$ be a Banach space. Then $GL(X)$ is a unital Banach algebra.
	\end{ex}
	
	\begin{proof}
	Clear.
	\end{proof}
		
		\begin{defn}
		Let $X$ be a unital Banach algebra. We define $GL(X) = \{T \in X: T \text{ is invertible}\}$.
		\end{defn}
		
		\begin{ex}
		Let $X$ be a unital Banach algebra. Then $GL(X)$ is a group.  
	\end{ex}
	
	\begin{proof}
	Clear.
	\end{proof}
	
	\begin{ex}
		Let $X$ be a unital Banach algebra. Then $1 \leq \|I \|$. 
	\end{ex}
	
	\begin{proof}
		Since $I \neq 0$, $\|I \|\neq 0$. By definition, $$\|I \|= \|I I \|\leq \|I \|\|I \|$$ Hence $1 \leq \|I \|$.
	\end{proof}
	
	\begin{ex}
		Let $X$ be a Banach algebra. Then mulitplication is continuous. 
	\end{ex}
	
	\begin{proof}
		Let $(S_1,T_1) \in X \times X$ and $\ep > 0$. Choose $\del = \min\{\frac{\ep}{2(\|S_1 \|+ \|T_1 \|+1)}, \frac{\sqrt{\ep}}{\sqrt{2}}\}$. Let $(S_2, T_2) \in X \times X$. Suppose that 
		$$\|(S_1, T_1) - (S_2, T_2) \|= \max \{ \|S_2 -S_2 \|, \|T_1 - T_2 \|\} < \del$$ 
		Then 
		\begin{align*}
			\|S_1T_1 - S_2T_2 \|
			&= \|S_1T_1 - S_2T_1 +S_2T_1 - S_2T_2 \|\\
			& \leq \|S_1 -S_2 \|\|T_1 \|+ \|S_2 \|\|T_1 - T_2 \|\\
			& \leq \|S_1 -S_2 \|\|T_1 \|+ \big( \|S_1-S_2 \|+ \|S_1 \|\big) \|T_1 - T_2 \|\\
			& \leq \del \|T_1 \|+(\del + \|S_1 \|) \del \\
			&= \del (\|S_1 \|+ \|T_1 \|) + \del^2 \\
			& < \frac{\ep}{2} + \frac{\ep}{2}\\
			&= \ep
		\end{align*}
	\end{proof}
	
	
	\begin{ex}
		Let $X$ be a unital Banach algebra. Then 
		\begin{enumerate}
			\item For each $T \in X$, if $\|I- T \|< 1$, then $T \in GL(X)$ and $$T^{-1} = \sum_{n=0}^{\infty}(I-T)^n$$
			\item For each $S,T \in X$, if $S \in GL(X)$  and $\|S-T \|< \|S^{-1} \|^{-1}$, then $T \in GL(X)$. 
			\item $GL(X)$ is open.
		\end{enumerate}
	\end{ex}
	
	\begin{proof}\
		\begin{enumerate}
			\item Let $T \in X$. Suppose that $\|I-T \|< 1$. Then $$\sum_{n=0}^{\infty} \|(I -T)^n \| \leq \sum_{n=0}^{\infty} \|I -T \|^{n} < \infty$$ Since $X$ is a complete, $\sum\limits_{n=0}^{\infty}(I-T)^n$ converges in $X$.\\
			Define $(S_k)_{k=0}^{\infty} \subset X$ and $S \in X$ by $S_k = \sum\limits_{n=0}^{k} (I-T)^n$ and \\ $S = \sum\limits_{n=0}^{\infty}(I-T)^n$. Then for each $k \in \N$,
			\begin{align*}
				S_k T
				&= S_k - S_k(I-T) \\
				&= (I-T)^0 - (I-T)^{k+1} \\
				&= I - (I-T)^{k+1}
			\end{align*}
			and $\|S_kT - I \|\leq \|I-T \|^{k+1}$. Since multiplication on Banach algebras is continuous, we have that $$ST = (\lim_{k \rightarrow \infty} S_k)T = \lim\limits_{k \rightarrow \infty}S_kT = I$$
			Similarly $TS = I$. Thus $T \in GL(X)$ and $T^{-1} = S \in X$. \vspace{.5cm}\\
			\item  Let $S, T \in X$. Suppose that $S \in GL(X)$ and $\|S-T \|< \|S^{-1} \|^{-1}$. Then 
			\begin{align*}
				\|I - S^{-1}T \|
				& = \|S^{-1}(S - T) \|\\
				& \leq \|S^{-1} \|\|S -T \|\\
				&< 1
			\end{align*}
			So $S^{-1}T \in GL(X)$. Thus $T = S (S^{-1}T) \in GL(X)$. \vspace{.5cm}\\
			\item Let $T \in GL(X)$. Choose $\del = \|T^{-1}\|^{-1}$. By (2), $B(T, \del) \subset GL(X)$.
		\end{enumerate}
	\end{proof}	
	
	
	
	\newpage
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	\newpage
	\section{Hilbert Spaces}
	
	\subsection{Introduction}
	
	\begin{defn}
		Let $H$ be a vector space and $\l \cdot, \cdot \r: H \rightarrow \C$. Then $\l \cdot, \cdot \r$ is said to be an \textbf{inner product} on $H$ if for each $x,y,z \in H$and $c \in \C$
		\begin{enumerate}
			\item $\l x , y + cz\r = \l x , y \r + c\l x , z\r $
			\item $\l x , y \r = \l y , x\r^*$
			\item $\l x , x \r \geq 0$
			\item if $\l x ,x \r = 0$, then $x = 0$.  
		\end{enumerate}
	\end{defn}
	
	\begin{note}
	In mathematics, inner products are conventionally defined to be linear in the first argument. However, in my opinion, the convention in physics of defining inner products to be linear in the second argument makes more sense.
	\end{note}
	 
	\begin{ex}
	Let $H$ be an inner product space, $(x_j)_{j =1}^n$, $(y_j)_{j =1}^n \subset H$ and $(\al_j)_{j=1}^n$, $(\be_j)_{j=1}^n \subset \C$. Then $$\bigg \l \sum_{i=1}^n \al_i x_i , \sum_{j=1}^n \be_j y_j \bigg \r = \sum_{i=1}^n \sum_{j=1}^n \al_i^*\be_j \l x_i , y_j \r $$
\end{ex}

\begin{proof}
Clear.
\end{proof}

\begin{defn}
Let $H$ be an inner product space. Define the \textbf{induced norm}, denoted $\|\cdot \|: H \rightarrow \C$, by $$\|x\| = \l x, x\r^{\frac{1}{2}}$$
\end{defn}

\begin{ex} \textbf{Cauchy-Schwarz Inequality}\\
Let $H$ be an inner product space. Then for each $x,y \in H$, $| \l x, y\r | \leq \|x\| \| y\|$ and $| \l x, y\r | = \|x\| \| y\|$ iff $x \in \spn(y)$. \\
\textbf{Hint:} For $x, y \in H$, put $z = \sgn\l x, y \r^*y$ and Consider $f: \R \rightarrow \Rg$ defined by $f(t) = \|x - tz\|^2$
\end{ex}

\begin{proof}
Let $x,y \in H$. If $y = 0$, then the claim holds trivially. Suppose that $y \neq 0$. Put $z = \sgn\l x, y \r^*y$. So $\l x, z\r = |\l x,y \r |$ and $\|z\| = \|y\|$. Define $f: \R \rightarrow \Rg$ by $$f(t) = \|x - tz\|^2$$. Then for each $t \in \R$, 
\begin{align*}
0 
& \leq f(t) \\
&=  \|x - tz\|^2 \\
&= \|x\|^2 + |t|^2\|z\|^2 - 2 \Re(t \l x,z \r) \\
&= \|x\|^2 + t^2\|y\|^2 - 2 t |\l x,y \r| \\
\end{align*} 
Thus $f$ is a quadratic with a minimum at $t_0 = \frac{|\l x, y \r|}{\|y\|^2}$. Hence 
\begin{align*}
0 
&\leq f(t_0) \\
&= \|x\|^2 +  \frac{|\l x, y \r|}{\|y\|^2} - 2\frac{|\l x, y \r|}{\|y\|^2} \\
& = \|x\|^2 -  \frac{|\l x, y \r|}{\|y\|^2}
\end{align*}
Which implies that $$| \l x, y\r |^2 \leq \|x\|^2 \| y\|^2$$ and hence the claim holds. Clearly if $x \in \spn(y)$, then equality holds. Conversely, if equality holds, then $x-z = 0$ which implies that $x \in spn(y)$.
\end{proof}

\begin{ex}
Let $H$ be an inner product space. Then the induced norm, $\| \cdot\|: H \rightarrow \C$, is a norm. 
\end{ex}

\begin{proof}Let $x,y \in H$ and $c \in \C$. Then
\begin{enumerate}
\item By definition, if $\|x\| = 0$, then $\l x, x \r =0$, which implies that $x =0$.
\item Note that 
\begin{align*}
\| cx \|^2 
&= \l cx, cx \r \\
&= c*c \l x, x\r \\
&= |c|^2\| x \|^2
\end{align*}
So $\| cx \| = |c|\|x\|$
\item The Cauchy-Schwarz inequality implies that
\begin{align*}
\|x + y\|^2 
&= \|x\|^2 + \|y\|^2 + 2 \Re(\l x, y\r) \\
& \leq \|x\|^2 + \|y\|^2 + 2 |\l x, y\r | \\
& \leq \|x\|^2 + \|y\|^2 + 2 \|x\| \|y\| \\
&= (\|x\| + \|y\|)^2
\end{align*}
Hence $\|x + y\| \leq \|x\| + \|y\|$.
\end{enumerate}
\end{proof}

\begin{defn}
	Let $H$ be an inner product space, $x, y \in H$ and $S \subset H$. Then
	\begin{enumerate}
	\item $x$ and $y$ are said to be \textbf{orthogonal} if $\l x,y\r = 0$. 
	\item $S$ is said to be \textbf{orthogonal} if for each $x,y \in S$, $x,y$ are orthogonal. 
	\end{enumerate}
\end{defn}

\begin{ex}\textbf{(Pythagorean theorem):}\\
	Let $H$ be an inner product space and $(x_j)_{j =1}^n \subset H$ an orthogonal set. Then $$\bigg \|\sum\limits_{j = 1}^n x_j  \bigg \|^2 = \sum\limits_{j =1}^n \|x_j \|^2$$
\end{ex}

\begin{proof}
	We have that
	\begin{align*}
		\bigg \| \sum\limits_{j = 1}^n  x_j\bigg \|^2
		&= \bigg \l \sum\limits_{i =1}^n x_i , \sum\limits_{j =1}^n x_j \bigg \r \\
		&= \sum\limits_{i =1}^n \sum\limits_{j =1}^n \l x_j , x_j \r \\
		&= \sum\limits_{j =1}^n \l x_j , x_j \r \\
		&= \sum\limits_{j =1}^n \| x_j \|^2
	\end{align*}
\end{proof}

\begin{ex}
	Let $H$ be an inner product space and $S \subset H$. Suppose that $0 \not \in S$. If $S$ is orthogonal, then $S$ is linearly independent.
\end{ex}

\begin{proof}
	Let $x_1, \cdots, x_n \in S$ and $c_1, \cdots, c_n \in \C$. Suppose that $\sum\limits_{j =1}^n c_j x_j = 0 $. Since $(c_j x_j)_{j=1}^n$ is orthogonal, the Pythagorean theorem implies that 
	\begin{align*}
		0
		&= \bigg \| \sum_{i=1}^n c_i x_i \bigg \| \\
		&= \sum_{j=1}^n  |c_j|^2 \| x_j\| 
	\end{align*}
	So for each $j \in \{ 1 , \cdots, n\}$, $c_j = 0$ and $S$ is linearly independent.
\end{proof}

\begin{defn}
	Let $H$ be an inner product space and $S \subset H$. Then $S$ is said to be \textbf{orthonormal} if $S$ is orthogonal and for each $x \in S$, $\|x \| = 1$.
\end{defn}

\begin{ex}\textbf{Bessel's Inequality:}\\
Let $H$ be an inner product space and $S \subset H$. If $S$ is orthonormal, then for each $x \in H$, $$\sum_{u \in S} | \l u, x \r |^2  \leq \|x\|$$
and in particular, $\{u \in S: \l u, x\r \neq 0\}$ is countable.
\end{ex}

\begin{proof}
Suppose that $S$ is orthonormal. Let $x \in H$ and $F \subset S$ finite. Then the Pythagorean theorem implies that  
\begin{align*}
0 
& \leq \bigg \|x - \sum_{u \in F} \l u, x \r u \bigg \|^2 \\
&= \|x\|^2 + \bigg \| \sum_{u \in F} \l u, x \r u \bigg \|^2 - 2 \Re \bigg \l x, \sum_{u \in F} \l u, x \r u \bigg \r  \\
&= \|x\|^2 +  \sum_{u \in F} |\l u, x \r|^2 \|u\|^2 - 2 \sum_{u \in F} | \l u, x \r|^2  \\
&= \|x\|^2 -  \sum_{u \in F} |\l u, x \r|^2 
\end{align*}
So $$\sum_{u \in F} | \l u, x \r |^2  \leq \|x\|$$
By definition of the sum, $$\sum_{u \in S} | \l u, x \r |^2  \leq \|x\|$$
Basic integration theory then tells us that $\{u \in S: \l u, x\r \neq 0\}$ is countable.
\end{proof}

\begin{defn}
	Let $H$ be an inner product space. Then $H$ is said to be a \textbf{Hilbert space} if $H$ is a complete with respect to the induced norm on $H$.
\end{defn}

\begin{ex}
Let $H$ be a Hilbert space and $S \subset H$. Suppose that  $S$ is orthonormal. Then the followong are equivalent: 
\begin{enumerate}
\item For each $x \in H$, if for each $u \in S$, $\l u, x \r = 0$, then $x =0$.
\item For each $x \in H$, there exist $(u_j)_{j\in \N} \subset S$ such that $x = \sum\limits_{j \in \N} \l u_j, x\r u_j$ and for each $u \not \in (u_j)_{j\in \N}$, $\l u, x\r =0$.
\item For each $x \in H$, $\|x\|^2 = \sum\limits_{u \in S} | \l u, x \r |^2$.
\end{enumerate}
\end{ex}

\begin{proof}\
\begin{itemize}
		\item $(1) \implies (2)$:\\
		Suppose that for each $x \in H$, if for each $u \in S$, $\l u, x \r = 0$, then $x =0$. Let $x \in H$. Put $S_{*} = \{u \in S: \l u, x \r \neq 0 \}$. The previous exercise implies that $S_{*}$ is countable. Write $S_* = (u_j)_{j=1}^n$. The previous exercise tells us that $\sum\limits_{j \in \N} |\l u_j, x \r|^2 \leq \|x\|^2$ and hence converges. Thus for $\ep >0$, there exist $N \in \N$ such that for each  $m,n \in \N$, $m, n \geq N$ implies that if $m < n$, then $$\sum_{m+1}^{n} |\l u_j, x \r |^2 < \ep$$
		Define $(y_n)_{n \in \N} \subset H$ by $$y_n = \sum_{j=1}^{n} \l u_j, x \r u_j$$ 
		Then for each $m,n \in \N$, $m, n \geq N$ implies that if $m < n$, then 
		\begin{align*}
		\|y_n - y_m\|^2 
		& = \bigg \|\sum_{1}^{n} \l u_j, x \r u_j  - \sum_{1}^{m} \l u_j, x \r u_j  \bigg \|^2 \\
		&= \bigg \|\sum_{m+1}^{n} \l u_j, x \r u_j \bigg \|^2 \\
		&= \sum_{m+1}^{n} |\l u_j, x \r |^2 \\
		& < \ep
		\end{align*}
		So $(y_n)_{n \in \N}$ is Cauchy. Since $H$ is complete, there exists $y \in H$ such that $y_n \rightarrow y$. By definition, $$y = \sum\limits_{j \in \N}\l u_j, x \r u_j $$
		Continuity of $\l \cdot, \cdot\r: H \times H \rightarrow \C$ implies that 
		\begin{enumerate}
		\item for each $u \in S \setminus  S_*$, 
		\begin{align*}
		\l u, x - y\r 
		&= \l u, x \r  - \l u, y \r \\
		&=  \l u, x \r - \limn \l u, y_n\r \\
		&=  \l u, x \r - \limn \sum_{j=1}^n \l u_j, x\r \l u, u_j \r \\
		&= 0 - 0 \\
		&=0
		\end{align*}
		\item for each $k \in \N$, 
		\begin{align*}
		\l u_k, x - y\r 
		&= \l u_k, x \r  - \l u_k, y \r \\
		&= \l u_k, x \r - \limn \l u_k, y_n\r \\
		&= \l u_k, x \r - \limn \sum_{j=1}^n \l u_j, x\r \l u_k, u_j \r \\
		&= \l u_k, x \r  - \l u_k, x\r \\
		&= 0
		\end{align*}
		\end{enumerate}
		So for each $u \in S$, $\l u, x-y\r =0$. By assumption, $x-y = 0$ and hence 
		$$x = \sum\limits_{j \in \N}\l u_j, x \r u_j$$
		
		\item $(2) \implies (3)$:\\
		Suppose that for each $x \in H$, there exist $(u_j)_{j\in \N} \subset S$ such that $x = \sum\limits_{j \in \N} \l u_j, x\r u_j$ and for each $u \not \in (u_j)_{j\in \N}$, $\l u, x\r =0$. Then continuity of $\|\cdot\|:H \rightarrow \Rg$ implies that
		\begin{align*}
		\|x\|^2 
		&= \bigg \|  \limn \sum_{j=1}^n \l u_j, x\r u_j \bigg \|^2 \\
		&= \limn \bigg \|\sum_{j=1}^n \l u_j, x\r u_j \bigg \|^2 \\
		&= \limn \sum_{j=1}^n |\l u_j, x\r |^2 \\
		&= \sum_{j \in \N}|\l u_j, x\r |^2  \\
		&= \sum_{u \in S}|\l u, x\r |^2 
		\end{align*}
		\item $(3) \implies (4)$:\\
		Suppose that for each $x \in H$, $\|x\|^2 = \sum\limits_{u \in S} | \l u, x \r |^2$. Let $x \in H$. Suppose that for each $u \in S$, $\l u,x \r = 0$. Then 
		\begin{align*}
		\| x\|^2 
		&= \sum_{u \in S}  | \l u, x \r |^2 \\
		&= 0
		\end{align*}
		So $x =0$
\end{itemize}
\end{proof}

\begin{defn}
	Let $H$ be a Hilbert space and $S \subset H$. Then $S$ is said to be an \textbf{orthonormal basis of $H$} if 
	\begin{enumerate}
	\item $S$ is orthonormal
	\item for each $x \in H$, if for each $u \in S$, $\l u, x \r = 0$, then $x =0$
	\end{enumerate}
\end{defn}





\newpage

\subsection{Operators and Functionals}

\begin{defn}\textbf{(Adjoint of an Operator):} \\
	Let $H$ be a Hilbert space and $A,B \in L(H)$. Then $B$ is said to be the \textbf{adjoint} of $A$ if for each $x_1$, $x_2 \in H$, $$\l x_1 , Ax_2 \r = \l B x_1 , x_2 \r$$  In this case, we write $$B = A^{*}$$
\end{defn}

\begin{note}
	In physics, the adjoint of $A$ is typically denoted by $A^{\dagger}$.
\end{note}

\begin{ex}
	Let $H$ be a Hilbert space, $A, B \in L(H)$ and $\lam \in \C$, then \begin{enumerate}
		\item $(A^{*})^{*} = A$
		\item $(A + B)^{*} = A^{*} + B^{*}$
		\item $(AB)^{*} = B^{*}A^{*}$
		\item $(\lam A)^{*} = \lam^*A^{*}$
		\item $A$ and $B$ commute iff $A^{*}$ and $B^{*}$ commute.
	\end{enumerate}
\end{ex}

\begin{proof} Let $x_1$, $x_2 \in H$. Then
	\begin{enumerate}
		\item 
		\begin{align*}
			\l A x_1 , x_2 \r
			&= \l x_2 , A x_1 \r^*\\
			&= \l A^{*}x_2 ,  x_1 \r^* \hspace{.5cm} \text{(by definition)}\\
			&= \l  x_1 , A^{*}x_2 \r
		\end{align*}
		\item 
		\begin{align*}
			\l x_1 , (A+B) x_2 \r 
			&= \l x_1 , A x_2 \r + \l x_1 , B x_2 \r \\
			&= \l A^{*} x_1 , x_2 \r + \l B^{*} x_1 , x_2 \r \\
			&= \l (A^{*} + B^{*})  x_1 , x_2 \r  \\
		\end{align*}
		\item 
		\begin{align*}
			\l x_1 , AB x_2 \r  
			&= \l A^{*}x_1 , B x_2 \r \\
			&= \l B^{*} A^{*} x_1 , x_2 \r 
		\end{align*}
		\item 
		\begin{align*}
			\l x_1 , \lam A x_2 \r 
			&= \lam \l x_1 , A x_2 \r \\
			&= \lam \l A^{*}x_1 , x_2 \r \\
			&= \l \lam^* A^{*} x_1 , x_2 \r 
		\end{align*}
		\item If $A$ and $B$ commute, then 
		\begin{align*}
			A^{*}B^{*}
			&= (BA)^{*} \\
			&= (AB)^{*} \\
			&= B^{*}A^{*}
		\end{align*}
		Conversely, if $A^{*}$ and $B^{*}$ commute then 
		\begin{align*}
			AB
			&= (B^{*}A^{*})^{*} \\
			&= (A^{*}B^{*})^{*} \\
			&= BA
		\end{align*}
	\end{enumerate}
\end{proof}

\begin{defn}
	Let $H$ be a Hilbert space and $Q \in L(H)$. Then $Q$ is said to be \textbf{self-adjoint} if $$Q = Q^{*}$$
\end{defn}

\begin{ex}
	Let $H$ be a Hilbert space and $Q \in L(H)$. If $Q$ is a self-adjoint then 
	\begin{enumerate}
		\item the eigenvalues of $Q$ are real.
		\item the eigenvectors of $Q$ corresponding to distinct eigenvalues are orthogonal.
	\end{enumerate}
\end{ex}

\begin{proof}
	Suppose that $Q$ is self-adjoint.
	\begin{enumerate}
		\item Let $\lam$ be an eigenvalue of $Q$ with corresponding eigenvector $x$. Then 
		\begin{align*}
			\lam \l x , x\r
			&= \l x , Q x\r \\
			&= \l Q x , x\r \\
			&= \lam^* \l x , x\r
		\end{align*}
		Thus $\lam = \lam^*$ and is real
		
		\item Let $\lam_1$ and $\lam_2$ be eigenvalues of $Q$ with corresponding eigenvectors $x_1$ and $x_2$. Suppose that $\lam_1 \neq \lam_2$. Then 
		\begin{align*}
			\lam_2 \l x_1 ,  x_2\r
			&= \l x_1 , Q x_2\r\\
			&= \l Q x_1 ,  x_2\r\\
			&= \lam_1 \l x_1 ,  x_2\r
		\end{align*}
		So $(\lam_2 - \lam_1)\l x_1 ,  x_2\r = 0$. Which implies that $\l x_1 ,  x_2\r=0$
	\end{enumerate}
\end{proof}

\begin{ex}
	Let $H$ be a Hilbert space, $A, B \in L(H)$ and $ \lam \in \R$. Suppose that $A, B$ are self-adjoint. If $A$ and $B$ commute and then $\lam AB$ is self-adjoint.
\end{ex}

\begin{proof}
	\begin{align*}
		(\lam AB)^{*}
		&= \lam^* (AB)^{*} \\
		&= \lam B^{*} A^{*} \\
		&= \lam B A \\
		&= \lam AB
	\end{align*}
\end{proof}

\begin{defn}\textbf{(Adjoint of a Vector):} \\
	Let $H$ be a Hilbert space and $x \in H$. We define the \textbf{adjoint} of $x$, denoted $x^* \in H^*$, by $x^* y = \l x, y \r$. 
\end{defn}

\begin{note}
	In mathematics, where linearity of the inner product is in the first argument, $x^{*}$ is typically referred to by $u_{x} \in H^{*} $ where $u_{x}(y) = \l y, x\r$. In physics, where the inner product with linearity in the second argument, $x^{*} \phi$ is usually written in the so-called ``bra-ket" notation as $\l x | \phi \r$ which works smoothly since it aligns with the linearity of $u_{x}(\phi_1 + \lam \phi_2)$ and the conjugate-linearity of $u_{x_1 + \lam x_2}(\phi)$. In this way, it generalizes the notation for $\l x, y\r = x^T y$ for $\R^n$ to $\l x, y\r = x^*y^*$ for $\C^n$. 
\end{note}

\begin{ex}
	Let $H$ be a Hilbert space, $x, y \in H$ and $\lam \in \C$. Then 
	\begin{enumerate}
		\item $(x + y)^* =  x^* + y^*$
		\item $(\lam x)^* = \lam^* x^*$
	\end{enumerate}
\end{ex}

\begin{proof}
	Clear.
\end{proof}

\begin{defn}
	Let $H$ be a Hilbert space, $x, y \in H$ and $A \in L(H)$. We define 
	\begin{enumerate}
		\item $x^* A \in H^*$ by $(x^*A) y = x^*(A y)$
		\item $x y^* \in L(H)$ by $(x y^*) z = (y^*z) x$
	\end{enumerate}
\end{defn}

\begin{ex}
	Let $H$ be a Hilbert space, $A \in L(H)$ and $x \in H$. Then $$(A x)^*= x^*A^*$$
\end{ex}

\begin{proof}
	Let $y \in H$. Then 
	\begin{align*}
		(Ax)^*	y 
		&= \l Ax, y \r \\
		&= \l x, A^* y \r \\
		&= x^*A^* y
	\end{align*}
\end{proof}

\begin{defn}\textbf{(Commutator):} \\
	Let $H$ be a Hilbert space and $A, B \in L(H)$. The \textbf{commutator} of $A$ and $B$, denoted $[A,B]$, is defined by $$[A,B] = AB - BA$$
\end{defn}

\begin{ex}
	Let $H$ be a Hilbert space and $A,B, C \in L(H)$. Then 
	\begin{enumerate}
		\item $[AB,C] = A[B,C] + [A,C]B$
		\item $[A, BC] = B[A, C] + [A,B]C$
	\end{enumerate}
\end{ex}

\begin{proof} \
	\begin{enumerate}
		\item 
		\begin{align*}
			[AB,C]
			&= ABC - CAB\\
			&= ABC - ACB + ACB -CAB\\
			&= A(BC - CB) + (AC-CA)B\\
			&= A[B,C] + [A,C]B
		\end{align*}
		\item Similar to (1).
	\end{enumerate}
\end{proof}

%\begin{defn}\textbf{(Tensor Product):} \\ 
%	Let $H_1, H_2$ be Hilbert spaces. Define $$\otimes: H_1 \times H_2 \rightarrow \C^{H_1 \times H_2} ,\hspace{.5cm} (x, \phi) \mapsto x \otimes \phi$$ by $$x \otimes \phi(x,y) = \l x, x  \r \l y, \phi\r$$ 
%\end{defn}
%
%\begin{note}
%	For the remainder of this section, we assume that $H_1$ and $H_2$ are Hilbert spaces.
%\end{note}
%
%\begin{ex}
%	We have that $\otimes: H_1 \times H_2 \rightarrow \C^{H_1 \times H_2}$ is bilinear.
%\end{ex}
%
%\begin{proof}
%	Clear.
%\end{proof}
%
%\begin{defn}
%	Define $T(H_1, H_2) = \spn \{x \otimes \phi: x \in H_1 \text{ and } \phi \in H_2\}$ and define $\l \cdot, \cdot \r : T(H_1, H_2) \rightarrow \C $ by $$\l x_1 \otimes \phi_1 , x_2 \otimes \phi_2 \r = \l x_1, x_2 \r \l \phi_1 ,  \phi_1\r$$ and extending sesquilinearly so that $$ \l \sum_{i=1}^m \al_i x_i \otimes \phi_i , \sum_{j=1}^n \beta_j \Xi_j \otimes \Gam_j\r = \sum_{i=1}^m \sum_{j=1}^n \al_i^* \beta_j \l x_i \otimes \phi_i,  \Xi_j \otimes \Gam_j \r$$
%\end{defn}
%
%\begin{ex}
%	We have that  $\l \cdot, \cdot \r : T(H_1, H_2) \rightarrow \C $ is an inner product on $T(H_1, H_2)$.
%\end{ex}
%
%\begin{proof} 
%	Clear.
%\end{proof}
%
%\begin{defn}
%	Define $H_1 \otimes H_2$ to be the completion of $T(H_1, H_2)$.
%\end{defn}
%	
%
%	\begin{ex}
%		Let $H_1, H_2$ be Hilbert spaces. If $(x_j)_{j\in \N}$ is an orthonormal basis for $H_1$ and $(\phi_j)_{j \in \N}$ is an orthonormal basis for $H_2$, then $(x_i \otimes \phi_j)_{i,j \in \N}$ is an orthonormal basis for $H_1 \otimes H_2$. 
%	\end{ex}
%
%	\begin{proof}
%		Since 
%		\begin{align*}
%			\l x_{i_1} \otimes \phi_{j_1} , x_{i_2} \otimes \phi_{j_2} \r 
%			&= \l x_{i_1} , x_{i_2} \r \l \phi_{j_1} , \phi_{j_2} \r \\
%			&= \del_{i_1, i_2} \del_{j_1, j_2}
%		\end{align*}
%		we have that $(x_i \otimes \phi_j)_{i,j \in \N}$ is orthonormal. Let $x = \sum\limits_{i \in \N} a_i x_i \in H_1$ and $\phi = \sum\limits_{j \in \N} b_j \phi_j \in H_2$. Then $\phi \otimes x = \sum\limits_{i \in \N} \sum\limits_{j \in \N} a_ib_j x_i \otimes \phi_j$, so $(x_i \otimes \phi_j)_{i,j \in \N}$ is a dense subset of $T(H_1, H_2)$, which is dense in $H_1 \otimes H_2$. Hence $(x_i \otimes \phi_j)_{i,j \in \N}$ is dense in $H_1 \otimes H_2$ and is a basis.
%	\end{proof}
%
%	\begin{note}
%		If $H_1$ and $H_2$ are function spaces over sets $S_1$ and $S_2$ respectively, then $H_1 \otimes H_2$ can be identified with the function space over $S_1 \times S_2$ given by  $f_1 \otimes f_2(s_1, s_2) = f_1(s_1)f_2(s_2)$.
%	\end{note}
%
%	\begin{defn}
%		Let $A$ and $B$ be operators on $H_1$ and $H_2$ respectively. We define the operator $A \otimes B$ on $H_1 \otimes H_2$ by setting $$A \otimes B (x \otimes \phi) = A x \otimes B \phi$$ and extending linearly to $T(H_1, H_2)$ and then extending continuously to $H_1 \otimes H_2$
%	\end{defn}


	
	
	
	
	
	
	
	
	
	
	
	
	
	\newpage
	\section{Differentiation}
	
	\subsection{The Gateaux Derivative}
	
	\begin{note}
	In this section, we assume all Banach spaces to be over $\R$. 
	\end{note}
	
	\begin{defn}
	Let $X,Y$ be a Banach spaces, $A \subset X$ open, $f:A \rightarrow Y$, $x_0 \in A$ and $x \in X$. Then $f$ is said to be 
	\begin{enumerate}
	\item \textbf{right-hand-differentiable at $x_0$ in the direction $x$} if the limit
	$$  \lim_{t \rightarrow 0^+} \frac{f(x_0 +tx) - f(x_0)}{t}$$
	exists. If $f$ is right-hand-differentiable at $x_0$ in the direction $x$, we define the \textbf{right-hand derivative} of $f$ at $x_0$ in the direction $x$, denoted by  $d^+ f(x_0; x)$, to be the above limit. 
	
	\item \textbf{left-hand-differentiable at $x_0$ in the direction $x$} if the limit
	$$  \lim_{t \rightarrow 0^-} \frac{f(x_0 +tx) - f(x_0)}{t}$$
	exists. If $f$ is right-hand-differentiable at $x_0$ in the direction $x$, we define the \textbf{left-hand derivative} of $f$ at $x_0$ in the direction $x$, denoted by  $d^- f(x_0; x)$, to be the above limit. 
	
	\item \textbf{differentiable at $x_0$ in the direction $x$} if the limit
	$$  \lim_{t \rightarrow 0} \frac{f(x_0 +tx) - f(x_0)}{t}$$
	exists. If $f$ is differentiable at $x_0$ in the direction $x$, we define the \textbf{derivative} of $f$ at $x_0$ in the direction $x$, denoted by  $d f(x_0; x)$, to be the above limit. 
	\end{enumerate}
	\end{defn}	
	
	\begin{ex}
	Let $X, Y$ be Banach spaces, $A \subset X$ open, $f:A \rightarrow \R$ and $x_0 \in A$. Then $df(x_0; 0) = 0$.
	\end{ex}
	
	\begin{proof}
	Clear.
	\end{proof}
	
	\begin{defn}\textbf{The Gateaux Derivative:}\\
	Let $X,Y$ be Banach spaces, $A \subset X$ open, $f:A \rightarrow Y$ and $x_0 \in A$. Then $f$ is said to be 
	\begin{enumerate}
	\item \textbf{right-hand Gateaux differentiable} at $x_0$ if for each $x \in X$, $d^+ f(x_0; x)$ exits. We define the \textbf{right-hand Gateaux derivative} of $f$ at $x_0$, denoted $d^+ f(x_0) : X \rightarrow \R$, to be $$d^+ f(x_0)(x) = d^+ f(x_0;x)$$ 
	
	\item \textbf{left-hand Gateaux differentiable} at $x_0$ if for each $x \in X$, $d^- f(x_0; x)$ exits. We define the \textbf{left-hand Gateaux derivative} of $f$ at $x_0$, denoted $d^- f(x_0) : X \rightarrow \R$, to be $$d^- f(x_0)(x) = d^- f(x_0;x)$$
	
	\item \textbf{Gateaux differentiable} at $x_0$ if for each $x \in X$, $d f(x_0; x)$ exits. We define the \textbf{Gateaux derivative} of $f$ at $x_0$, denoted $d f(x_0) : X \rightarrow \R$, to be $$d f(x_0)(x) = d f(x_0;x)$$
	\end{enumerate}
	\end{defn}
	
	\begin{defn}
Let $Y$ be a Banach space, $A \subset \R$ open and $f:A \rightarrow Y$. Then $f$ is said to be \textbf{Gateaux differentiable} if for each $x \in A$, $f$ is Gateaux differentiable at $x$. If $f$ is Gateaux differentiable, we define $df:A \rightarrow Y^X$ by $x_0 \mapsto df(x_0)$.
\end{defn}	
	
	\begin{ex}
	Let $X, Y$ be Banach spaces, $A \subset X$ open, $f,g :A \rightarrow Y$, $\lam \in \R$ and $x_0 \in A$. If $f, g$ are Gateaux differentiable at $x_0$, then $f + \lam g$ Gateaux differentiable at $x_0$ and $d[f+\lam g](x_0) = df(x_0) + \lam dg(x_0)$.
	\end{ex}
	
	\begin{proof}
	Similar to the case of the derivative from Calc I. 
	\end{proof}		
	
	\begin{ex}
	Let $X, Y$ be Banach spaces, $A \subset X$ open, $f:A \rightarrow Y$ and $x_0 \in A$. Suppose that $f$ is Gateaux differentiable at $x_0$. Then for each $\lam \in \R$ and $x \in X$, $$df(x_0)(\lam x) = \lam df(x_0)(x)$$
	\end{ex}
	
	\begin{proof}
	Let $\lam \in \R$ and $x \in X$. Then 
	\begin{align*}
	df(x_0)(\lam x) 
	&= \lim_{t \rightarrow 0} \frac{f(x_0 + t \lam x) - f(x_0)}{t} \\
	&= \lim_{t \rightarrow 0} \lam \frac{f(x_0 + t \lam x) - f(x_0)}{\lam t} \\
	&= \lam \lim_{t \rightarrow 0}  \frac{f(x_0 + t \lam x) - f(x_0)}{\lam t} \\
	&= \lam \lim_{t \rightarrow 0}  \frac{f(x_0 + t x) - f(x_0)}{t} \\
	&= \lam df(x_0)(x) 
	\end{align*}
	\end{proof}
	
	\begin{ex}
	Let $X$ be a Banach space, $A \subset \R$ open, $f:A \rightarrow \R$ and $x_0 \in A$. Suppose that $f$ is Gateaux differentiable at $x_0$. Then $df(x_0) \in L(\R,Y)$.
	\end{ex}
	
	\begin{proof}
	Let $x,y ,lam \in \R$. 
	\begin{enumerate}
	\item The previous exercise implies 
	\begin{align*}
	df(x_0)(x + \lam y) 
	&= df(x_0)((x+\lam y)1)  \\
	&= (x+\lam y)df(x_0)(1) \\
	&= xdf(x_0)(1) + \lam y df(x_0)(1) \\
	&= df(x_0)(x) + \lam df(x_0)(y)
	\end{align*}
	So $df(x_0):\R \rightarrow Y$ is linear.
	\item Since 
	\begin{align*}
	\|df(x_0)(x)\| 
	&= \|xdf(x_0)(1)\| \\
	&= |x| \|df(x_0)(1)\| \\
	\end{align*}	
	We have that $df(x_0):\R \rightarrow Y$ is bounded with $\|df(x_0)\| \leq \|df(x_0)(1)\|$. 
	\end{enumerate}
	\end{proof}
	
	\begin{ex}
	Let $X$ be a Banach space, $A \subset X$ open, $f:A \rightarrow \R$ and $x_0 \in A$. If $f$ is Gateaux differentiable at $x_0$ and $f$ has a local extremum at $x_0$, then $df(x_0) = 0$.
	\end{ex}	
	
	\begin{proof}
	Suppose that $f$ is Gateaux differentiable at $x_0$ and $f$ has a local minimum point at $x_0$. Then there exists $\del >0 $ such that $B(x_0, \del) \subset A$ and for each $y \in B(x_0, \del)$, $f(x_0) \leq f(y)$. \\
	For the sake of contradiction, suppose that $df(x_0) \neq 0$. Then there exists $x \in X$ such that $x \neq 0$ and $df(x_0)(x) \neq 0$. \\
	First, suppose that $df(x_0)(x) < 0$. Choose $\ep = -df(x_0)(x) >0$. Then there exists $t_0 >0$ such that for each $t \in B^*(0, t_0)$, $x_0 + tx \in B(x_0, \del)$ and $$\bigg | \frac{f(x_0 + tx) - f(x_0)}{t} - df(x_0)(x) \bigg | < \ep$$ 
	This implies that for each $t \in B^*(0, t_0)$,
	\begin{align*}
	\frac{f(x_0 + tx) - f(x_0)}{t}  
	&< \ep + df(x_0)(x) \\
	&= 0
	\end{align*} 
	and hence $f(x_0 + tx) < f(x_0)$, which is a contradiction. \\
	Now, suppose that $df(x_0)(x) > 0$. Then 
	\begin{align*}
	df(x_0)(-x) 
	&= -df(x_0)(x) \\
	& < 0
	\end{align*}
	Similarly to above, this implies that there exists $t_0 >0$ such that for each $t \in B^*(0, t_0)$, $x_0 - tx \in B(x_0, \del)$ and $f(x_0 - tx) < f(x_0)$ which is a contradiction. So $df(x_0)(x) = 0$ and $df(x_0) = 0$. \\
	If $f$ has a local maximum at $x_0$, then $-f$ has a local minimum point at $x_0$. Then 
	\begin{align*}
	df(x_0)
	&= -d[-f](x_0) \\
	&= -0 \\
	&= 0
\end{align*}	 
	\end{proof}
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	\newpage
	\subsection{The Frechet Derivative}
	
	\begin{ex}
	Let $X,Y$ be a normed vector spaces and $\phi: X \rightarrow Y$ linear. If $\phi(h) = o(\|h\|)$ as $h \rightarrow 0$, then $\phi = 0$. 
	\end{ex}
	
	\begin{proof}
	Let $h_0 \in X$. If $h_0 = 0$, then $\phi(h_0) = 0$. Suppose that $h_0 \neq 0$. Define $(h_n)_{n \in \N} \subset X$ by $$h_n = \frac{h_0}{n}$$ Then $h_n \rightarrow 0$. By continuity of $\phi$ and our initial assumption we have that 
	\begin{align*}
	\| h_0 \|^{-1} \phi ( h_0 ) 
	&= \phi \bigg( \frac{h_0}{\| h_0 \|} \bigg) \\
	&= \phi \bigg( \frac{h_n}{\| h_n \|} \bigg) \\
	&= \frac{\phi(h_n)}{\| h_n \|} \\
	& \rightarrow 0
	\end{align*}
	which implies that $\| h_0 \|^{-1}\phi ( h_0 ) = 0$. So $\phi(h_0) = 0$ and hence $\phi = 0$.
	\end{proof}
	
	\begin{ex}
	Let $X, Y$ be a normed vector spaces, $A \subset X$ open, $f:A \rightarrow Y$ and $x_0 \in A$. Suppose that there exists $\phi: X \rightarrow Y$ such that $\phi$ is linear and $$f(x_0 + h) = f(x_0) + \phi(h) + o(\|h\| ) \hspace{.5cm} \text{ as } h \rightarrow 0$$ then $\phi$ is unique. 
	\end{ex}
	
	\begin{proof}
	Suppose that there exists $\psi : X \rightarrow Y$ such that $\psi$ is linear and such that
	$$f(x_0 + h) = f(x_0) + \psi(h) + o(\|h\| ) \hspace{.5cm} \text{ as } h \rightarrow 0$$ 
	Then $\phi(h) - \psi(h) = o(h)$. Since $\phi - \psi$ is linear, the previous exercise implies that $\phi = \psi$.
	\end{proof}
	
	\begin{note}
	Recall that for Banach spaces $X$ and $Y$, there isomorphic isometry $$L(X, L(X, \cdots, L(X, Y)) \cdots) \rightarrow L^n(X, Y)$$ given by $\phi \mapsto \psi_{\phi}$ where $$\psi_{\phi}(x_1, x_2, \cdots, x_n) = \phi(x_1)(x_2),\cdots,(x_n)$$
	\end{note}	
	
	\begin{defn}\textbf{Frechet Derivative:} \\
	Let $X, Y$ be a banach spaces, $A \subset X$ open, $f:A \rightarrow Y$ and $x_0 \in A$. 
	\begin{enumerate}
	\item 
	\begin{itemize}
	\item Then $f$ is said to be \textbf{ Frechet differentiable at $x_0$} if there exists $Df(x_0) \in L(X,Y)$ such that, $$f(x_0 + h) = f(x_0) + Df(x_0)(h) + o(\|h\| ) \hspace{.5cm} \text{ as } h \rightarrow 0$$  
	\item If $f$ is Frechet differentiable at $x_0$, we define the \textbf{ Frechet derivative of $f$ at $x_0$} to be $Df(x_0)$. 
	\item We say that $f$ is \textbf{ Frechet differentiable} if for each $x \in A$, $f$ is Frechet differentiable at $x$. 
	\item If $f$ is Frechet differentiable, we define the \textbf{ Frechet derivative of $f$}, denoted $Df:A \rightarrow L(X, Y)$, by $x \mapsto D^{(1)}f(x)$. 
	\end{itemize}
	\item Continuing inductively, we set $D^0f = f$ and for $n \geq 2$, 
	\begin{itemize}
	\item $f$ is said to be \textbf{$n$-th order Frechet differentiable at $x_0$} if $f$ is $(n-1)$-th order Frechet differentiable and $D^{n-1}f$ is Frechet differentiable at $x_0$. 
	\item If $f$ is $n$-th order Frechet differentiable at $x_0$, we define $D^nf(x_0) \in L^n( X, Y)$ by 
	$$D^nf(x_0) = D[D^{n-1}f](x_0)$$ 
	\item We say that $f$ is \textbf{$n$-th order Frechet differentiable} if $f$ is $(n-1)$-th order Frechet differentiable and for each $x \in A$, $D^{n-1}f$ is Frechet differentiable at $x$. 
	\item If $f$ is $n$-th order Frechet differentiable, we define the \textbf{$n$-th order Frechet derivative of $f$}, denoted $D^nf:A \rightarrow  L^n(X, Y)$ by $x \mapsto D^{n}f(x)$ \\
	\end{itemize}		
	\item If $f$ is $n$-th order differentiable, then $f$ is said to be \textbf{continuously $n$-th order differentiable} if $D^nf$ is continuous. We define $$C^n(A,Y) = \{f:A \rightarrow Y: f \text{ is continuously $n$-th order differentiable}\}$$
	
	\end{enumerate}
	\end{defn}
	
	\begin{ex}
	Let $X, Y$ be a banach spaces, $A \subset X$ open, $f,g:A \rightarrow Y$, $\lam \in \R$ and $x_0 \in A$. If $f$ and $g$ are Frechet differentiable at $x_0$, then $f+ \lam g$ is Frechet differentiable at $x_0$ and $D(f+\lam g)(x_0) = Df(x_0) + \lam Dg(x_0)$.
	\end{ex}
	
	\begin{proof}
	Suppose that $f$ and $g$ are Frechet differentiable at $x_0$. Then $$f(x_0 + h) = f(x_0) + Df(x_0)(h) + o(\|h\| ) \hspace{.5cm} \text{ as } h \rightarrow 0$$  and $$g(x_0 + h) = g(x_0) + Dg(x_0)(h) + o(\|h\| ) \hspace{.5cm} \text{ as } h \rightarrow 0$$  
	This implies that 
	\begin{align*}
	(f+\lam g)(x_0 + h) 
	&= f(x_0 + h) +\lam g(x_0 + h) \\
	&= f(x_0) + Df(x_0)(h) + o(\|h\| ) + \lam g(x_0) + \lam Dg(x_0)(h) + o(\|h\| ) \\
	&= (f+\lam g)(x_0) + [Df(x_0)+ \lam Dg(x_0)](h) + o(\|h\|) \hspace{.5cm} \text{ as } h \rightarrow 0
	\end{align*}
	Since $Df(x_0)+\lam Dg(x_0) \in L(X,Y)$, $f+\lam g$ is Frechet differentiable at $x_0$ and $D(f+\lam g)(x_0) = Df(x_0) + \lam Dg(x_0)$. 
	\end{proof}
	
	\begin{ex}
	Let $X, Y$ be a banach spaces, $A \subset X$ open, $f:A \rightarrow Y$ and $x_0 \in A$. If $f$ is Frechet differentiable at $x_0$, then $f$ is Gateaux differentiable at $x_0$ and $df(x_0) = Df(x_0)$.
	\end{ex}
	
	\begin{proof}
	Suppose that $f$ is Frechet differentiable at $x_0$. Then $f(x_0 + h) = f(x_0) + Df(x_0)(h) + o(\|h\| )$ as $h \rightarrow 0$. Let $x \in X$. Then $f(x_0 + tx) - f(x_0) = tDf(x_0)(x) + o(t)$ as $t \rightarrow 0$. This implies that $f$ is differentiable at $x_0$ in the direction $x$ and 
	\begin{align*}
	df(x_0)(x) 
	&= \lim_{t \rightarrow 0} \frac{f(x_0 + tx) - f(x_0)}{t} \\
	&= Df(x_0)(x)
	\end{align*}
	Since $x \in X$ is arbitrary, $f$ is Gateaux differentiable at $x_0$ and $df(x_0) = Df(x_0)$.
	\end{proof}
	
	\begin{ex}
	Let $X$ be a Banach space, $A \subset X$ open, $f:A \rightarrow \R$ and $x_0 \in A$. If $f$ is Frechet differentiable at $x_0$ and $f$ has a local extremum at $x_0$, then $df(x_0) = 0$.
	\end{ex}	
	
	\begin{proof}
	Suppose that $f$ is Frechet differentiable at $x_0$ and $f$ has a local extremum at $x_0$, then $df(x_0) = 0$. Two previous exercises imply that $f$ is Gateaux differentiable at $x_0$ and 
	\begin{align*}
	Df(x_0) 
	&= df(x_0) \\
	&= 0
	\end{align*}	
	\end{proof}
	
	
	\begin{ex}\textbf{Chain Rule:}\\
	Let $X, Y, Z$ be a Banach spaces, $A \subset X$ open, $B \subset Y$ open, $f:A \rightarrow Y$, $g:B \rightarrow Z$ and $x_0 \in A$. Suppose that $f(x_0) \in B$. If $f$ is Frechet differentiable at $x_0$ and $g$ is Frechet differentiable at $f(x_0)$, then $g \circ f$ is Frechet differentiable at $x_0$ and $$D(g \circ f)(x_0) = Dg(f(x_0)) \circ Df(x_0)$$
	\end{ex}
	
	\begin{proof}
	Suppose that $f$ is Frechet differentiable at $x_0$ and $g$ is Frechet differentiable at $f(x_0)$. Then 
	\begin{enumerate}
	\item $f(x_0 + h) = f(x_0) + Df(x_0)(h) + o(\|h\|) \hspace{.2cm } \text{ as } h \rightarrow 0 $
	\item $g(f(x_0) + k) = g(f(x_0)) + Dg(f(x_0))(k) + o(\|k\|) \hspace{.2cm } \text{ as } k \rightarrow 0 $
	\end{enumerate}
	\end{proof}
	
	\begin{ex}
	Let $Y$ be a Banach space, $A \subset \R$ open and $f:A \rightarrow Y$. Then $f$ is Gateaux differentiable iff $f$ is Frechet differentiable.
	\end{ex}
	
	\begin{proof}
	Suppose that $f$ is Gateaux differentiable. Let $x_0 \in A$. A previous exercise implies that $df(x_0) \in L(\R, Y)$. By defintion, $$  \lim_{h \rightarrow 0} \bigg \| \frac{f(x_0 + h) - f(x_0)}{h} - df(x_0)(1) \bigg \| = 0$$ 
	This is equivalent to saying that $$f(x_0 + h) = f(x_0) + df(x_0)(h) + o(|h|) \hspace{.5cm} \text{ as } h \rightarrow 0$$
	So $f$ is Frechet differentiable at $x_0$ and $Df(x_0) = df(x_0)$.
	\end{proof}
	
	
	
	
	
	
	
	
	\newpage
	\subsection{The Calc I Derivative}
	\begin{defn}\textbf{Calc I Derivative:}\\
	Let $Y$ be a Banach space, $A \subset \R$ open, $f:A \rightarrow Y$ and $x_0 \in A$. 
	\begin{enumerate}
	\item 
	\begin{itemize}
	\item If $f$ is Frechet differentiable at $x_0$, we define the \textbf{calc I derivative of $f$ at $x_0$}, denoted $$f'(x_0) \text{ or } \dv{f}{t}{(x_0)}$$ by
	\begin{align*}
	f'(x_0) 
	&= \lim_{t \rightarrow 0} \frac{f(x_0 + t) - f(x_0)}{t} \\
	&= df(x_0)(1) \\
	&= Df(x_0)(1)
	\end{align*}
	\item If $f$ is Frechet differentiable, we define $f':A \rightarrow Y$ by $x \mapsto f'(x)$. 
	\end{itemize}
	\item Continuing inductively, we set $f^{(0)} = f$ and for $n \geq 2$,
	\begin{itemize}
	\item  if $f^{(n-1)}$ is Frechet differentiable at $x_0$, we define the \textbf{$(n)$-th order calc I derivative of $f$ at $x_0$}, denoted $f^{(n)}(x_0)$, by $$f^{(n)} = [f^{(n-1)}]'$$ 
	\item if $f^{(n-1)}$ is Frechet differentiable, we define $f^{(n)}:A \rightarrow Y$ by $$f^{(n)} = [f^{(n)}]'$$ 
	\end{itemize}
	\end{enumerate}
	\end{defn}	
	
	\begin{ex}
	Let $Y$ be a Banach space, $A \subset \R$ open and $f:A \rightarrow Y$. If $f$ is $n$-th order Frechet differentiable, then for each $x_0 \in A$ and $k \in \{1, \cdots, n\}$, $$f^{(k)}(x_0) = D^kf(x_0)(1^{\oplus k})$$
	\end{ex}
	
	\begin{proof}
	Let $x_0 \in A$. We proceed by induction. The base case is true by definition. Let $k \in \{1, \cdots, n\}$. Suppose the claim is true for $k-1$. Then $$f^{(k-1)}(x_0) = D^{k-1}f(x_0)(1^{\oplus (k-1)})$$
	Since $f$ is $n$-th order Frechet differentiable, $$D^{k-1}f(x_0+h) = D^{k-1}f(x_0) + D^kf(x_0)(h) + o(\|h\|) \hspace{.5cm} \text{ as } h \rightarrow 0$$ 
	This implies that 
	\begin{align*}
	f^{(k-1)}(x_0+h) 
	&=  D^{k-1}f(x_0+h)(1^{\oplus (k-1)}) \\
	&= D^{k-1}f(x_0)(1^{\oplus (k-1)}) + D^kf(x_0)(h)(1^{\oplus (k-1)}) + o(\|h\|) \hspace{.5cm} \text{ as } h \rightarrow 0
	\end{align*}
	Therefore for each $h \in \R$, $$Df^{(k-1)}(x_0)(h) = D^kf(x_0)(h)(1^{\oplus (k-1)})$$
	and by definition,
	\begin{align*}
	f^{(k)}(x_0) 
	&= [f^{(k-1)}]'(x_0) \\
	&= Df^{(k-1)}(x_0)(1) \\
	&=  D^kf(x_0)(1^{\oplus k})
	\end{align*}
	\end{proof}
	
	
	
	
	\begin{ex}
	Let $X,Y$ be Banach spaces, $A \subset X$ open, $f \in C^n(A, Y), x_0 \in A$, and $h \in X$. Suppose that $\{x_0 +tx:T \in [0,1]\} \subset A$. Define and $g:(0,1) \rightarrow Y$ by $$g(t) = f(x_0 + th)$$
	Then for each $k \in \{1 \dots, n\}$ and $t \in (0,1)$, $$g^{(k)}(t) = D^kf(x_0 + th)(h^{\oplus k})$$
	\end{ex}
	
	\begin{proof}
	We proceed by induction. It is straightforward to show that the claim is true for $k=1$.\\
	Let $k \in \{1 \dots, n\}$. Suppose that $g^{(k-1)}(t) = D^{k-1}f(x_0 + th)(h^{\oplus (k-1)})$. Since $f \in C^k(A, Y)$, $$D^{k-1}f(x_0 + s_0h + th)= D^{k-1}f(x_0 + s_0h) + D^k f(x_0 + s_0h)(th) + o(\|t\|) \hspace{.2cm} \text{ as }t \rightarrow 0 $$ 
	The previous exercise implies that 
	\begin{align*}
	g^{(k-1)}(s_0 + t)
	&= D^{k-1}g(s_0+t)(1^{\oplus (k-1)}) \\
	&= D^{k-1}f(x_0 + s_0h + th)(h^{\oplus (k-1)}) \\
	&= D^{k-1}f(x_0 + s_0h)(h^{\oplus (k-1)}) + D^kf(x_0 + s_0h)(th)(h^{\oplus (k-1)}) + o(\|t\|) \hspace{.2cm} \text{ as }t \rightarrow 0
	\end{align*}
	Hence $$Dg^{(k-1)}(s_0)(t) = D^kf(x_0 + s_0h)(th)(h^{\oplus (k-1)})$$ 
	and 
	\begin{align*}
	g^{(k)}(t)
	&= Dg^{(k-1)}(t)(1) \\
	&= D^kf(x_0 + th)(h^{\oplus k})
	\end{align*}
	\end{proof}
	
	
	
	
	
	
	
	\newpage
	\subsection{Taylor's Theorem}	
	
	\begin{note}
	This section makes use of the Bochner integral. For reference, see .
	\end{note}
	\begin{ex}\textbf{Mean Value Theorem:}\\
	Let $X, Y$ be a Banach spaces, $A \subset X$ open and convex and $f:A \rightarrow Y$. If $f$ is Frechet differentiable, then for each $x,y \in A$, there exists $t \in (0,1)$ such that $$\|f(x) - f(y)\| \leq \|Df(tx + (1-t)y)\|\|x-y\|$$
	\textbf{Hint:} For $x,y \in A$ with $f(x) \neq f(y)$, using a Hahn-Banach argument, find $\lam \in Y^*$ such that $\|\lam\| = 1 $ and $\lam (f(x) - f(y)) = \|f(x) - f(y)\|$.
	\end{ex}
	
	\begin{proof}
	Suppose that $f$ is Frechet differentiable. Let $x,y \in A$. The claim is clearly true when $f(x) = f(y)$. Suppose that $f(x) \neq f(y)$. An exercise in the section on linear functionals implies that there exists $\lam \in Y^*$ such that $\lam(f(x)-f(y)) = \| f(x) - f(y)\|$ and $\|\lam \| = 1$
	Define $g:[0,1] \rightarrow \R$ by $$g(t) = \lam(f(tx +(1-t)y))$$ Then $g$ is continuous and (Frechet) differentiable on $(0,1)$ with $$Dg(t)(h) = \lam \circ Df(tx+(1-t)y)((x-y)h)$$ which implies that
	\begin{align*}
	g'(t) 
	&= Dg(t)(1)\\
	&= \lam \circ Df(tx+(1-t)y)((x-y))
	\end{align*}
	The mean value theorem implies that there exists $t \in (0,1)$ such that 
	\begin{align*}
	\|f(x) - f(y)\|
	&= \lam(f(x) - f(y)) \\
	&= g(1) - g(0) \\
	&= g'(t)\\
	&= \lam \circ Df(tx+(1-t)y)((x-y))
	\end{align*}
	Taking absolute values, we see that 
	\begin{align*}
	\|f(x) - f(y)\|
	&= |\lam \circ Df(tx+(1-t)y)((x-y))| \\
	& \leq \|\lam \| \|Df(tx+(1-t)y)\|\|x-y\| \\
	& \leq \|Df(tx+(1-t)y)\|\|x-y\|
	\end{align*}
	\end{proof}
	
	\begin{ex}
	Let $X, Y$ be a Banach spaces, $A \subset X$ open and convex and $f:A \rightarrow Y$. Suppose that $f$ is Frechet differentiable. If for each $x \in A$, $Df(x) = 0$, then $f$ is constant.
	\end{ex}
	
	\begin{proof}
	Suppose that for each $x \in A$, $Df(x) = 0$. Let $x,y \in A$. Then the mean value theorem implies that there exists $t \in (0, 1)$ such that 
	\begin{align*}
	\|f(x) - f(y)\| 
	&\leq \|Df(tx + (1-t)y)\| \|x-y\| \\
	&= 0
	\end{align*}
	So $f(x) = f(y)$. 
	\end{proof}
	
	\begin{ex}
	Let $X, Y$ be a Banach spaces, $A \subset X$ open and convex and $f,g:A \rightarrow Y$. Suppose that $f$ and $g$ are Frechet differentiable. If $Df = Dg$, then there exists $c \in Y$ such that $f = g+c$.
	\end{ex}
	
	\begin{proof}
		Suppose that $Df = Dg$. Then $D(f-g) = 0$ and the previous exercise implies that $f -g$ is constant.
	\end{proof}		
	
	\begin{ex}
	Let $X, Y$ be a Banach spaces, $A \subset \R$ open and $f:A \rightarrow Y$. Suppose that $f$ is Frechet differentiable. Then $f' \in C(A,Y)$ iff $f \in C^1(A,Y)$.
	\end{ex}
	
	\begin{proof}
	Suppose that $f' \in C(A, Y)$. Let $x,y \in A$ and $h \in \R$. Then 
	\begin{align*}
	\|(Df(x)- Df(y))(h)\| 
	&= \|Df(x)(h) - Df(y)(h)\| \\
	&=  \|hf'(x) - hf'(y)\| \\
	&= \|h(f'(x) - f'(y))\| \\
	&= \|f'(x) - f'(y)\||h|
	\end{align*}
	So $\|Df(x) - Df(y)\| \leq \|f'(x) - f'(y)\|$. Hence continuity of $f'$ implies continuity of $Df$ and $f \in C^1(A, Y)$.
	Conversely, suppose that $f \in C^1(A, Y)$. Let $x,y \in A$. Then 
	\begin{align*}
	\|f'(x) - f'(y)\| 
	&= \|Df(x)(1) - Df(y)(1)\| \\
	&= \|(Df(x) - Df(y))(1)\| \\
	& \leq \| Df(x) - Df(y)\|
	\end{align*}
	Hence continuity of $Df$ implies continuity of $f'$ and $f' \in C(A, Y)$.
	\end{proof}
	
	\begin{ex}
	Let $Y$ be a separable Banach space, $f:[a,b] \rightarrow Y$ continuous so that $f$ is Bochner-integrable. Define $F:(a,b) \rightarrow Y$ by  $$F(x) = \int_{(a, x]}f dm$$ Then $F \in C^1((a,b), Y)$ and for each $x_0 \in (a,b)$ and $F'(x_0) = f(x_0)$.
	\end{ex}
	
	\begin{proof}
	Let $x_0 \in (a,b)$ and $h \in (0, b-x_0)$. Then continuity implies that
	\begin{align*}
	\frac{1}{\|h\|} \bigg | \int_{(x_0, x_0 + h]}f - f(x_0) dm \bigg |
	& \leq  \frac{1}{\|h\|} \max_{x \in (x_0, x_0+h]} |f(x) - f(x_0)| \|h\| \\
	&= \max_{x \in [x_0, x_0+h]} |f(x) - f(x_0)| \\
	& \rightarrow 0  \text{ as } h \rightarrow 0
\end{align*}	  
So $$\int_{(x_0, x_0 + h]}f - f(x_0) dm = o(\|h\|) \hspace{1cm}\text{ as }h \rightarrow 0$$ 
	Therefore 
	\begin{align*}
	F(x_0 + h)
	&= \int_{(a, x_0 + h]} f dm  \\
	&= \int_{(a, x_0]} f dm + \int_{(x_0, x_0 + h]} fdm \\
	&= \int_{(a, x_0]} f dm + hf(x_0) + \int_{(x_0, x_0 + h]} f - f(x_0) dm \\ 
	&= F(x_0 ) + hf(x_0) + o(\|h\|) \hspace{1cm }\text{ as } h \rightarrow 0\\
	\end{align*}
	The case is similar for $h \in (x_0 - b, 0)$. Since the map $h \mapsto f(x_0)h$ is bounded, $F$ is Frechet differentiable at $x_0$ and $DF(x_0)(h) = f(x_0)h$. This implies that $F'(x_0) = f(x_0)$ and the previous exercise implies tells us that continuity of $f$ implies continuity of $DF$. So $F \in C^1(A, Y)$.
	\end{proof}
	
	\begin{ex}\textbf{Fundamental Theorem of Calculus:}
	Let $Y$ be a separable Banach space and $f \in C^1((a,b), Y)$. Then for each $x, x_0 \in (a,b)$, $x_0 < x$ implies that 
	\begin{enumerate}
	\item $f'$ is Bochner integrable on $(x_0, x]$ 
	\item  $$f(x) - f(x_0) = \int_{(x_0, x]}f'dm$$ 
	\end{enumerate}
	\end{ex}

	\begin{proof}
	\begin{enumerate}
	\item Since $f \in C^1((a,b), Y)$, a previous exercise tells us that $f' \in C_Y(a,b)$. Let $x, x_0 \in (a,b)$. Suppose that $x_0 < x$. Choose $c,d \in (a,b)$ such that $a < c < x_0< x< d < b$. Then $f'$ is continuous on $[c,d]$ and hence Bochner-integrable on $(c,d]$ and $(x_0,x]$. 
	\item Define $g: (c,d) \rightarrow Y$ by $$g(\xi) = \int_{(c, \xi]}f'dm$$
	Then the previous exercise implies that $g \in C^1_Y(c,d)$ and for each $t \in (c, d)$, $g'(t) = f'(t)$. Let $t \in (c,d)$ and $h \in \R$. Then
	\begin{align*}
	Dg(t)(h) 
	&= hg'(t) \\
	&= hf'(t) \\
	&= Df(t)(h)
	\end{align*}
	So $Dg = Df$ on $(c,d)$. A previous exercise implies that there exists $c \in Y$ such that $f = g + c$ on $(c, d)$. Then 
	\begin{align*}
	f(x) - f(x_0)
	&= g(x)+c - (g(x_0)+c) \\
	&= g(x) - g(x_0) \\
	&= \int_{(c, x]}f'dm - \int_{(c, x_0]}f'dm\\
	&= \int_{(x_0, x]}f'dm
	\end{align*}
	\end{enumerate}
	\end{proof}
	
	
	\begin{ex}
	Let $Y$ be a Banach space, $A \subset \R$ open and $g:A \rightarrow Y$. If $g$ is $n$-th order Frechet differentiable, then 
	$$\dv{t} \sum_{k=0}^{n-1} \frac{(1-t)^k}{k!}g^{(k)}(t) = \frac{(1-t)^{n-1}}{(n-1)!}g^{(n)}(t)$$
	\end{ex}
	
	\begin{proof}
	Taking the derivative yields a telescoping series.
	\end{proof}
	
	
	
	\begin{ex}\textbf{Taylor's Theorem:}\\
	Let $X$ be a Banach space, $Y$ a separable Banach space, $A \subset X$ open and convex, $f\in C^{n+1}(A, Y)$, $x_0 \in A$, and $h \in X$. Suppose $x_0 + h \in A$. Then $$f(x_0 + h) = \sum_{k=0}^{n} \frac{1}{k!} D^k f(x_0)(h^{\oplus k}) + R(x_0;h)$$ 
	where $$R(x_0;h) = \frac{1}{n!}\int_{(0,1)} (1-t)^{n}D^{n+1}f(x_0 + th)(h^{\oplus (n+1)})d m(t)$$
	and $R(x_0, h) = o(\|h\|^{n})$ as $h \rightarrow 0$.\\
	\textbf{Hint:} Define $g: (0,1) \rightarrow Y$ by $$g(t) = f(x_0 +t h)$$ Then use the previous exercise and the fundamental theorem of calculus.
	\end{ex}
	
	\begin{proof}
	For each $k \in \{1, \dots, n+1\}$, a previous exercise implies that $g^{(k)}(t) = D^kf(x_0 + th)(h^{\oplus k})$, so $g^{(k)}(0) = D^kf(x_0)(h^{\oplus k})$. The previous exercise and the fundamental theorem of calculus tell us that 
	\begin{align*}
	f(x_0 +h) - \sum_{k=0}^{n} \frac{1}{k!}D^kf(x_0)(h^{\oplus k})
	&= g(1) - \sum_{k=0}^{n} \frac{1}{k!}g^{(k)}(0)\\
	&= \int_{(0,1)} \bigg [\dv{t} \sum_{k=0}^{n} \frac{(1-t)^k}{k!}g^{(k)}(t)\bigg ] dm(t) \\
	&= \int_{(0,1)} \frac{(1-t)^{n}}{n!}g^{(n+1)}(t) dm(t)
	\end{align*}	
	Note that $$\frac{1}{n+1} = \frac{1}{n!}\int_{(0,1)} (1-t)^{n} dm(t)$$ 
	Since $D^{n+1}f$ is continuous at $x_0$, there exists $\del_1 >0$ such that for each $h \in B(0, \del_1)$, 
	$$\|D^{n+1} f(x_0+h) - D^{n+1}f(x_0)\| < 1 $$  
	Let $\ep >0$. Choose $\del_2 >0$ such that $$\frac{1}{n+1} \bigg( \|D^{n+1}f(x_0 )\|  +  1 \bigg) \del_2 < \ep$$ Set $\del = \min(\del_1, \del_2)$. Let $h \in B(0, \del)$. Then
	\begin{align*}
	\|R(x_0;h)\| 
	&= \bigg \| \int_{(0,1)} \frac{1}{n!}\int_{(0,1)} (1-t)^{n}D^{n+1}f(x_0 + th)(h^{\oplus (n+1)})d m(t) \bigg\| \\
	&\leq \frac{1}{n!}\int_{(0,1)} \|(1-t)^{n}D^{n+1}f(x_0 + th)(h^{\oplus (n+1)}) \|dm(t)\\
	&\leq \frac{1}{n+1} \max_{t \in [0,1]}\|D^{n+1}f(x_0 + th)\| \|h\|^{n+1}  \\
	&\leq \frac{1}{n+1}  \bigg(\|D^{n+1}f(x_0 )\| +  \max_{t \in [0,1]} \|D^n f(x_0+th) - D^{n+1}f(x_0)\| \bigg)\|h\|^{n+1}  \\
	&< \frac{1}{n+1}\bigg(\|D^{n+1}f(x_0 )\|  +  1 \bigg)\|h\|^{n+1}  \\
	&<\ep \|h\|^n
	\end{align*}
	So $R(x_0, h) = o(\|h\|^{n})$ as $h \rightarrow 0$.
	\end{proof}
	
	\begin{ex}
	
	\end{ex}

	
	
	
	
	
	\newpage
	\subsection{The Gradient}
	
	\begin{defn}
	Let $H$ be a Hilbert space, $f: H \rightarrow \R$ and $x_0 \in H$. Suppose that $f$ is Frechet differentiable at $x_0$. Then $Df(x_0) \in H^*$. We define the \textbf{gradient of $f$ at $x_0$}, denoted $\nabla f(x_0) \in H$, via the Riesz representation theorem to be the unique element of $H$ satisfying $$\l \nabla f(x_0), y \r = Df(x_0)(y) \hspace{.3cm} \text{ for each } y \in H$$
	\end{defn}
	
	
	
	
	
	
	
	
	
	
	

	
	
	
	
	
	
	\newpage
	\section{Convexity}
	
	\subsection{Introduction}

	\begin{note}
	In this section, we assume all vector spaces are real.
	\end{note}

	\begin{defn}
	Let $X$ be a vector space and $A \subset X$. Then $A$ is said to be $\textbf{convex}$ if for each $x, y \in A$, and $t \in [0,1]$,  $tx + (1-t)y \in A$. 
	\end{defn}	
	
	\begin{defn}
	Let $X$ be a vector space and $f:A \rightarrow R$. Then $f$ is said to be \textbf{convex} if for each $x,y \in A$, $t \in \ui$, $$f(tx + (1-t)y) \leq tf(x) + (1-t)f(y)$$
	\end{defn}
		
	\begin{ex}
	Let $X$ be a Banach space, $A \subset X$ open and convex, and $f \in C^2(A)$. Then $f$ is convex (resp. strictly convex) iff for each $x \in A$, $D^2f(x)$ is positive semidefinite (resp. positive definite).\\
	\textbf{Hint:} For $x,y \in X$, consider the function $g:(0,1) \rightarrow \R$ given by  $g(t) = f(tx + (1-t)y)$
	\end{ex}
	
	\begin{proof}
	
	\end{proof}
	
	\begin{ex}
	Let $X$ be a vector space, $f \in X^*$ and $g: X \rightarrow \R$ constant. Then $f$ and $g$ are convex. 
	\end{ex}
	
	\begin{proof}
		Let $x, y \in X$ and $t \in \ui$. Put $c = g(0)$. Then $$f(tx + (1-t)y) = tf(x) + (1-t)f(y)$$ and 
		\begin{align*}
		g(tx + (1-t)y) 
		&= c\\ 
		&= tc + (1-t)c \\
		&= tg(x) + (1-t)g(y)
		\end{align*}
		So $f$ and $g$ are convex.
	\end{proof}		
	
	\begin{ex}
	Let $X$ be a vector space, $A \subset X$ convex, $f,g:A \rightarrow \R$ and $\lam \geq 0$. If $f,g$ are convex, then 
	\begin{enumerate}
	\item $f + g$ is convex 
	\item $\lam f$ is convex
	\end{enumerate}
	\end{ex}
	
	\begin{proof}
	Suppose that $f$ and $g$ are convex. Let $x,y \in A$ and $t \in [0,1]$. Then 
	\begin{align*}
	(f + \lam g)(tx + (1-t)y) 
	&= f(tx + (1-t)y) + \lam g(tx + (1-t)y) \\
	& \leq tf(x) + (1-t)f(y) +  t \lam g(x) + (1-t)\lam g(y) \\
	&= t(f(x) + \lam g(x)) + (1-t)(f(y) + \lam g(y))\\
	& = t(f + \lam g)(x) + (1-t)(f + \lam g)(y)
\end{align*}		 
	\end{proof}
	
	
	\begin{defn}
	Let $X$ be a vector space and $f: X \rightarrow \R$. Then $f$ is said to be \textbf{affine} if there exists $\phi \in X^*$, $a \in R$ constant such that $f = \phi + a$.\\
	\end{defn}
	
	\begin{ex}
	Let $X$ be a vector space and $f: X \rightarrow \R$. If $f$ is affine, then $f$ is convex.
	\end{ex}
	
	\begin{proof}
	Suppose that $f$ is affine. Then there exists $\phi \in X^*$, $a \in R$ constant such that $f = \phi + a$. Then $\phi$ is convex and $g: X \rightarrow \R$ defined by $g(x) = a$ is convex. So $f = \phi + g$ is convex.
	\end{proof}
	
	\begin{ex}
	Let $X$ be a vector space, $A \subset X$ convex, $f:\R \rightarrow \R$ and $g: A \rightarrow \R$. If $f$ is convex and increasing and $g$ is convex, then $f \circ g$ is convex.
	\end{ex}	
	
	\begin{proof}
	Let $t \in [0,1]$ and $x, y \in A$. Then convexity of $g$ implies that $$g(tx +(1-t)y) \leq tg(x) + (1-t)g(y)$$ and we have
	\begin{align*}
	f\circ g(tx +(1-t)y) 
	&= f(g(tx +(1-t)y)) \\
	& \leq f(tg(x) + (1-t)g(y)) \hspace{2cm} (f \text{ increasing)}\\
	& \leq tf(g(x)) + (1-t)f(g(y)) \hspace{2cm}  (f \text{ convex)}\\	
	&= tf \circ g(x) + (1-t)f \circ g(y)
\end{align*}	 
So $f \circ g$ is convex.
	\end{proof}
	
	\begin{ex}
	Let $X$ be a vector space, $A \subset X$ convex, $f:A \rightarrow \R$ convex and $x_0 \in A$. Then $f$ has a local minimum point at $x_0$ iff $f$ has a global minimum point at $x_0$.
	\end{ex}	
	
	\begin{proof}
	If $f$ has a global minimum point at $x_0$, then $f$ has a local minimum point at $x_0$. Conversely, suppose that $f$ has a local minimum point at $x_0$. Then there exists $\del >0$ such that for each $x \in B(x_0, \del)$, $f(x_0) \leq f(x)$. For the sake of contradiction, suppose that $f$ does not have a global minimum point at $x_0$. Then there exits $x' \in A$ such that $f(x') < f(x_0)$. Put $t_0 = \min(\frac{\del}{\|x' - x_0\| + 1}, 1) >0$. Let $t \in (0, t_0)$, then
	\begin{align*}
	\|(tx' + (1-t)x_0) - x_0\| 
	&= t\|x' -x_0 \| \\
	& <   \frac{\|x' -x_0 \|\del}{\|x' -x_0\| + 1} \\
	& < \del
	\end{align*} 
	so that $tx' + (1-t)x_0 \in B(x_0, \del)$ and hence $f(x_0) \leq f(tx' + (1-t)x_0)$.  Therefore  
	\begin{align*}
	f(x_0) 
	& \leq f(tx' + (1-t)x_0) \\
	& \leq tf(x') + (1-t)f(x_0)  \hspace{.5cm} (\text{convexity of }f)\\
	& < tf(x_0) + (1-t)f(x_0) \\
	&= f(x_0)
	\end{align*}
	which is a contradiction. Hence $f$ has a global minimum point at $x_0$.
	\end{proof}
	
	\begin{defn}
	Let $X, Y$ be vector spaces, $A \subset X \oplus Y$. For $y \in Y$, define $$A^y = \{x \in X: (x,y) \in A \}$$ and $f^y:A^y \rightarrow \R$ by $$f^y(x) = f(x,y)$$
	\end{defn}
	
	\begin{ex}
	Let $X, Y$ be vector spaces, $A \subset X \oplus Y$ convex and $f:A \rightarrow \R$ convex. Then for each $y \in \pi_2(A)$,
	\begin{enumerate}
	\item $A^y$ is convex 
	\item $f^y$ is convex  
	\end{enumerate}	  
	where $\pi_2: X\times Y \rightarrow Y$, the canonical projection of $X \times Y$ onto $Y$ given by $\pi_2(x,y) = y$.
	\end{ex}
	
	\begin{proof}
	Let $y \in \pi_2(A)$, $x_1, x_2 \in A^y$ and $t \in [0,1]$. Then by definition, $(x_1, y)$, $(x_2, y) \in A$.
	\begin{enumerate}
	\item  Convexity of $A$ implies that $(tx_1 + (1-t)x_2, y) \in A$. Hence $tx_1 + (1-t)x_2 \in A^y$ and $A^y$ is convex. 
	\item Convexity of $f$ implies that 
	\begin{align*}
	f^y(tx_1 + (1-t)x_2)
	&= f(tx_1 + (1-t)x_2, y) \\
	&= f(t(x_1, y) + (1-t)(x_2,y)) \\
	& \leq tf(x_1, y) + (1-t) f(x_2,y) \\
	&= tf^y(x_1) + (t-t)f^y(x_2)
\end{align*}	  
	and so $f^y$ is convex.
	\end{enumerate}
	\end{proof}
	
	\begin{ex}
	Let $X$, $Y$ be vector spaces and $A\subset X, B \subset Y$. If $A$ and $B$ are convex, then $A \times B \subset X \oplus Y$ is convex.
	\end{ex}	
	
	\begin{proof}
	Suppose that $A$ and $B$ are convex. Let $(x_1,y_1), (x_2,y_2) \in A \times B$ and $t \in [0,1]$. Convexity of $A$ and $B$ implies that $tx_1 + (1-t)x_2 \in A$ and $ty_1 + (1-t)y_2 \in B$. Therefore 
	\begin{align*}
	t(x_1,y_1) + (1-t)(x_2,y_2) 
	&= (tx_1 + (1-t)x_2, ty_1 + (1-t)y_2) \\
	& \in A \times B
\end{align*}	 
	\end{proof}
	
	\begin{ex}
	Let $X, Y$ be vector spaces and $A \subset X$, $B \subset Y$ convex (implying that $A \times B$ is convex)  and $f:A \times B \rightarrow \R$ convex. Suppose that for each $y \in B$, $\{f(x, y): x \in A\}$ is bounded below. Then $\inf\limits_{y \in B}f^y$ is convex
	\end{ex}
	
	\begin{proof}
	Put $g = \inf\limits_{y \in B}f^y$. 
	Let $x_1, x_2 \in A$, $y_1, y_2 \in B$ and $t \in [0,1]$. Put $y'= ty_1 + (1-t)y_2$. Then convexity of $f$ implies that
	\begin{align*}
	g(tx_1 + (1-t)x_2) 
	& \leq f^{y'}(tx_1 + (1-t)x_2) \\
	&= f(tx_1 + (1-t)x_2, ty_1 + (1-t)y_2)\\
	&= f(t(x_1,y_1) + (1-t)(x_2, y_2)) \\
	& \leq tf(x_1, y_1) + (1-t)f(x_2, y_2) \\
	&= tf^{y_1}(x_1) + (1-t)f^{y_2}(x_2) \\
	\end{align*}
	Since $y_1 \in B$ is arbitrary, we have that $$g(tx_1 + (1-t)x_2) \leq tg(x_1) + (1-t)f^{y_2}(x_2)$$ Similarly, since $y_2 \in B$ is arbitrary, we have that $$g(tx_1 + (1-t)x_2) \leq tg(x_1) + (1-t)g(x_2)$$ and $f$ is convex.
	\end{proof}	

	\begin{ex}
	Let $X$ be a vector space, $A \subset X$ convex and $ (f_{\lam})_{\lam \in \Lam} \subset \R^A$. Suppose that for each $\lam \in \Lam$, $f_\lam$ is convex. Then $\sup\limits_{\lam \in \Lam}f_\lam$ is convex.
	\end{ex}
	
	\begin{proof}
	Define $f = \sup\limits_{\lam \in \Lam} f_{\lam}$. Let $x, y \in A$, $t \in [0,1]$ and $\lam \in \Lam$. Then \begin{align*}
	f_\lam(tx + (1-t)y) 
	&\leq tf_\lam (x) + (1-t)f_\lam(y) \\
	& \leq tf(x) + (1-t)f(y) 
\end{align*}	
	Since $\lam \in \Lam$ is arbitrary, $f(tx + (1-t)y) \leq tf(x) + (1-t)f(y) $. 
	\end{proof}
	
	\begin{ex}
	Let $X$ be a normed vector space, $A \subset X$ open and convex, $f:A \rightarrow \R$ convex and $x_0 \in A$. If $f$ is continuous at $x_0$, then $f$ is locally Lipschitz at $x_0$. \\
	\textbf{Hint:} Given $x_1, x_2$ near $x_0$ Choose a $z$ near $x_0$ s.t. $x_1$ is a convex combination of $x_2$ and $z$. Then repeat but with $x_2$ as a convex combination of $x_1$ and $z$
	\end{ex}
	
	\begin{proof}
	By continuity, $f$ is locally bounded at $x_0$. So there exist $M, \del >0$ such that $B(x_0, \del) \subset A$ and for each $x \in B(x_0, \del)$, $|f(x)| \leq M$. Put $\del' = \frac{\del}{2}$ and choose $U = B(x_0, \del')$. Then $U \subset A$, $U$ is open and $U \in N_{x_0}$. \\
	Let $x_1, x_2 \in U$. Suppose that $x_1 \neq x_2$. Define $\al = \|x_1 - x_2\| >0$, $p = \frac{\al}{\al + \del'}$, $q = 1-p$ and $z = p^{-1}(x_1 - qx_2)$. Then $x_1 = pz + qx_2$ and 
	\begin{align*}
	\|z - x_1\| 
	&= \|(p^{-1} - 1)x_1 - p^{-1}qx_2\| \\
	&= \frac{1-p}{p} \al \\
	&= \frac{\del'}{\al} \al \\
	&= \del ' 
	\end{align*}
	Therefore 
	\begin{align*}
	\|z - x_0\| 
	& \leq \|z - x_1\| + \|x_1 - x_0\| \\
	& <  \del '  + \del '  \\
	&= \del
\end{align*}	  
	So $z \in B(x_0, \del)$, which implies that 
	\begin{align*}
	f(z) - f(x_2) 
	& \leq |f(z) - f(x_2)|\\ 
	&\leq |f(z)| + |f(x_2)| \\
	&\leq 2M
\end{align*}		
	Since $x_1 = pz + qx_2$, convexity of $f$ implies that $f(x_1) \leq pf(z) + qf(x_2)$. Hence 
	\begin{align*}
	f(x_1) - f(x_2) 
	& \leq pf(z) -pf(x_2) \\
	&= p(f(z) - f(x_2)) \\
	& \leq p 2M \\
	&= \frac{\al}{\al + \del'} 2M \\
	& \leq \al 2M \\
	&= 2M \|x_1 - x_2 \|
	\end{align*}
	Similarly, choosing $z = p^{-1}(x_2 - qx_1)$, yields $f(x_2) - f(x_1) \leq 2M \|x_1 - x_2 \|$ which implies that $$|f(x_1) - f(x_2)| \leq 2M \|x_1 - x_2 \|$$ and $f$ is Lipschitz on $U$. 
 	\end{proof}



	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	\newpage
	\subsection{The Subdifferential}
	
	\begin{ex}
	Let $X$ be a Banach space, $A \subset X$ open and convex, $f:A \rightarrow \R$ convex, $x_0 \in A$ and $x \in X$. Define $T = \{ t \in \R: x_0+tx \in A\}$. Then there exist $a, b \in (0, \infty]$ such that $T = (-a, b)$.
	\end{ex}
	
	\begin{proof}
	Continuity of scalar multiplication and addition implies that $T$ is an open neighborhood of $0$. Let $t > 0$ and $s \in [0,t]$. Then $\frac{s}{t} \in [0, 1]$ and by convexity of $A$, $x_0 + tx \in A$ implies that
	\begin{align*}
	x_0 + sx 
	&= \frac{s}{t}(x_0 + tx) + \bigg(1-\frac{s}{t} \bigg )x_0\\
	& \in A
	\end{align*} 
	Thus $[0,t] \subset T$. Similarly, $x_0 - tx \in A$ implies that $[-t, 0] \subset T$. \\
	Define $a,b \in (0, \infty]$ by $a = \sup \{t > 0: x_0 -tx \in A\}$ and $b = \sup\{t > 0: x_0 +tx \in A\}$. Then $(-a, b) = T$.
	\end{proof}
	
	\begin{defn}
	Let $X$ be a Banach space, $A \subset X$ open and convex, $f:A \rightarrow \R$ convex, $x_0 \in A$ and $x \in X$. Define $T$ as in the previous exercise and choose $t_0 >0$ such that $(-t_0, t_0) \subset T$. For $t \in (0,t_0)$, define the difference quotient $q: (-t_0, t_0) \setminus \{0\} \rightarrow \R$ by$$q(t) = \frac{f(x_0 + tx) - f(x_0)}{t}$$ 
	\end{defn}	
	
	\begin{ex}
	Let $X$ be a Banach space, $A \subset X$ open and convex, $f:A \rightarrow \R$ convex, $x_0 \in A$ and $x \in X$. Define $t_0$ as above.
	Then
	\begin{enumerate}
	\item $q(t)$ is increasing on $(0, t_0)$
	\item $q(-t)$ decreasing on $(0, t_0)$
\end{enumerate}	 
	 \textbf{Hint:} As an example, look at the graph of $f(x) = x^2$. For the algebra, start at the desired end inequality and work backwards
	\end{ex}	
	
	\begin{proof}\
	\begin{enumerate}
	\item Let $s, t \in (0, t_0)$ and suppose that $s \leq t$. Then $x_0 +sx$, $x_0 + tx \in A$. Note that since $0 < s \leq t$, $\frac{s}{t} \in (0, 1]$ and $1- \frac{s}{t} = \frac{t-s}{t} \in (0, 1]$. Also, since $A$ is convex, we have that $$ \bigg( \frac{t-s}{t} \bigg) x_0 +  \bigg(\frac{s}{t} \bigg) (x_0 + tx)  \in A$$
	Convexity of $f$ implies that 
	\begin{align*}
	f(x_0 + sx)
	&= f\bigg ( \bigg( \frac{t-s}{t} \bigg) x_0 +  \bigg(\frac{s}{t} \bigg) (x_0 + tx) \bigg) \\
	& \leq \bigg( \frac{t-s}{t} \bigg) f(x_0) + \bigg(\frac{s}{t} \bigg) f(x_0 + tx)
	\end{align*}
	This implies that $$tf(x_0 + sx) \leq (t-s) f(x_0) + s f(x_0 + tx)$$
	and after rearranging, we get $$t f(x_0 + sx) - tf(x_0) \leq s f(x_0 + tx) - sf(x_0)$$
	and so finally, dividing both sides by $st$, we obtain 
	\begin{align*}
	q(s)
	&= \frac{f(x_0 + sx) - f(x_0)}{s} \\
	& \leq \frac{f(x_0 + tx) - f(x_0)}{t} \\
	&= q(t) 
	\end{align*}
	as desired.
	\item Similar to $(1)$.
	\end{enumerate}
	\end{proof}
	
	\begin{ex}
	Let $X$ be a Banach space, $A \subset X$ open and convex, $f:A \rightarrow \R$ convex, $x_0 \in A$ and $x \in X$. Define $t_0$ as before. Then for each $t \in (0, t_0)$, $$q(-t) \leq q(t)$$ \\
	\textbf{Hint:} for sufficiently small $t$, convexity of $f$ implies that $f(x_0) \leq \frac{1}{2} f(x_0 - 2tx) + \frac{1}{2} f(x_0 + 2tx)$
	\end{ex}
	
	\begin{proof}
	Choose $t_0$ as in the previous exercise. Since convexity of $f$ implies that for each $t \in (0, t_0/2)$,
	$$f(x_0) \leq \frac{1}{2} f(x_0 - 2tx) + \frac{1}{2} f(x_0 + 2tx)$$
	we have that for each $t \in (0, t_0/2)$,
	\begin{align*}
	q(-2t) 
	&= \frac{f(x_0 - 2tx) - f(x_0)}{-2t} \\
	&\leq \frac{f(x_0 + 2tx) - f(x_0)}{2t} \\
	&= q(2t)
	\end{align*}	 
	So for each $t \in (0, t_0)$, $q(-t) \leq q(t)$.
	\end{proof}	
	
	\begin{ex}
	Let $X$ be a Banach space, $A \subset X$ open and convex, $f:A \rightarrow \R$ convex and $x_0 \in A$. Then 
	\begin{enumerate}
	\item $f$ is left-hand and right-hand Gateaux differentiable at $x_0$ with $d^-f(x_0) \leq d^+f(x_0)$ 
	\item for each $x \in X$, $d^-f(x_0)(x) = - d^+f(x_0)(-x)$
	\end{enumerate}
	\end{ex}	
	
	\begin{proof}\
	\begin{enumerate}
	\item Let $x \in X$. Choose $t_0 >0$ as in the previous two exercises. Let $t, u \in (0,t_0)$. Choose $s \in (0, \min(u, t))$. The previous two exercises imply that 
	\begin{align*}
	q(-u) 
	& \leq q(-s) \\ 
	&\leq q(s) \\
	&\leq q(t)
	\end{align*} and therefore $q(t)$ is an upper bound for $\{q(-u): u \in (0,t_0)\}$ and $d^-f(x_0)(x) = \sup\limits_{u \in (0,t_0)}q(-u)$ exists with $d^-f(x_0)(x) \leq q(t)$.\\
	Since $t \in (0, t_0)$ is arbitrary, $d^-f(x_0)(x)$ is a lower bound for $\{q(t): t \in (0, t_0)\}$. Therefore $$d^+f(x_0)(x) = \inf_{t \in (0,t_0)}q(t)$$ exists with $d^+f(x_0)(x) \geq d^-f(x_0)(x)$. 
	\item By definition, we have 
	\begin{align*}
	d^-f(x_0)(x)
	&= \lim_{t \rightarrow 0^+} \frac{f(x_0 + -tx) - f(x_0)}{-t} \\
	&= - \lim_{t \rightarrow 0^+} \frac{f(x_0 + -tx) - f(x_0)}{t} \\
	&= - d^+f(x_0)(-x)
	\end{align*}
	\end{enumerate}
	\end{proof}
	
	\begin{ex}
	Let $X$ be a Banach space, $A \subset X$ open and convex, $f:A \rightarrow \R$ convex and $x_0 \in A$. Then $d^+f(x_0):X \rightarrow \R$ is a sublinear functional.
	\end{ex}	
	
	\begin{proof}
	Let $x,y \in X$ and $k \geq 0$. If $k = 0$, then clearly
	\begin{align*}
	d^+f(x_0)(kx)
	&= k d^+(x_0)(x)
	\end{align*}
	If $k >0$. Then 
	\begin{align*}
	d^+f(x_0)(kx)
	&= \lim_{t \rightarrow 0^+} \frac{f(x_0 + tkx) - f(x_0)}{t} \\
	&= k\lim_{t \rightarrow 0^+} \frac{f(x_0 + tkx) - f(x_0)}{tk}\\
	&= kd^+f(x_0)(x)
	\end{align*}
	Define $t_0 >0$ as before and let $t \in (0, \frac{t_0}{2})$. Note that $$x_0 + tx + ty = \frac{1}{2}(x_0 + 2tx) + \frac{1}{2}(x_0 + 2ty)$$ 
	Convexity of $f$ implies that $$f(x_0 + tx + ty) \leq \frac{1}{2}f(x_0 + 2tx) + \frac{1}{2}f(x_0 + 2ty)$$
	which implies that $$\frac{f(x_0 + tx + ty) - f(x_0)}{t} \leq \frac{f(x_0 + 2tx) - f(x_0)}{2t} + \frac{f(x_0 + 2ty) - f(x_0)}{2t}$$
	Therefore 
	\begin{align*}
	d^+f(x_0)(x+y) 
	&= \lim_{t \rightarrow 0^+} \frac{f(x_0 + t(x + y)) - f(x_0)}{t} \\
	&= \lim_{t \rightarrow 0^+} \frac{f(x_0 + tx + ty) - f(x_0)}{t} \\
	& \leq \lim_{t \rightarrow 0^+} \bigg[ \frac{f(x_0 + 2tx) - f(x_0)}{2t} + \frac{f(x_0 + 2ty) - f(x_0)}{2t} \bigg ] \\
	&= \lim_{t \rightarrow 0^+}  \frac{f(x_0 + 2tx) - f(x_0)}{2t} + \lim_{t \rightarrow 0^+} \frac{f(x_0 + 2ty) - f(x_0)}{2t} \\
	&= d^+f(x_0)(x) + d^+f(x_0)(y) 
	\end{align*}
	\end{proof}
	
	\begin{ex}
	Let $X$ be a Banach space, $A \subset X$ open and convex, $f:A \rightarrow \R$ convex and $x_0 \in A$. Then for each $x \in A$, $$d^+f(x_0)(x-x_0) \leq f(x) - f(x_0)$$
	\end{ex}	
	
	\begin{proof}
	Let $x \in A$. Define $T = \{t \in \R: x_0 + t(x-x_0) \in A\}$ similarly to earlier. Clearly $1 \in T$ and  
	\begin{align*}
	d^+f(x_0)(x - x_0) 
	&= \inf_{t \in (0,1]} \frac{f(x_0 + t(x-x_0)) - f(x_0)}{t} \\
	& \leq f(x) - f(x_0)
	\end{align*}
	\end{proof}
	
	\begin{ex}
	Let $X$ be a Banach space, $A \subset X$ open and convex, $f:A \rightarrow \R$ convex and $x_0 \in A$. If $f$ is continuous at $x_0$, then $d^+f(x_0)$ is Lipschitz (equivalently bounded). 
	\end{ex}	
	
	\begin{proof}
	Suppose that $f$ is continuous at $x_0$. A previous exercise about convex functions tells us that $f$ is locally Lipschitz at $x_0$, so there exists $\del,M >0$ such that for each $x_1, x_2 \in B(x_0, \del)$, $|f(x_1) - f(x_2)| \leq M\|x_1 - x_2\|$. Let $x \in X$ and define $t_0 = \frac{\del}{\|x\| + 1}$ so that for each $t \in (0, t_0)$,
	\begin{align*}
	\|(x_0 +tx) - x_0\|
	& = t\|x\| \\
	& \leq t_0 \| x\| \\
	&= \frac{\del \| x\|}{\|x\| + 1} \\
	& < \del
	\end{align*}  
	and $x_0 +tx \in B(x_0, \del)$.
	Then for each $t \in (0, t_0)$, 
	\begin{align*}
	d^+f(x_0)(x) 
	& \leq \frac{f(x_0 + tx) - f(x_0)}{t} \\
	& \leq \frac{|f(x_0 + tx) - f(x_0)|}{t} \\
	& \leq t^{-1}M \| (x_0 + tx) - x_0\| \\
	&= M\|x\|
	\end{align*}
	Thus $d^+f(x_0)$ is a bounded sublinear functional and  a previous exercise in the section on sublinear functionals implies this is eqivalent to $d^+f(x_0)$ being Lipschitz.
	\end{proof}
	
	\begin{ex}
	Let $X$ be a Banach space, $A \subset X$ open and convex, $f:A \rightarrow \R$ convex and $x_0 \in A$. If $f$ is continuous at $x_0$, then there exists $\phi \in X^*$ such that $\phi \leq d^+f(x_0)$.
	\end{ex}	
	
	\begin{proof}
	Suppose that $f$ is continuous at $x_0$. The previous exercise implies that $d^+f(x_0)$ is Lipschitz (equivalently bounded). A previous exercise in the section discussing sublinear functionals tells us that boundedness of $d^+f(x_0)$ implies that there exists $\phi \in X^*$ such that $\phi \leq d^+f(x_0)$.
	\end{proof}
	
	\begin{defn}\textbf{Subdifferential:}\\
	Let $X$ be a Banach space, $A \subset X$ open and convex, $f:A \rightarrow \R$ convex and $x_0 \in A$. We define the \textbf{subdifferential of $f$ at $x_0$}, denoted $\p f(x_0)$, to be $$\p f(x_0) = \{ \phi \in X^*: \text{for each } x \in A, f(x_0) + \phi(x-x_0) \leq f(x)\}$$
	\end{defn}
	
	\begin{ex}
	Let $X$ be a Banach space, $A \subset X$ open and convex, $f:A \rightarrow \R$ convex and $x_0 \in A$. If $f$ is continuous at $x_0$, then $\p f(x_0) \neq \varnothing$.
	\end{ex}
	
	\begin{proof}
	Suppose that $f$ is continuous at $x_0$. The previous exercise tells us that there exists $\phi \in X^*$ such that $\phi \leq d^+f(x_0)$. Let $x \in A$. A previous exercise implies that
	\begin{align*}
	\phi(x-x_0) 
	& \leq d^+f(x_0)(x - x_0) \\
	& \leq f(x) - f(x_0)
	\end{align*}
	Then $f(x_0) + \phi(x-x_0) \leq f(x)$.
	\end{proof}
	
	\begin{ex}
	Let $X$ be a Banach space, $A \subset X$ open and convex, $f:A \rightarrow \R$ convex, $\phi \in X^*$ and $x_0 \in A$. Then 
	\begin{enumerate}
	\item for each $x \in A$, $$\phi(x-x_0) \leq f(x) - f(x_0)$$ iff  $$\phi \leq d^+f(x_0)$$ 
	\item  $\p f(x_0) = \{ \phi \in X^*: \phi \leq d^+ f(x_0)\}$
	\end{enumerate}
	\end{ex}	
	
	\begin{proof}\
	\begin{enumerate}
	\item Suppose that for each $x \in A$, $\phi(x-x_0) \leq f(x) - f(x_0)$. Let $x \in X$. Define $t_0$ as before. Then for each $t \in (0, t_0)$, 
	\begin{align*}
	t\phi(x)
	&= \phi((x_0 + tx) - x_0) \\
	& \leq f(x_0 + tx) - f(x_0)
	\end{align*}	 
	This implies that $\phi(x) \leq d^+f(x_0)(x)$.\\
	Conversely, suppose that $\phi \leq d^+f(x_0)$. Let $x \in A$. A previous exercise implies that, 
	\begin{align*}
	\phi(x-x_0) 
	& \leq d^+f(x_0)(x-x_0) \\
	&\leq f(x) - f(x_0)
	\end{align*}
	\item Clear.
	\end{enumerate}
	\end{proof}
	
	\begin{ex}
	Let $X$ be a Banach space, $A \subset X$ open and convex, $f:A \rightarrow \R$ convex and $x_0 \in A$. If $f$ is continuous at $x_0$, then the following are equivalent:
	\begin{enumerate}
	\item $f$ is Gateaux differentiable at $x_0$    
	\item $d^+f(x_0)$ is linear 
	\item $\# \p f(x_0) = 1$
	\end{enumerate}
	\end{ex}	
	
	\begin{proof}
	Suppose that $f$ is continuous at $x_0$. Then $d^+f(x_0)$ is Lipschitz and bounded.
	\begin{itemize}
	\item $(1) \implies (2)$: \\ 
	Suppose that $f$ is Gateaux differentiable at $x_0$. Let $x \in X$. Then a previous exercise implies that 
	\begin{align*}
	-df^+(x_0)(-x) 
	&= df^-f(x_0)(x) \\
	&= df^+f(x_0)(x)
	\end{align*}
	An exercise in the section on sublinear functionals implies that $df^+f(x_0)$ is linear.
	\item $(2) \implies (3)$: \\  
	Suppose that $df^+f(x_0)$ is linear. Let $\phi \in \p f(x_0)$. The previous exercise implies that $\phi \leq df^+f(x_0)$. Equivalence of linearity in the section on sublinear functionals implies that $d^+f(x_0) = \phi$. 
	\item $(3) \implies (1)$: \\  
	Suppose that $\# \p f(x_0) = 1$. Since $\p f(x_0) = \{ \phi \in X^*: \phi \leq d^+ f(x_0) \}$, equivalence of linearity in the section on sublinear functionals implies that $d^+ f(x_0)$ is linear. This implies that $d^+ f(x_0) = d^- f(x_0)$ and which implies that $f$ is Gateaux differentiable at $x_0$.
	\end{itemize}
	\end{proof}
	
	\begin{ex}
	Let $X$ be a Banach space, $A \subset X$ open and convex, $f:A \rightarrow \R$ convex and $x_0 \in A$. If $f$ is continuous at $x_0$, then $f$ has a global minimum point at $x_0$ iff $0 \in \p f(x_0)$.
	\end{ex}
	
	\begin{proof}
	Suppose that $f$ has a global minimum point at $x_0$. Let $x \in X$. Then 
	\begin{align*}
	d^+f(x_0)(x) 
	&= \lim_{t \rightarrow 0^+} \frac{f(x_0 + tx) - f(x_0)}{t} \\
	& \geq 0
	\end{align*}
	So $0 \leq df^+(x_0)$ and $0 \in \p f(x_0)$.\\
	Conversely, suppose that $0 \in \p f(x_0)$. Let $x \in A$. Then 
	\begin{align*}
	0
	& = 0(x - x_0) \\
	& \leq f(x) - f(x_0)
	\end{align*}
	So that $f(x_0) \leq f(x)$ which implies that $f$ has a global minimum point at $x_0$.
	\end{proof}
	
	
	
	\newpage 
	\subsection{Conjugacy}
	
	\begin{defn}
	Let $X$ be a Banach space, $A \subset X$ and $f:A \rightarrow \R$. Define $A^* \subset X^*$ and $f^*: A^* \rightarrow \R$ by $$A^* = \bigg \{\phi \in X^*: \sup_{x \in A} \bigg[ \phi(x) - f(x) \bigg] < \infty \bigg  \}$$ and $$f^*(\phi) = \sup_{x \in A} \bigg[ \phi(x) - f(x) \bigg] $$ 
	If $X$ is a Hilbert space, we may define $A^* \subset X$ and $f^*: A^* \rightarrow \R$ via the Riesz representation theorem by $$A^* = \bigg \{y \in X: \sup_{x \in A} \bigg[ \l y, x \r - f(x) \bigg] < \infty \bigg  \}$$ and $f^*: A^* \rightarrow \R$ and $$ f^*(y) = \sup_{x \in A} \bigg[ \l y, x \r - f(x) \bigg] $$
	\end{defn} 
	
	\begin{ex}
	Let $X$ be a Banach space, $A \subset X$ and $f:A \rightarrow \R$. Then $f^*$ is convex. 
	\end{ex}
	
	\begin{proof}
		For $x \in A$, define $g_x: X^* \rightarrow \Rd$ by $g_x(\phi) = \phi(x) - f(x)$. Then for each $x \in A$, $g_x$ is convex since it is affine. Thus $f^* = \sup\limits_{x \in A} g_x$		 
is convex.  
	\end{proof}
	
	\begin{ex}
		Let $X$ be a Banach space, $A \subset X$ and $f:A \rightarrow \R$. Then for each $x \in X$ and $\phi \in X^*$, $f(x) \geq \phi(x) - f^*(\phi)$.	
	\end{ex}
	
	\begin{proof}
	Clear
	\end{proof}
	
	\begin{ex}
	
	\end{ex}
	
	\newpage
	
	
	
	
	
	
	
	
	
	
	\begin{defn}
	Let 
	\end{defn}
	
	\begin{defn}
	$\partial f$
	\end{defn}	
	
	\begin{ex}
	
	\end{ex}
	
	
	\subsection{Functional Optimization}
	\begin{ex}
	Let $X$ be a Banach space, $(S, \MS, \mu)$ a measure space, $A \subset X$, $K \in L^0(A, \R)$ and $\Lam \subset L^0(S, A) \cap \{f:S \rightarrow A:  K \circ f \in L^1(\mu) \}$. Suppose that $A$ and $\Lam$ are convex. Define $\phi: \Lam \rightarrow \R$ by $$\phi f = \int K\circ f d \mu $$
	Then $K$ is convex implies that $\phi$ is convex. 
	\end{ex}	
	
	\begin{proof}
	Suppose that $K$ is convex. Let $t \in \ui$ and $f, g \in \Lam$. Convexity of $K$ implies that for each $s \in S$, $$K[tf(s) + (1-t)g(s)] \leq tK[f(s)] + (1-t)K[g(s)]$$ So $$K \circ [tf +(1-t)g] \leq t K \circ f + (1-t) K \circ g$$
	Therefore 
	\begin{align*}
	\phi[tf + (1-t) g]
	&= \int K \circ [tf +(1-t)g] d \mu \\
	& \leq  \int t K \circ f + (1-t) K \circ g d \mu \\
	&= t \int K \circ f d\mu + (1-t) \int K \circ g d \mu \\
	&= t \phi f + (1-t) \phi g
	\end{align*}
	and $\phi$ is convex.
	\end{proof}
	
	\newpage
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	\newpage
	\section{Topological Groups}
	\subsection{Introduction}
	
	\begin{defn}
	Let $G$ be a group and $\tau$ a topology on $G$. Then $(G, \tau)$ is said to be a \textbf{topological group} if the maps $(g,h) \mapsto gh$ and $g \mapsto g^{-1}$ are continuous. 
	\end{defn}	
	
	\subsection{Automorphism Groups of Metric Spaces}
	
	\begin{defn}
	Let $(X, \tau)$ be a topological space. Define $$\Aut(X) = \{\sig:X\rightarrow X: \sig \text{ is a homeomorphism} \}$$ 
	\end{defn}	
	
	\begin{ex}
	Let $(X, d)$ be a compact metric space. Then $(\Aut(X), d_{u} )$ is a topological group.
	\end{ex}
	
	\begin{proof}
	Let $(\sig_n)_{n \in \N}, (\tau_n)_{n \in \N} \subset \Aut(X)$ and $\sig,\tau \in \Aut(X)$. Suppose that $\sig_n \convt{u} \sig$ and $\tau_n \convt{u} \tau$.
	\begin{enumerate}
	\item Let $\ep >0$. Since $X$ is compact and $\sig$ is continuous, $\sig$ is uniformly continuous. Then there exists $\del >0$ such that for each $x, y \in X$, $d(x,y) < \del$ implies that $d(\sig(x), \sig(y)) \leq \ep/2$.  Choose $N_\sig \in \N$ such that for each $n \in \N$, $ n \geq \N$ implies that $d_u(\sig_n, \sig) < \ep/2$. Choose $N_\tau \in \N$ such that for each $n \in \N$, $ n \geq \N$ implies that $d_u(\tau_n, \tau) < \del$. Put $N = \max(N_\sig, N_\tau)$. Let $n \in \N$ and $x \in X$. Suppose that $n \geq N$. Then 
	\begin{align*}
		d(\sig_n \circ \tau_n (x) ,\sig \circ \tau (x) ) 
		&\leq  d(\sig_n(\tau_n(x)),  \sig(\tau_n(x))) + d( \sig(\tau_n (x)), \sig( \tau (x))) \\
		& < \ep / 2 +\ep / 2 \\
		&= \ep 
	\end{align*}
	So $d_u(\sig_n \circ \tau_n, \sig\circ \tau) \leq \ep$ and $\circ: \Aut(X)^2 \rightarrow \Aut(X)$ is continuous. 
	\item Suppose that $\sig = \id_X$. Let $\ep >0$. Then there exists $N \in \N$ such that for each $n \in \N$, $n \geq N$ implies that $d_u(\sig_n, \id_X) < \ep$. Let $n \in \N$. Suppose that $n \geq N$. Then 
	\begin{align*}
	\sup_{x \in X} d(\sig^{-1}_n(x), x) 
	&= \sup_{x \in \sig_n(X)}d(\sig^{-1}_n(x), x) \\
	&= \sup_{x \in X}d(\sig^{-1}_n(\sig_n(x)), \sig_n(x)) \\
	&= \sup_{x \in X}d(x, \sig_n(x)) \\
	&< \ep
	\end{align*}
	So $\sig^{-1}_n \convt{u} \id_X$. Now suppose that $\sig \neq \id_X$. Since $\sig_n \convt{u} \sig$, part $(1)$ implies that $\sig^{-1} \circ \sig_n \convt{u} \id_X$. Applying the result from above, we get that $\sig_n^{-1} \circ \sig \convt{u} \id_X$. Applying part $(1)$ again implies that $\sig_n^{-1}  \convt{u}  \sig^{-1}$. So the map $\sig \mapsto \sig^{-1}$ is continuous. 
	\end{enumerate}
	Hence $\Aut(X)$ is a topological group. 
	\end{proof}
	
	\begin{defn}
	Let $(X, d)$ be a metric space. Define 
	$$\Aut(X, d) = \{\sig:X\rightarrow X: \sig \text{ is an isometric isomorphism} \}$$  
	\end{defn}
	
	\begin{ex}
	Let $(X, d)$ be a compact metric space. Then $(\Aut(X, d), d_u)$ is a compact subgroup of $(\Aut(X), d_u)$.
	\end{ex}
	
	\begin{proof}
	Clearly, $(\Aut(X, d), d_u)$ is a topological subgroup. To show compactness, use the Arzela Ascoli theorem.
	\end{proof}
	
	\begin{defn}
	Let $(X, \tau)$ be a topological space and $\mu: \MB(X) \rightarrow \R$ a Borel measure. Define $$\Aut(X, \mu) = \{\sig \in \Aut(X): \sig_* \mu = \mu\}$$ 
	\end{defn}	
	
	\begin{ex}
	Let $(X,d)$ be a compact metric space and $\mu: \MB(X) \rightarrow \R$ an outer-regular Borel measure. Then $\Aut(X, \mu)$ is a closed subgroup of $\Aut(X)$.
	\end{ex}
	
	\begin{proof}
	It is clear that $\Aut(X, \mu)$ is a subgroup of $\Aut(X)$. Let $(\sig_n)_{n \in \N} \subset \Aut(X, \MB(X), \mu)$ and $\sig \in \Aut(X)$. Suppose that $\sig_n \convt{u} \sig$. Let $E \subset X$ be closed, $U \subset X$ open and suppose that $E \subset U$. An exercise in the section on metric spaces tells us that there exists $N \in \N$ such that for each $n \in \N$, $n \geq N$ implies that $\sig(E) \subset \sig_n(U)$. Then 
	\begin{align*}
	\mu(\sig(E)) 
	&\leq \mu(\sig_N(U)) \\
	&= \mu(U) 
	\end{align*}
	Therefore, since $\mu$ is outer regular, $\mu(\sig(E)) \leq \mu(E)$. Since $\sig_n^{-1} \convt{u} \sig^{-1}$, we may apply the above argument to obtain that 
	\begin{align*}
	\mu(E) 
	&= \mu(\sig^{-1}(\sig (E))) \\
	&\leq  \mu(\sig(E))
\end{align*}	 
Hence $\mu(E) = \mu(\sig(E))$. Applying the whole argument above thus far to $\sig^{-1}$, we see that $\mu(E) = \mu(\sig^{-1}(E))$. Since $E \subset X$ is an arbitrary closed set and $\MB(X) = \sig(E \subset X: E \text{ is closed})$, we have that $\mu = \sig_*\mu$. Thus $\sig \in \Aut(X, \mu)$ which implies that $\Aut(X, \mu)$ is closed. 
	\end{proof}
	
	\begin{defn}
	Let $(X,d)$ be a compact metric space and $\mu: \MB(X) \rightarrow \R$ an outer-regular Borel measure. Define $\Aut(X, d, \mu) = \Aut(X, d) \cap \Aut(X, \mu)$.
	\end{defn}
	
	\begin{ex}
	Let $(X,d)$ be a compact metric space and $\mu: \MB(X) \rightarrow \R$ an outer-regular Borel measure. Then $\Aut(X, d, \mu)$ is compact.
	\end{ex}
	
	\begin{proof}
	Since $\Aut(X, d)$ is compact and $\Aut(X, \mu)$ is closed, $\Aut(X, d, \mu)$ is compact.
	\end{proof}
	
	
	
	
	
	
	
	
	
	
	
	\newpage
	\subsection{Group Actions on Metric Spaces}
	
	\begin{note}
	For a set $X$, a group $G$ and a (left) group action $\phi: G \times X \rightarrow X$, we will write $\phi(g, x)$ as $g \cdot x$. We denote the projection map by $\pi: X \rightarrow X/G$.
	\end{note}	
	
	\begin{defn}
	Let $(X, d)$ be a metric space, $G$ a group, and $\phi: G \times X \rightarrow X$ a group action. We define 
	$d_*: X/G \times X / G \rightarrow \Rg$ by 
	$$d_*(o_x, o_y) = \inf_{\substack{a \in o_x \\ b \in o_y}} d(a,b) $$
	\end{defn}
	
	\begin{defn}
	Let $(X, d)$ be a metric space, $G$ a group, and $\phi: G \times X \rightarrow X$ a group action. Then $\phi$ is said to be an \textbf{isometric group action} if for each $g \in G$, the map $x \mapsto g \cdot x$ is an isometry. 
	\end{defn}
	
	\begin{ex}
	Let $(X, d)$ be a metric space, $G$ a group, and $\phi: G \times X \rightarrow X$ an isometric group action. Then for each $x, y \in X$, $$d_*(o_x, o_y) = \inf_{g \in G} d(g \cdot x, y)$$
	\end{ex}
	
	\begin{proof}
	Let $x, y \in X$, $a \in o_x$ and $b \in o_y$. Then there exists there exists $g_x, g_y \in G$ such that $a = g_x \cdot x$ and $b = g_y \cdot y$. Set $g = g_y^{-1}g_x$. Since the map $z \mapsto g_y^{-1} \cdot z$ is an isometry, 
	\begin{align*}
	d(a,b) 
	&= d(g_x \cdot x, g_y \cdot y) \\
	&= d(g_y^{-1}g_x \cdot x, y)\\
	&= d(g\cdot x, y)
	\end{align*}
	Let $\ep >0$. Then there exist $a^* \in o_x$ and $b^* \in o_y$ such that $d(a^*,b^*) < d_*(o_x,o_y) + \ep$. The above argument implies that that there exists $g^* \in G$ such that 
	\begin{align*} 
	\inf_{g \in G} d(g \cdot x, y) 
	& \leq d(g^* \cdot x, y) \\
	&= d(a^*, b^*) \\
	& < d_*(o_x, o_y) + \ep
\end{align*}	 
	Since $\ep >0$ is arbitrary, $$\inf_{g \in G} d(g \cdot x, y) \leq d_*(o_x, o_y)$$
	Conversely, since $\{(g \cdot x, y): g \in G\} \subset \{(a,b): a \in o_x, b \in o_y\}$, we have that 
	$$\inf_{g \in G} d(g \cdot x, y) \geq d_*(o_x, o_y)$$ 
	\end{proof}
	
	\begin{ex}
	Let $(X, d)$ be a metric space, $G$ a group, and $\phi: G \times X \rightarrow X$ an isometric group action. Then for each $x, y, z \in X$, $$d_*(o_x, o_y) \leq d_*(o_x, o_z) + d_*(o_z, o_y)$$
	\end{ex}
	
	\begin{proof}
	Let $x, y, z \in X$. An exercise in section $(2.1)$ implies that $d(o_x, o_y) \leq d(o_x, z) + d(z, o_y)$. The previous exercise implies that 
	\begin{align*}
	d(o_x, z) 
	&= \inf_{a \in o_x} d(a, z) \\
	&= \inf_{g \in G} d(g \cdot x, z) \\
	&= d_*(o_x, o_z)
	\end{align*}
	Similarly, $d(z, o_y) = d_*(o_z, o_y)$. Then 
	\begin{align*}
	d(o_x, o_y) 
	&\leq d(o_x, z) + d(z, o_y) \\
	&= d_*(o_x, o_z) + d_*(o_z, o_y)
	\end{align*}
	\end{proof}
	
	\begin{ex}
	Let $(X, d)$ be a metric space, $G$ a group, and $\phi: G \times X \rightarrow X$ an isometric group action. If for each $x \in X$, $o_x$ is closed, then for each $x, y \in X$, $d_*(o_x, o_y) =0$ implies that $o_x = o_y$.
	\end{ex}
	
	\begin{proof}
	Suppose that for each $x \in X$, $o_x$ is closed. Let $x,y \in X$. Suppose that $d_*(o_x , o_y) = 0$. Then $\inf\limits_{ g \in G} d(g \cdot x, y) = 0$. Hence there exists $(g_n)_{n \in N} \subset G$ such that $g_n \cdot x \rightarrow y$. Since $(g_n \cdot x)_{n \in \N} \subset o_x$ and $o_x$ is closed, $y \in o_x$. Thus $o_x = o_y$. 
	\end{proof}
	
	\begin{ex}
	Let $(X, d)$ be a metric space, $G$ a group, and $\phi: G \times X \rightarrow X$ an isometric group action. If for each $x \in X$, $o_x$ is closed, then $d_*$ is a metric on $X/G$.
	\end{ex}
	
	\begin{proof}
	Clear by preceeding exercises.
	\end{proof}
	
	\begin{ex}
	Let $(X, d)$ be a metric space, $(G, \tau)$ a topological group, and $\phi: G \times X \rightarrow X$ an isometric group action. Suppose that $G$ is compact and for each $x \in X$, the map $g \mapsto g \cdot x$ is continuous. Then $d_*$ is a metric on $X/G$. 
	\end{ex}
	
	\begin{proof}
	Let $x \in X$. Since $G$ is compact and the map $g \mapsto g \cdot x$ is continuous, $o_x = G \cdot x$ is compact and therefore closed. The previous exercise implies that $d_*$ is a metric.
	\end{proof}
	
	\begin{ex}
	Let $(X, d)$ be a metric space, $G$ a group, and $\phi: G \times X \rightarrow X$ an isometric group action. Suppose that $d_*$ is a metric on $X/G$. Then the projection map $\pi: X \rightarrow X/G$ is Lipschitz and therefore continuous.
	\end{ex}
	
	\begin{proof}
	Let $x,y \in X$. Then
	\begin{align*}
	d_*(\pi(x), \pi(y)) 
	&= d_*(o_x, o_y) \\
	&= \inf_{g \in G} d(g \cdot x, y)\\
	& \leq d(x,y)  \\
	\end{align*}
	\end{proof}
	
	\begin{ex}
	Let $(X, d)$ be a metric space, $G$ a group, and $\phi: G \times X \rightarrow X$ an isometric group action. Suppose that $d_*$ is a metric on $X/G$. Let $(x_n)_{n \in \N} \subset X$ and $x \in X$. Then $o_{x_n} \conv{d_*} o_x$ iff there exists a sequence $(g_n)_{n \in \N}$ such that $g_n \cdot x_n \conv{d} x$.
	\end{ex}
	
	\begin{proof} 
	Suppose that $o_{x_n} \conv{d_*} o_x$. For $n \in \N$, choose $g_n \in G$ such that $d(g_n \cdot x_n, x) < d(o_{x_n}, o_x) + 2^{-n}$. Then $d(g_n \cdot x_n, x) \rightarrow 0$ and $g_n \cdot x_n \conv{d_*} x$.  \\
	Conversely, suppose that that there exists a sequence $(g_n)_{n \in \N}$ such that $g_n \cdot x_n \conv{d} x$. Since $\pi:X \rightarrow X/G$ is continuous, we have that
	\begin{align*}
	g_n \cdot x_n \conv{d} x
	& \implies \pi(g_n \cdot x_n) \conv{d_*} \pi(x)\\
	& \implies o_{x_n}  \conv{d_*} o_x
	\end{align*}
	\end{proof}		
	
	\begin{ex}
	Let $X$ be a set, $d_1, d_2: X^2 \rightarrow \Rg$ metrics, $G$ a group and $\phi: G \times X \rightarrow X$ an isometric group action. Suppose that $d_1$ and $d_2$ are topologically equivalent. 
	\begin{enumerate}
	\item Then ${d_1}_*$ is a metric on $X/G$ iff ${d_2}_*$ is a metric on $X/G$
	\item If ${d_1}_*$ and ${d_2}_*$ are metrics, then ${d_1}_*$ and ${d_2}_*$ are topologically equivalent. 
	\end{enumerate}
	\end{ex}
	
	\begin{proof}\
	\begin{enumerate}
	\item 
	\begin{itemize}
	\item $\implies$ Suppose that ${d_1}_*$ is a metric. Let $x,y \in X$. Suppose that ${d_2}_*(o_x, o_y) = 0$. Then there exist $(g_n)_{n \in \N} \subset G$ such that $d_2(g_n \cdot x, y) \rightarrow 0$. Since $d_1$ and $d_2$ are topologically equivalent, $d_1(g_n \cdot x, y) \rightarrow 0$. Thus ${d_1}_*(o_x, o_y) = 0$. Since ${d_1}_*$ is a metric, $o_x = o_y$. Hence ${d_2}_*$ is a metric. 
	\item $\impliedby$ Similar.
	\end{itemize}
	\item Suppose that ${d_1}_*$ and ${d_2}_*$ are metrics. Let $(o_{x_n})_{n \in \N} \subset X/G$ and $o_x \in X/G$. 
	\begin{itemize}
	\item Suppose that $o_{x_n} \conv{{d_1}_*} o_x$. Then there exists a sequence $(g_n)_{n \in \N}$ such that $g_n \cdot x_n \conv{d_1} x$. Since $d_1$ and $d_2$ are topologically equivalent, $g_n \cdot x_n \conv{d_2} x$. This implies that $o_{x_n} \conv{{d_2}_*} o_x$. 
	\item Suppose that $o_{x_n} \conv{{d_2}_*} o_x$. Then similarly to above, $o_{x_n} \conv{{d_1}_*} o_x$.
	\end{itemize}
	\end{enumerate}
	\end{proof}	
	
	\begin{ex}
	Let $X$ be a set, $d_1, d_2: X^2 \rightarrow \Rg$ metrics on $X$, $G$ a group and $\phi: G \times X \rightarrow X$ an isometric group action. Suppose that $d_1$ and $d_2$ are equivalent. If ${d_1}_*$ and ${d_2}_*$ are metrics, then ${d_1}_*$ and ${d_2}_*$ are equivalent.
	\end{ex}
	
	\begin{proof} Suppose that ${d_1}_*$ and ${d_2}_*$  are metrics. Since $d_1$ $d_2$ are equivalent, there exist $C_1, C_2 >0$ such that for each $x,y \in X$, $C_1d_1(x,y) \leq d_2(x,y) \leq C_2d_1(x,y)$. Let $x,y \in X$. Then
	\begin{align*}
	C_1{d_1}_*(o_x, o_y) 
	&= C_1 \inf_{g \in G} d_1(g \cdot x, y) \\
	&=  \inf_{g \in G} C_1 d_1(g \cdot x, y) \\
	&\leq \inf_{g \in G} d_2(g \cdot x, y) \\
	&= {d_2}_*(o_x, o_y) \\
	\end{align*}	 
	and 
	\begin{align*}
	{d_2}_*(o_x, o_y) 
	&= \inf_{g \in G} d_2(g \cdot x, y) \\	
	& \leq \inf_{g \in G} C_2 d_1(g \cdot x, y) \\
	&= C_2 \inf_{g \in G}  d_1(g \cdot x, y) \\
	&= C_2 {d_1}_*(o_x, o_y)
	\end{align*}
	So that $C_1 {d_1}_* \leq {d_2}_* \leq C_2 {d_1}_*$
	\end{proof}

	
	
	
	
	
	
	
	
	
	
	\newpage
	\subsection{Fundamental Examples}
	\begin{ex}
	Consider the metric space $(\C^{n \times d}, \|\cdot\|_F)$, topological group $(U_d, \|\cdot\|_F)$ and  the (right) action $X \cdot U = XU$. Then this action is continuous, $U_d$ is compact and for each $U \in U_d$, the map $X \mapsto XU$ is an isometry. Thus $d_*$ is a metric on $\C^{n \times d}/ U_d$.
	\end{ex}
	
	\begin{proof}
	Clear.
	\end{proof}		
	
	\begin{ex}
	Let $X$ be a compact metric space and $\mu:\MB(X) \rightarrow \RG$ a Borel measure. Define the (right) group action $L^1(\mu) \times \Aut(X, \mu) \rightarrow L^1(\mu) $ by $$f \cdot \sig = f \circ \sig$$ Then for each $\sig \in \Aut(X, \mu)$, the map $f \mapsto f \cdot \sig$ is an isometry. 
	\end{ex}
	
	\begin{proof}
	Let $\sig \in \Aut(X, \mu)$ and $f \in L^1(\mu)$. 
Then 
	\begin{align*}
	\|f \cdot \sig\|_1
	&=  \int_X |f \circ \sig| d\mu \\
	&=  \int_X |f| \circ \sig d\mu \\
	&=  \int_{\sig(X)} |f| d \sig_* \mu  \\
	&=  \int_{\sig(X)} |f| d \mu \\
	&=  \int_{X} |f| d \mu \\
	&= \|f\|_1 
	\end{align*}	 
	\end{proof}
	
	\begin{ex}
	Let $(X,d)$ be a compact metric space and $\mu: \MB(X) \rightarrow \R$ an outer-regular Borel measure. Then 
	\end{ex}
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	\newpage
	\section{Appendix}
	
	\subsection{Summation}
	
	\begin{defn}
		Let $f:X \rightarrow \Rg$, Then we define $$\sum_{x \in X} f(x) := \sup_{\substack{F \subset X \\ F \text{ finite}}} \sum_{x \in F} f(x)$$ This definition coincides with the usual notion of summation when $X$ is countable. For $f:X \rightarrow \C$, we can write $f = g +ih$ where $g,h:X \rightarrow \R$. If $$\sum_{x \in X}|f(x)| < \infty,$$ then the same is true for $g^+,g^-,h^+,h^-$. In this case, we may define $$\sum_{x \in X} f(x)$$ in the obvious way.
	\end{defn} 
	
	The following note justifies the notation $\sum_{x \in X}f(x)$ where $f:X \rightarrow \C$.
	
	\begin{note}
		Let $f:X \rightarrow \C$ and $\al:X \rightarrow X$ a bijection. If $\sum_{x \in X}|f(x)|< \infty$, then $\sum_{x \in X}f( \al (x)) = \sum_{x \in X}f(x) $.
	\end{note}
	
	\newpage	
	
	\subsection{Asymptotic Notation}
	
	\begin{defn}
	Let $X$ be a topological space, $Y, Z$ be normed vector spaces, $f:X \rightarrow Y$, $g: X \rightarrow Z$ and $x_0 \in X \cup \{\infty\}$. Then we write $$f = o(g) \hspace{.5cm} \text{ as } x \rightarrow x_0$$ if for each $\ep >0$, there exists $U \in \MN_{x_0}$ such that $U$ is open and for each $x \in U$, $$\|f(x)\|_u \leq \ep\|g(x)\|_u$$
	\end{defn}
	
	\begin{ex}
	Let $X$ be a topological space, $Y, Z$ be normed vector spaces, $f:X \rightarrow Y$, $g: X \rightarrow Z$ and $x_0 \in X \cup \{\infty\}$. If there exists $U \in \MN_{x_0}$ such that $U$ is open and for each $x \in U \setminus \{x_0\}$, $g(x) > 0$, then $$f = o(g) \text{ as } x \rightarrow x_0 \hspace{.25cm} \text{ iff } \hspace{.25cm}  \lim_{x \rightarrow x_0} \frac{\| f(x) \|}{\| g(x) \|} = 0$$
	\end{ex}	
	
	
	
	
	
	
	
	
	
	
	
	
	\newpage
	\begin{thebibliography}{4}
\bibitem{groups} \href{https://github.com/carsonaj/Mathematics/tree/master/Introduction\%20to\%20Group\%20Theory}{Introduction to Group Theory}

\bibitem{measure}  \href{https://github.com/carsonaj/Mathematics/blob/master/Introduction\%20to\%20Measure\%20and\%20Integration/Introduction\%20to\%20Measure\%20and\%20Integration.pdf}{Introduction to Measure and Integration}


\end{thebibliography}


	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	\end{document}
	
	