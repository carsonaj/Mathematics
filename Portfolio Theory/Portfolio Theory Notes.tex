
\documentclass[12pt]{amsart}
 \usepackage[margin=1in]{geometry} 
\usepackage{amsmath,amsthm,amssymb,amsfonts,setspace}

\newtheorem{thm}{Theorem}[section]
\newtheorem{lem}[thm]{Lemma}
\newtheorem{prop}[thm]{Proposition}
\newtheorem{cor}[thm]{Corollary}
\newtheorem{conj}{Conjecture}
\newtheorem{defn}[thm]{Definition}
\newtheorem{note}[thm]{Note}
\newtheorem{ex}[thm]{Exercise}


\newcommand{\al}{\alpha}
\newcommand{\be}{\beta} 
\newcommand{\del}{\delta} 
\newcommand{\Del}{\Delta}
\newcommand{\lam}{\lambda}  
\newcommand{\Lam}{\Lambda} 
\newcommand{\ep}{\epsilon}
\newcommand{\sig}{\sigma} 
\newcommand{\om}{\omega}
\newcommand{\Om}{\Omega}
\newcommand{\C}{\mathbb{C}}
\newcommand{\N}{\mathbb{N}}
\newcommand{\E}{\mathbb{E}}
\newcommand{\Z}{\mathbb{Z}}
\newcommand{\R}{\mathbb{R}}
\newcommand{\Q}{\mathbb{Q}}
\renewcommand{\P}{\mathbb{P}}
\newcommand{\MA}{\mathcal{A}}
\newcommand{\MB}{\mathcal{B}}
\newcommand{\MF}{\mathcal{F}}
\newcommand{\MG}{\mathcal{G}}
\newcommand{\ML}{\mathcal{L}}
\newcommand{\MN}{\mathcal{N}}
\newcommand{\MS}{\mathcal{S}}
\newcommand{\MP}{\mathcal{P}}
\newcommand{\ME}{\mathcal{E}}
\newcommand{\MT}{\mathcal{T}}
\newcommand{\MM}{\mathcal{M}}

\newcommand{\RG}{[0,\infty]}
\newcommand{\Rg}{[0,\infty)}
\newcommand{\limfn}{\liminf \limits_{n \rightarrow \infty}}
\newcommand{\limpn}{\limsup \limits_{n \rightarrow \infty}}
\newcommand{\limn}{\lim \limits_{n \rightarrow \infty}}
\newcommand{\convt}[1]{\xrightarrow{\text{#1}}}
\newcommand{\conv}[1]{\xrightarrow{#1}} 

\DeclareMathOperator*{\argmax}{arg\,max}
\DeclareMathOperator*{\argmin}{arg\,min}
 
 
 
\newcommand\Item[1][]{%
  \ifx\relax#1\relax  \item \else \item[#1] \fi
  \abovedisplayskip=0pt\abovedisplayshortskip=0pt~\vspace*{-\baselineskip}} 
 
 
 
 
 
\begin{document}

\title{Portfolio Theory Notes}
\maketitle

\tableofcontents

\begin{note}
In these notes we will mostly consider a probability space $(\Om, \MF, P)$ and a random variable $X: \Om \rightarrow \R$. We assume that $X \in L^1(P)$ and $F_X:\R \rightarrow (0,1)$ is strictly increasing and continuous. We will call such a random variable "nice". The random variable $X$ will usually refer to the return on some portfolio. As such, we will define the loss of $X$ to be $L_X = -X$.
\end{note}

\section{Risk Measures}

\subsection{Value at Risk}

\begin{defn}
Let $X$ be a nice random variable and $\al \in (0,1)$. We define the \textbf{value at risk of } $X$ \textbf{at confidence level } $\al$, denoted by $v_{\al}(X)$, to be 

\begin{align*}
v_{\al}(X) 
&= F^{-1}_{L_X}(\al)
\end{align*}
Thus $$P(L_X > v_{\al}(X)) = 1- \al$$
\end{defn}

\begin{note}
In practice, we take $\al= .95$ or $\al= .99$. 
\end{note}

\subsection{Expected Shortfall}

 \begin{defn}
Let $X$ be a nice random variable and $\al\in (0,1)$. We define the \textbf{expected shortfall of } $X$ \textbf{with tail probability } $1-\al$, denoted by $e_{\al}(X)$, to be $$e_{\al}(X) = \frac{1}{1-\al}\int_{[\al,1)}v_p(X)dm(p)$$
\end{defn}

\begin{note}
If $X$ represents the return on a portfolio, then $e_{\al}(X)$ is just the average of the $v_{p}(X)$ on the interval $(\al, 1]$.
\end{note}

\begin{ex}
Let $X$ be a nice random variable and $\al\in (0,1)$. Then 
\begin{align*}
e_{\al}(X) 
&= E[L_X|L_X \geq v_{\al}(X)]
\end{align*}
\end{ex}

\begin{proof}
Recall that for measurable spaces $(X,\MA)$ and $(Y, \MB)$, a measurable function $f:X \rightarrow Y$ and a measure $\mu:\MA \rightarrow \RG$, we may form the push-foreward measure of $\mu$ by $f$, $f_{*}\mu:\MB \rightarrow \RG$ with the following property: for each $g:Y \rightarrow \C$, $g \in L^1(f_* \mu)$ iff  $g \circ f \in L^1(\mu)$ and for each $B \in \MB$, 

$$\int_{f^{-1}(B)}g \circ f d\mu = \int_B g d f_*\mu$$
Also recall that for an increasing continuous, bijective $F:\R \rightarrow (0,1)$, we may form the Borel measure $\mu_F$ with $\mu_F((a,b]) = F(b)-F(a)$. Then observe that $F_*\mu_F = m$ because
\begin{align*}
{F}_{*} \mu_F ((a,b]) 
&= \mu_F(F^{-1}((a,b]))\\
&= \mu_F((F^{-1}(a), F^{-1}(b)]) \\ 
&= F(F^{-1}(b)) - F(F^{-1}(a))\\
&= b-a
\end{align*}
Then  
\begin{align*}
E[L_X |L_X \geq v_{\al}(X)]
&= E[L_X|L_X \geq F^{-1}_{L_X}(\al)] \\ 
&= \frac{1}{1-\al}E [L_X I_{\{L_X \geq F^{-1}_{L_X}(\al)\}}] \\ 
&=  \frac{1}{1-\al} \int_{\{L_X \geq F_{L_X}^{-1}(\al)\}}L_X dP \\
&= \frac{1}{1-\al} \int_{[F_{L_X}^{-1}(\al),  \infty)}pd F_{L_X}(p) \\
&= \frac{1}{1-\al} \int_{[F_{L_X}^{-1}(\al),  \infty)}pd F_{L_X}(p) \\
&= \frac{1}{1-\al} \int_{[F_{L_X}^{-1}(\al),  \infty)}(F^{-1}_{L_X} \circ F_{L_X}) (p)d F_{L_X}(p) \\
&= \frac{1}{1-\al} \int_{[\al,  1)} F^{-1}_{L_X}(p)dm(p)\\
&= \frac{1}{1-\al} \int_{[\al,  1)} v_{p}(X)dm(p) \\
&= e_{\al}(X)
\end{align*}
\end{proof}

\begin{lem}
Let $\al \in (0,1)$. Define $f_{\al}: \R \rightarrow \R$ by $$f_\al(\theta) = \theta + \frac{1}{1-\al}E[(L_X - \theta)^+]$$
Then $f_\al$ is convex and $$\frac{df_\al}{d \theta}(\theta) = \frac{F_{L_X}(\theta) - \al}{1-\al}$$
\end{lem}

\begin{proof} 
Recall that given $g:\Om \times \R \rightarrow \R$, if for each $\om \in \Om$, $g(\om, \theta)$ is convex in $\theta$, then $E[g(\cdot, \theta)]$ is convex in theta. For $\om \in \Om, \theta \in \R$, put $$g(\om, \theta) = (L_X(\om) - \theta)^+$$ So $$f_{\al}(\theta) = \theta + \frac{1}{1-\al}E[g(\cdot, \theta)]$$ Then for each $\om \in \Om$, $g(\om, \cdot)$ is convex. This implies that for each $\al\in (0,1)$, $f_{\al}$ is convex and therefore continuous. \vspace{3mm}\\ 
Now Let $\theta, \theta' \in \R$. Suppose that $\theta<\theta'$. Then 
\begin{align*}
\frac{f_\al(\theta') - f_\al(\theta)}{\theta' - \theta} 
&= 1 + \frac{1}{1-\al}E\bigg[\frac{(L_X - \theta')^+ - (L_X - \theta)^+}{\theta'-\theta}\bigg] \\
\end{align*}
For $\om \in \Om$, we have that 
$$\frac{(L_X(\om) - \theta')^+ - (L_X(\om) - \theta)^+}{\theta'-\theta}= 
\begin{cases}
-1 &  \theta' \leq L_X(\om) \\
0 & L_X(\om) \leq  \theta \\
\ep \in (-1,0) &\theta < L_X(\om) < \theta'
\end{cases}$$
This implies that 
\begin{align*}
-(F_{L_X}(\theta') - F_{L_X}(\theta))
&= -P(\theta < L_X < \theta') \\
&\leq E\bigg[ \frac{(L_X - \theta')^+ - (L_X - \theta)^+}{\theta'-\theta} I_{L_X \in (\theta, \theta')}\bigg] \\
&< 0
\end{align*} 
Thus there exists $c \in (0, 1)$ such that $$E\bigg[ \frac{(L_X - \theta')^+ - (L_X - \theta)^+}{\theta'-\theta} I_{L_X \in (\theta, \theta')}\bigg] = -c(F_{L_X}(\theta') - F_{L_X}(\theta))$$\vspace{3mm}\\
In addition, $P(\theta' \leq L_X) = 1-F_{L_X}(\theta')$.
Therefore 
\begin{align*}
E\bigg[ \frac{(L_X - \theta')^+ - (L_X - \theta)^+}{\theta'-\theta} \bigg]
&= -(1-F_{L_X}(\theta')) -c[F_{L_X}(\theta') - F_{L_X}(\theta)]
\end{align*}\\
This implies that $$\lim_{\theta' \rightarrow \theta^+}E\bigg[ \frac{(L_X - \theta')^+ - (L_X - \theta)^+}{\theta'-\theta} \bigg] = F_{L_X}(\theta) -1$$\\
Finally we have that 
\begin{align*}
\lim_{\theta' \rightarrow \theta^+} \frac{f_\al(\theta') - f_\al(\theta)}{\theta' - \theta} 
&= 1 + \frac{1}{1-\al}\lim_{\theta' \rightarrow \theta^+}E\bigg[ \frac{(L_X - \theta')^+ - (L_X - \theta)^+}{\theta'-\theta} \bigg] \\
&= 1 + \frac{F_{L_X}(\theta) -1}{1-\al}\\
&= \frac{F_{L_X}(\theta) -\al}{1-\al}
\end{align*}
The case is similar for the lefthand limit.

\end{proof}

\begin{thm}
Let $X$ be a nice random variable and $\al\in (0,1)$. Then $$v_{\al}(X) = \argmin_{\theta \in \R} \bigg(\theta + \frac{1}{1-\al}E[(L_X - \theta)^+]\bigg)$$ and $$e_{\al}(X) = \min_{\theta \in \R} \bigg(\theta + \frac{1}{1-\al}E[(L_X - \theta)^+]\bigg)$$
\end{thm}

\begin{proof} 
Define $f_{\alpha}$ as before. The previous lemma tells us that $$\frac{d f_{\al}}{d \theta}(\theta) = \frac{F_{L_X}(\theta) -\al}{1-\al} $$ Thus $$\lim_{\theta \rightarrow \infty}\frac{d f_{\al}}{d \theta}(\theta) = 1$$ and $$\lim_{\theta \rightarrow -\infty} \frac{d f_{\al}}{d \theta}(\theta) = - \frac{\al}{1-\al} <0$$
Thus $\lim\limits_{\theta \rightarrow \infty} f_{\alpha}(\theta) = \lim\limits_{\theta \rightarrow -\infty}f_{\al}(\theta) = \infty$. The convexity of $f_{\al}$ implies that there exists a unique $\theta^* \in \R$ such that $f_{\al}(\theta^*) = \inf\limits_{\theta \in \R}f_{\al}(\theta)$
Thus $$\frac{d f_{\al}}{d \theta}(\theta^*) = 0$$
which implies that $$F_{L_X}(\theta^*) = \al$$
By definition, $\theta^* = v_{\al}(X)$. Finally, evaluating $f_{\al}$ at $\theta^*$ shows us that 

\begin{align*}
f_{\al}(\theta^*)  
&=  \theta^* + \frac{1}{1- \al}E[(L_X - \theta^*)^+]\\
& = \theta^* + \frac{1}{P(L_X>\theta^*)}E[(L_X-\theta^*)I_{\{L_X>\theta^*\}}] \\
& = \theta^* + \frac{1}{P(L_X>\theta^*)}E[L_XI_{\{L_X>\theta^*\}}] - \frac{1}{P(L_X>\theta^*)}E[\theta^*I_{\{L_X>\theta^*\}}] \\
& = \theta^* + \frac{1}{P(L_X>\theta^*)}E[L_XI_{\{L_X>\theta^*\}}] - \theta^* \\
&= E[L_X|L_X> \theta^*] \\
& = E[L_X|L_X>v_{\al}(X)] \\
& = e_{\al}(X)
\end{align*}

\end{proof}

\section{Estimation of Risk}

\subsection{Estimating the Value at Risk in the IID Case}

\begin{defn}
Let $X$ be a random nice random variable, $X_1, \cdots , X_n \stackrel{iid}{\sim} X$ and $\al\in (0,1)$. Define $$\widehat{v}_\al = $$
\end{defn}

\subsection{Estimating the Expected Shortfall in the IID Case}

\begin{defn}
Let $X$ be a nice random random variable, $X_1, \cdots , X_n \stackrel{iid}{\sim} X$ and $\al\in (0,1)$. Define $$ \widehat{e}_{\al, n} = \frac{\sum_{i=1}^nL_{X_i}I_{L_{X_i \geq \widehat{v}_{\al}}}}{\sum_{i=1}^nI_{L_X \geq \widehat{v}_{\al}}} $$ 
\end{defn}

\begin{lem}
Let $X$ be a nice random random variable, $X_1, \cdots , X_n
\stackrel{iid}{\sim} X$ and $\al \in (0,1)$. Then $\widehat{e}_{\al, n} \convt{a.e.} e_{\al}(X)$.
\end{lem}

\begin{proof}
	Since $(L_X)_{i = 1}^n \subset L^1$ are iid, the SLLN tells us that for each $v \in \R$, $$\frac{1}{n}\sum_{i=1}^n L_{X_i}I_{\{L_{X_i} \geq v\}} \convt{a.e.} E[L_XI_{\{X > v\}}]$$
\end{proof}

\begin{proof}
For each $\al\in (0,1), \om \in \Om$ and $\theta \in \R$, define $$f_{\al}(\om)(\theta) = \theta + \frac{1}{n (1-\al)} \sum_{i=1}^n\max(-X_i(\om) - \theta, 0) $$ 

Note that for each $\al\in (0,1)$ and $\om \in \Om$, $f_{\al}(\om)$ is convex and continuous. In this case with no expectation, it is easy to show that $$\lim_{\theta \rightarrow \infty}\frac{\partial f_{\al}(\om)}{\partial \theta}(\theta) = 1$$

and
 
$$\lim_{\theta \rightarrow -\infty}\frac{\partial f_{\al}(\om)}{\partial \theta}(\theta) = -\frac{\al}{1-\al} <0$$  

So for each $\al\in (0,1)$ and $\om \in \Om$, $f_{\al}(\om)$ achieves its minimum at . Then $\{\theta \in \R: f_{\al}(\om)(\theta)\leq m+1\}$ is bounded

Since $f_{\al}$ is continuous, we have that $$\inf_{\theta \in \R} f_{\al}(\theta) = \inf_{\theta \in \Q} f_{\al}(\theta)$$ 

which is measurable. 

\end{proof} 

\bibliographystyle{amsplain}
\bibliography{Portfolio_Theory_References}

\end{document}